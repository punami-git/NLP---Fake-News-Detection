{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085bb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "import random\n",
    "from nltk.collocations import *\n",
    "import dill\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a53a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666bb0a",
   "metadata": {},
   "source": [
    "<h1>Define N-gram Feature Exractor Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fda741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram Only Extractor\n",
    "def unigram_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['V_{}'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "70512f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Unigram + Bigram Extractor\n",
    "def bigram_document_features(document, word_features, bigram_features): \n",
    "    document_words = set(document) \n",
    "    document_bigrams = nltk.bigrams(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f\"W_{word}\"] = (word in document_words)\n",
    "    for bigram in bigram_features:\n",
    "        features[f\"B_{bigram[0]}_{bigram[1]}\"] = (bigram in document_bigrams)\n",
    "    return features\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede91a4",
   "metadata": {},
   "source": [
    "<h1>Define Cross Validation Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3047b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_accuracy(num_folds, featuresets):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    print('Each fold size:', subset_size)\n",
    "    accuracy_list = []\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = featuresets[:(i*subset_size)] + featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        print (i, accuracy_this_round)\n",
    "        accuracy_list.append(accuracy_this_round)\n",
    "        \n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean accuracy', sum(accuracy_list) / num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c08e41",
   "metadata": {},
   "source": [
    "<h1> Define Evaluation Metrics Function: Precision, Recall, F1, and Specificity</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ab3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### EVALUATE PRECISION, RECALL, F1, AND SPECIFICITY FOR EACH LABEL\n",
    "def eval_measures(gold, predicted):\n",
    "    # get a list of labels\n",
    "    labels = list(set(gold))\n",
    "    # these lists have values for each label \n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    F1_list = []\n",
    "    specificity_list =[]\n",
    "    for lab in labels:\n",
    "        # for each label, compare gold and predicted lists and compute values\n",
    "        TP = FP = FN = TN = 0\n",
    "        for i, val in enumerate(gold):\n",
    "            if val == lab and predicted[i] == lab:  TP += 1\n",
    "            if val == lab and predicted[i] != lab:  FN += 1\n",
    "            if val != lab and predicted[i] == lab:  FP += 1\n",
    "            if val != lab and predicted[i] != lab:  TN += 1\n",
    "        # use these to compute recall, precision, F1\n",
    "        recall = TP / (TP + FN)\n",
    "        precision = TP / (TP + FP)\n",
    "        specificity = TN / (TN + FP)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        F1_list.append( 2 * (recall * precision) / (recall + precision))\n",
    "        specificity_list.append(specificity)\n",
    "\n",
    "    # the evaluation measures in a table with one row per label\n",
    "    print('\\n\\nEvaluation_Metrics----\\n\\n\\tPrecision\\tRecall\\t    F1\\t Specificity')\n",
    "    # print measures for each label\n",
    "    for i, lab in enumerate(labels):\n",
    "        print(lab, '\\t', \"{:10.3f}\".format(precision_list[i]), \\\n",
    "          \"{:10.3f}\".format(recall_list[i]), \"{:10.3f}\".format(F1_list[i]),\"{:10.3f}\".format(specificity_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e4fcd",
   "metadata": {},
   "source": [
    "<h1>Define Confusion Matrix and Eval Metrics Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ae09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_eval_print(test_set):\n",
    "\n",
    "    goldlist = []\n",
    "    predictedlist = []\n",
    "\n",
    "    for (features, label) in test_set:\n",
    "        goldlist.append(label)\n",
    "        predictedlist.append(NBclassifier.classify(features))\n",
    "        \n",
    "    cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "\n",
    "    print(\"\\nConfusion_Matrix----\\n\\n\", cm.pretty_format(sort_by_count=True))\n",
    "    \n",
    "    eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c42581",
   "metadata": {},
   "source": [
    "<h1>Loading and Examining the Dataset</h1> \n",
    "<br>\n",
    "<body>In the interest of familiarizing ourselves with the data quickly, we will start out by looking at only a portion of it. Specfically, we will start out by analyzing only the \"title\" field of the dataset, which is the headlines of the news items. We will do minimal pre-processing, extract unigrams, and use them to train a Naive Bayes Classifier to establish a baseline of accuracy and take an initial look at informative features.</body>\n",
    "<h3>Load the unfiltered dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "983aedd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72129</th>\n",
       "      <td>Russians steal research on Trump in hack of U....</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72130</th>\n",
       "      <td>WATCH: Giuliani Demands That Democrats Apolog...</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72131</th>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72132</th>\n",
       "      <td>Trump tussle gives unpopular Mexican leader mu...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trump’s combati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72133</th>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1                                                    NaN   \n",
       "2      UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3      Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4      SATAN 2: Russia unvelis an image of its terrif...   \n",
       "...                                                  ...   \n",
       "72129  Russians steal research on Trump in hack of U....   \n",
       "72130   WATCH: Giuliani Demands That Democrats Apolog...   \n",
       "72131  Migrants Refuse To Leave Train At Refugee Camp...   \n",
       "72132  Trump tussle gives unpopular Mexican leader mu...   \n",
       "72133  Goldman Sachs Endorses Hillary Clinton For Pre...   \n",
       "\n",
       "                                                    text  label  \n",
       "index                                                            \n",
       "0      No comment is expected from Barack Obama Membe...      1  \n",
       "1         Did they post their votes for Hillary already?      1  \n",
       "2       Now, most of the demonstrators gathered last ...      1  \n",
       "3      A dozen politically active pastors came here f...      0  \n",
       "4      The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "...                                                  ...    ...  \n",
       "72129  WASHINGTON (Reuters) - Hackers believed to be ...      0  \n",
       "72130  You know, because in fantasyland Republicans n...      1  \n",
       "72131  Migrants Refuse To Leave Train At Refugee Camp...      0  \n",
       "72132  MEXICO CITY (Reuters) - Donald Trump’s combati...      0  \n",
       "72133  Goldman Sachs Endorses Hillary Clinton For Pre...      1  \n",
       "\n",
       "[72134 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('~/WELFake_Dataset.csv', \n",
    "                 index_col='index', \n",
    "                 header=0,\n",
    "                 names=['index', 'title', 'text', 'label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf1e169",
   "metadata": {},
   "source": [
    "<h2> Minimal pre-processing</h2>\n",
    "<h3> Drop rows with empty fields </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b943c23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72134\n",
      "71537\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c4f49914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN fields in the original dataset: 597\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of NaN fields in the original dataset: {72134 - 71537}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c209286",
   "metadata": {},
   "source": [
    "<h3>Balance fake and real labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f54a2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fakenews items: 36509\n",
      "Number of real news items: 35028\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of fakenews items:\", df['label'].value_counts()[1])\n",
    "print(\"Number of real news items:\", df['label'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83f4e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between fake (1) and real (0) count: 0\n"
     ]
    }
   ],
   "source": [
    "# balance labels\n",
    "rows_to_delete = df[df['label'] == 1].head(740) + df[df['label'] == 1].tail(741)\n",
    "df = df.drop(rows_to_delete.index)\n",
    "\n",
    "# confirm labels are now balanced\n",
    "count = (df['label'].value_counts()[1])-(df['label'].value_counts()[0])\n",
    "print(\"Difference between fake (1) and real (0) count:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fba719",
   "metadata": {},
   "source": [
    "<h3>Re-shuffle the rows of the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e44e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9929bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of rows in the dataset: 70056\n"
     ]
    }
   ],
   "source": [
    "print(\"Current number of rows in the dataset:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "61642fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_process_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b193b",
   "metadata": {},
   "source": [
    "<h3>EXPORT to CSV: Minimally Processed Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "36d203fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT REVISED DATAFRAME TO CSV FOR FUTURE USE SO RANDOMIZATION WILL NOT BE A VARIABLE\n",
    "\n",
    "min_process_df.to_csv('~/min_process_fakenews_df_canonical.csv ', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad526dd",
   "metadata": {},
   "source": [
    "<h1>TEST 1: Create Unigram Features: Unfiltered, Titles-Only </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbc585",
   "metadata": {},
   "source": [
    "<h1>Define the Unigram Extraction Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "41c5c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MINIMALLY PRE-PROCESSED DATASET\n",
    "\n",
    "df = pd.read_csv('~/min_process_fakenews_df_canonical.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "5f9f47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tuple of title, label for each row in the df\n",
    "tuple_rows = list(df.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "bd4cb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and lowercase the words in the title\n",
    "title_words_tuple = [(word_tokenize(title[0].lower()), title[2]) for title in tuple_rows]\n",
    "documents = title_words_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "f7a611a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['help', 'blow', 'up', 'the', 'globalists', 'plot', 'to', 'steal', 'the', 'presidency-', 'make', 'this', 'go', 'viral'], 1)\n"
     ]
    }
   ],
   "source": [
    "# print an example document to confirm everything looks right\n",
    "print(title_words_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "60d0b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 995190 words in the unfiltered title-only corpus.\n",
      "There are 38811 unique words in the unfilted title-only corpus.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of unique words in the corpus\n",
    "all_words_list = [word for (title, cat) in documents for word in title]\n",
    "print(f\"There are {len(all_words_list)} words in the unfiltered title-only corpus.\")\n",
    "print(f\"There are {len(set(all_words_list))} unique words in the unfilted title-only corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "92ddd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the word list by frequency and select the 3000 most common unique words as our vocabulary\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "word_items = all_words.most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "6b7888ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the unigram features variable\n",
    "title_features = [word for (word,count) in word_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "d2169703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the title featureset variable\n",
    "title_featuresets = [(unigram_features(title, title_features), cat) for (title, cat) in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84e843",
   "metadata": {},
   "source": [
    "<h3>Train and Test Naive Bayes Classifier on the Unigram Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "546ec4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 70:30 train/test ratio\n",
    "train_set, test_set = title_featuresets[(round(.30 * len(title_featuresets))):], title_featuresets[:(round(.30 * len(title_featuresets)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "9c649631",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "460fb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "7fa86fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8838083456249702\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f776a9",
   "metadata": {},
   "source": [
    "<h4>Test 1 Most Informative Features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "211260ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = Fake / 0 = Real\n",
      "Most Informative Features\n",
      "                     V_[ = True                1 : 0      =   1442.0 : 1.0\n",
      "                     V_] = True                1 : 0      =   1442.0 : 1.0\n",
      "                   V_wow = True                1 : 0      =    161.7 : 1.0\n",
      "               V_myanmar = True                0 : 1      =    140.4 : 1.0\n",
      "                     V_“ = True                1 : 0      =    129.2 : 1.0\n",
      "                     V_” = True                1 : 0      =    127.0 : 1.0\n",
      "                 V_video = True                1 : 0      =     70.1 : 1.0\n",
      "               V_awesome = True                1 : 0      =     63.9 : 1.0\n",
      "             V_brilliant = True                1 : 0      =     61.9 : 1.0\n",
      "             V_bombshell = True                1 : 0      =     60.8 : 1.0\n",
      "           V_hilariously = True                1 : 0      =     58.6 : 1.0\n",
      "                     V_! = True                1 : 0      =     58.2 : 1.0\n",
      "                V_insane = True                1 : 0      =     57.9 : 1.0\n",
      "                 V_bundy = True                1 : 0      =     53.2 : 1.0\n",
      "               V_crooked = True                1 : 0      =     53.2 : 1.0\n",
      "                  V_york = True                0 : 1      =     51.0 : 1.0\n",
      "              V_zimbabwe = True                0 : 1      =     50.4 : 1.0\n",
      "              V_shocking = True                1 : 0      =     48.6 : 1.0\n",
      "                 V_onion = True                1 : 0      =     48.5 : 1.0\n",
      "                V_finest = True                1 : 0      =     47.2 : 1.0\n",
      "             V_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "                  V_oops = True                1 : 0      =     45.2 : 1.0\n",
      "                V_mugabe = True                0 : 1      =     44.8 : 1.0\n",
      "              V_breaking = True                1 : 0      =     38.9 : 1.0\n",
      "             V_perfectly = True                1 : 0      =     38.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"1 = Fake / 0 = Real\")\n",
    "NBclassifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "2060792b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 7005\n",
      "0 0.8792291220556745\n",
      "1 0.8850820842255531\n",
      "2 0.8852248394004283\n",
      "3 0.8866523911491792\n",
      "4 0.8809421841541756\n",
      "5 0.8795146324054247\n",
      "6 0.8822269807280514\n",
      "7 0.8843683083511777\n",
      "8 0.8765167737330478\n",
      "9 0.8795146324054247\n",
      "mean accuracy 0.8819271948608136\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 10\n",
    "cross_validation_accuracy(num_folds, title_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldlist = []\n",
    "predictedlist = []\n",
    "\n",
    "for (features, label) in test_set:\n",
    "    goldlist.append(label)\n",
    "    predictedlist.append(NBclassifier.classify(features))\n",
    "\n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "72316dbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8846>1712 |\n",
      "0 |  730<9729>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm.pretty_format(sort_by_count=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "07e81c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.850      0.930      0.888      0.838\n",
      "1 \t      0.924      0.838      0.879      0.930\n"
     ]
    }
   ],
   "source": [
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363140ae",
   "metadata": {},
   "source": [
    "<h3>Test 1 Discussion: NB Classifier on Unigram Features of the Minimally Processed Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850b5a1",
   "metadata": {},
   "source": [
    "<body>Although we have already achieved impressive results with the minimally pre-processed title-only corpus using the <b>Naive Bayes Classifier on unigram features, scoring 88.1% mean accuracy with 10-fold cross evaluation,</b> when we look at the <b>Most Informative Features</b>, we see some irregularities. Some of the features, such as \"wow\", \"awesome\", \"shocking\", and even \"!\" are plausible sytlistic distinguishing features for fakenews, indicative of a more sensationalistic rhetorical style.  \n",
    "<br><br>When we look at the detailed evalauation metrics, we see that the <b>F1 Score for both the positive and negative label are close to each other and to the mean accuracy</b>, suggesting that the model is generally well-balanced.   \n",
    " <br><br>However, the two <b>Most Informative Features are open and closed square brackets</b>, and in the top ten, we also have the word \"video\" as well as double quotation marks. These seem arbitrary and are less plausible as truly informative features. One possible explanation is that we are seeing <b>over-fitting due to imbalances in the dataset</b>, e.g. headline labels such as \"[VIDEO]\" might consistently come from a single fakenews source that happens to format video titles this way. \n",
    "<br><br>\n",
    "Interestingly, though the outliers in Most Informative Features predict positive labels, in the detailed evaluation metrics, we see that <b>Recall</b>, or sensitivity, is higher for the negative label assignment. We also see that <b>Precision and Specificty for postive (fake) label prediction is quite high at 92.4% and 93%</b> respectively, indicating that there are unigram features that are highly predictive of a positive label, with realitively few false positives. \n",
    "<br><br>Though this minimally processed featureset gives us a high level of accuracy, the model will not generalize well in a dataset that does not have this imbalance. To correct this, we will perform some standard text pre-processing and check our results...</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a904ed6",
   "metadata": {},
   "source": [
    "<h1>Pre-Processing</h1><br>\n",
    "<body>In order to maintain flexibility for future use, we will tokenize and pre-process both the \"title\" (headline) and \"text\" (news item body) in the dataset separately before re-exporting the processed text to a csv.\n",
    "<br><br>Because there are some stylistically signficant puncutation marks we will want to keep and some unusual tokens, such as censored expletives using '*' vowel replacement and hashtags that we will want to treat differently than the word_tokenize method, we will use the NLTK <b>RegexpTokenizer</b>.\n",
    "<br><br>We will use the NLTK <b>Snowball Stemmer</b> to stem tokens.\n",
    "</body>\n",
    "<h3>Creating Custom Filters for Non-Significant Punctuation and Stopwords + Stemming</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db2d141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT STEMMER\n",
    "stemmer = nltk.SnowballStemmer('english')\n",
    "\n",
    "# STOPWORDS TO FILTER OUT\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# NEGATION WORDS TO KEEP\n",
    "negationwords = ['no', 'not', 'never', 'none', 'nowhere', 'nothing', 'no one', 'rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor']\n",
    "\n",
    "# WORDS TO FILTER OUT\n",
    "filter_words = [word for word in stopwords if word not in negationwords]\n",
    "\n",
    "# STYLISTICALLY SIGNIFICANT PUNCTUATION TO KEEP\n",
    "style_punct = ['!', '#', '*']\n",
    "\n",
    "# STYLISTICALLY INSIGNIFICANT PUNCT NOT INCLUDED IN string.punctuation BUT FOUND IN THE DATASET\n",
    "extra_punct = [\"’\", \"”\", \"”\", \"‹\", \"›\", \"'s\",\"“\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13956bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase the text and remove unwanted characters\n",
    "    text = \"\".join([word.lower() for word in text if (word not in string.punctuation and \n",
    "    word not in extra_punct) or word in style_punct])\n",
    "    \n",
    "    # Define a RegexpTokenizer that tokenizes asteriks within words (e.g. for obscuring expletives)\n",
    "    # and keeps hashes with hashtags\n",
    "    tokenizer = RegexpTokenizer(r'[A-Za-z*]+|\\S+')\n",
    "\n",
    "    # Tokenize the cleaned text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # stem words using Snowball Stemmer\n",
    "    text = [stemmer.stem(word) for word in tokens if word not in filter_words]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "80f4afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD THE MINIMALLY PRE-PROCESSED DATASET IF NEEDED\n",
    "# df = pd.read_csv('~/min_process_fakenews_df_canonical.csv', \n",
    "#                  index_col=None, \n",
    "#                  header=0,\n",
    "#                  names=['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "1edca8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tuple of title, label for each row in the df\n",
    "fulltext_label_tuple = list(df.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "8d02bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN THE TEXT \n",
    "documents = [(clean_text(i[0]),clean_text(i[1]), i[2]) for i in fulltext_label_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "30850037",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['grow',\n",
       "  'f*ck',\n",
       "  '!',\n",
       "  'trump',\n",
       "  'get',\n",
       "  'taken',\n",
       "  'woodsh',\n",
       "  'call',\n",
       "  'govern',\n",
       "  'shutdown'],\n",
       " ['yesterday',\n",
       "  'amateur',\n",
       "  'presid',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'made',\n",
       "  'ass',\n",
       "  'fail',\n",
       "  'histori',\n",
       "  'today',\n",
       "  'call',\n",
       "  'futur',\n",
       "  'govern',\n",
       "  'shutdown',\n",
       "  'trump',\n",
       "  'could',\n",
       "  'f*ck',\n",
       "  'past',\n",
       "  'futur',\n",
       "  '24hour',\n",
       "  'trump',\n",
       "  'want',\n",
       "  'shut',\n",
       "  'govern',\n",
       "  'lead',\n",
       "  'thing',\n",
       "  'real',\n",
       "  'presid',\n",
       "  'would',\n",
       "  'tri',\n",
       "  'avoid',\n",
       "  'former',\n",
       "  'presid',\n",
       "  'barack',\n",
       "  'obama',\n",
       "  'made',\n",
       "  'concess',\n",
       "  'order',\n",
       "  'avoid',\n",
       "  'govern',\n",
       "  'shutdown',\n",
       "  'manbabi',\n",
       "  'potus',\n",
       "  'whine',\n",
       "  'twitter',\n",
       "  'deal',\n",
       "  'reach',\n",
       "  '1',\n",
       "  'trillionplus',\n",
       "  'bill',\n",
       "  'fund',\n",
       "  'govern',\n",
       "  'final',\n",
       "  'five',\n",
       "  'month',\n",
       "  'fiscal',\n",
       "  'yeareven',\n",
       "  'though',\n",
       "  'republican',\n",
       "  'control',\n",
       "  'congress',\n",
       "  'senat',\n",
       "  'instal',\n",
       "  'republican',\n",
       "  'presid',\n",
       "  'trump',\n",
       "  'not',\n",
       "  'get',\n",
       "  'fund',\n",
       "  'ineffect',\n",
       "  'border',\n",
       "  'wall',\n",
       "  'taxpay',\n",
       "  'dollar',\n",
       "  'not',\n",
       "  'spent',\n",
       "  'deport',\n",
       "  'forc',\n",
       "  'bill',\n",
       "  'includ',\n",
       "  '295',\n",
       "  'million',\n",
       "  'puerto',\n",
       "  'rico',\n",
       "  'medicaid',\n",
       "  'program',\n",
       "  'congress',\n",
       "  'budget',\n",
       "  'not',\n",
       "  'defund',\n",
       "  'plan',\n",
       "  'parenthood',\n",
       "  'short',\n",
       "  'listobvi',\n",
       "  'upset',\n",
       "  'former',\n",
       "  'realiti',\n",
       "  'show',\n",
       "  'star',\n",
       "  'previous',\n",
       "  'deem',\n",
       "  'great',\n",
       "  'negotiatoron',\n",
       "  'twitter',\n",
       "  'wrote',\n",
       "  'reason',\n",
       "  'plan',\n",
       "  'negoti',\n",
       "  'republican',\n",
       "  'democrat',\n",
       "  'need',\n",
       "  '60',\n",
       "  'vote',\n",
       "  'senat',\n",
       "  'not',\n",
       "  '!',\n",
       "  'reason',\n",
       "  'plan',\n",
       "  'negoti',\n",
       "  'republican',\n",
       "  'democrat',\n",
       "  'need',\n",
       "  '60',\n",
       "  'vote',\n",
       "  'senat',\n",
       "  'not',\n",
       "  '!',\n",
       "  'donald',\n",
       "  'j',\n",
       "  'trump',\n",
       "  'realdonaldtrump',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017a',\n",
       "  'minut',\n",
       "  'later',\n",
       "  'trump',\n",
       "  'ad',\n",
       "  'either',\n",
       "  'elect',\n",
       "  'republican',\n",
       "  'senat',\n",
       "  '2018',\n",
       "  'chang',\n",
       "  'rule',\n",
       "  '51',\n",
       "  'countri',\n",
       "  'need',\n",
       "  'good',\n",
       "  'shutdown',\n",
       "  'septemb',\n",
       "  'fix',\n",
       "  'mess',\n",
       "  '!',\n",
       "  'either',\n",
       "  'elect',\n",
       "  'republican',\n",
       "  'senat',\n",
       "  '2018',\n",
       "  'chang',\n",
       "  'rule',\n",
       "  '51',\n",
       "  'countri',\n",
       "  'need',\n",
       "  'good',\n",
       "  'shutdown',\n",
       "  'septemb',\n",
       "  'fix',\n",
       "  'mess',\n",
       "  '!',\n",
       "  'donald',\n",
       "  'j',\n",
       "  'trump',\n",
       "  'realdonaldtrump',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017so',\n",
       "  'get',\n",
       "  'way',\n",
       "  'want',\n",
       "  'chang',\n",
       "  'rule',\n",
       "  'reason',\n",
       "  'prospect',\n",
       "  'govern',\n",
       "  'shutdown',\n",
       "  'huge',\n",
       "  'unpopular',\n",
       "  'one',\n",
       "  'twitter',\n",
       "  'user',\n",
       "  'school',\n",
       "  'himrealdonaldtrump',\n",
       "  'your',\n",
       "  'reckless',\n",
       "  'shut',\n",
       "  'govern',\n",
       "  'isnt',\n",
       "  'like',\n",
       "  'close',\n",
       "  'casino',\n",
       "  'last',\n",
       "  'govern',\n",
       "  'shutdown',\n",
       "  'cost',\n",
       "  'economi',\n",
       "  '24b06',\n",
       "  'gdp',\n",
       "  'joseph',\n",
       "  'amodeo',\n",
       "  'josephamodeo',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  '2013',\n",
       "  'shutdown',\n",
       "  'also',\n",
       "  'result',\n",
       "  '450kday',\n",
       "  'lost',\n",
       "  'revenu',\n",
       "  'natlparkservic',\n",
       "  'sourc',\n",
       "  'nps',\n",
       "  'wapo',\n",
       "  'joseph',\n",
       "  'amodeo',\n",
       "  'josephamodeo',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'natlparkservic',\n",
       "  'accord',\n",
       "  'ustravel',\n",
       "  '2013',\n",
       "  'shutdown',\n",
       "  'cost',\n",
       "  '152mday',\n",
       "  '24b',\n",
       "  'lost',\n",
       "  'travel',\n",
       "  'spend',\n",
       "  'sourc',\n",
       "  'us',\n",
       "  'travel',\n",
       "  'assoc',\n",
       "  'wapo',\n",
       "  'joseph',\n",
       "  'amodeo',\n",
       "  'josephamodeo',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'natlparkservic',\n",
       "  'ustravel',\n",
       "  'realdonaldtrump',\n",
       "  'govern',\n",
       "  'fact',\n",
       "  'shutdown',\n",
       "  'mean',\n",
       "  'didnt',\n",
       "  'job',\n",
       "  'american',\n",
       "  'ppl',\n",
       "  'cannot',\n",
       "  'afford',\n",
       "  'shutdown',\n",
       "  'joseph',\n",
       "  'amodeo',\n",
       "  'josephamodeo',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'natlparkservic',\n",
       "  'ustravel',\n",
       "  'cannot',\n",
       "  'afford',\n",
       "  'increas',\n",
       "  'gas',\n",
       "  'tax',\n",
       "  'consumpt',\n",
       "  'tax',\n",
       "  'disproportion',\n",
       "  'affect',\n",
       "  'lowmiddl',\n",
       "  'incom',\n",
       "  'ppl',\n",
       "  'joseph',\n",
       "  'amodeo',\n",
       "  'josephamodeo',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017it',\n",
       "  'true',\n",
       "  'trump',\n",
       "  'liter',\n",
       "  'call',\n",
       "  'increas',\n",
       "  'gas',\n",
       "  'tax',\n",
       "  'rememb',\n",
       "  'conserv',\n",
       "  'blame',\n",
       "  'obama',\n",
       "  'gas',\n",
       "  'price',\n",
       "  'increas',\n",
       "  'not',\n",
       "  'control',\n",
       "  'republican',\n",
       "  'presid',\n",
       "  'want',\n",
       "  'deliber',\n",
       "  'rais',\n",
       "  'price',\n",
       "  'gas',\n",
       "  'tax',\n",
       "  'increasetwitt',\n",
       "  'user',\n",
       "  'not',\n",
       "  'amus',\n",
       "  'trump',\n",
       "  'reckless',\n",
       "  'tweetrealdonaldtrump',\n",
       "  'wait',\n",
       "  'put',\n",
       "  'shutdown',\n",
       "  'quot',\n",
       "  'accord',\n",
       "  'sean',\n",
       "  'spicer',\n",
       "  'dont',\n",
       "  'realli',\n",
       "  'mean',\n",
       "  'david',\n",
       "  'nuzzi',\n",
       "  'nussbaum',\n",
       "  'thenuzzi',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'mayb',\n",
       "  'attempt',\n",
       "  'presid',\n",
       "  'peopl',\n",
       "  'reach',\n",
       "  'across',\n",
       "  'aisl',\n",
       "  'bipartisan',\n",
       "  'agreement',\n",
       "  'like',\n",
       "  'everi',\n",
       "  'presid',\n",
       "  'david',\n",
       "  'nuzzi',\n",
       "  'nussbaum',\n",
       "  'thenuzzi',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'last',\n",
       "  'week',\n",
       "  'blame',\n",
       "  'democrat',\n",
       "  'shut',\n",
       "  'govern',\n",
       "  'jail',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'dtrumpexpos',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'sound',\n",
       "  'like',\n",
       "  'toddler',\n",
       "  'throw',\n",
       "  'truck',\n",
       "  'know',\n",
       "  'like',\n",
       "  'playpen',\n",
       "  'kid',\n",
       "  'mean',\n",
       "  'grown',\n",
       "  'fuck',\n",
       "  'mike',\n",
       "  'p',\n",
       "  'william',\n",
       "  'mikepwilliam',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017realdonaldtrump',\n",
       "  'well',\n",
       "  'your',\n",
       "  'least',\n",
       "  'consist',\n",
       "  'earlier',\n",
       "  'posit',\n",
       "  'view',\n",
       "  'govern',\n",
       "  'shutdown',\n",
       "  'httpstco',\n",
       "  '07wlkur1c',\n",
       "  'simon',\n",
       "  'hedlin',\n",
       "  'simonhedlin',\n",
       "  'may',\n",
       "  '2',\n",
       "  '2017trump',\n",
       "  'unpopular',\n",
       "  'presid',\n",
       "  'first',\n",
       "  '100',\n",
       "  'day',\n",
       "  'offic',\n",
       "  'wonder',\n",
       "  'tri',\n",
       "  'distract',\n",
       "  'us',\n",
       "  'time',\n",
       "  'cough',\n",
       "  'cough',\n",
       "  'russiaphoto',\n",
       "  'chip',\n",
       "  'somodevillagetti',\n",
       "  'imag'],\n",
       " 1)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check an entry with focus tokens (e.g. internal '*' and '!')\n",
    "documents[70055]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513932f",
   "metadata": {},
   "source": [
    "<h3>EXPORT to CSV: Pre-Processed Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "4f706144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE DATAFRAME\n",
    "cleaned_df = pd.DataFrame(documents,\n",
    "               columns =['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c0d573ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLATTEN LISTS INSIDE THE DATAFRAME\n",
    "def process_text(text):\n",
    "    return ', '.join(text)\n",
    "\n",
    "cleaned_df['title'] = cleaned_df['title'].apply(process_text)\n",
    "cleaned_df['text'] = cleaned_df['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "a9d57ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT PRE-PROCESSED DATASET TO CSV FOR FUTURE USE\n",
    "cleaned_df.to_csv('~/preprocessed_fakenews_df_canonical.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98343166",
   "metadata": {},
   "source": [
    "<h1>TEST 2: <br>Using the Naive Bayes Classifier on the Cleaned Title-Only Unigram Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "ec42a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE PRE-PROCESSED DATASET IF NEEDED\n",
    "df = pd.read_csv('~/preprocessed_fakenews_df_canonical.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "8ce1dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_rows = list(df.itertuples(index=False, name=None))\n",
    "document_str = [(str(i[0]), i[2]) for i in tuple_rows]\n",
    "documents = [(i[0].split(\", \"), i[1]) for i in document_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "d17e5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_featuresets = [(unigram_features(title, title_features), cat) for (title, cat) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "5d876c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list = [word for (title, cat) in documents for word in title]\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "word_items = all_words.most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "233ebb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = title_featuresets[(round(.30 * len(title_featuresets))):], title_featuresets[:(round(.30 * len(title_featuresets)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "197d5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "b3095a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "dab51efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8435552172051196\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b678c",
   "metadata": {},
   "source": [
    "<h3>Test 2 Most Informative Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "cd512422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = Fake / 0 = Real\n",
      "Most Informative Features\n",
      "                   V_wow = True                1 : 0      =    162.3 : 1.0\n",
      "               V_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     V_… = True                1 : 0      =     95.7 : 1.0\n",
      "                     V_! = True                1 : 0      =     56.9 : 1.0\n",
      "                  V_york = True                0 : 1      =     50.5 : 1.0\n",
      "             V_brilliant = True                1 : 0      =     49.6 : 1.0\n",
      "                 V_onion = True                1 : 0      =     49.2 : 1.0\n",
      "                V_finest = True                1 : 0      =     47.2 : 1.0\n",
      "             V_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "                 V_video = True                1 : 0      =     38.8 : 1.0\n",
      "                     V_– = True                1 : 0      =     37.6 : 1.0\n",
      "                V_antifa = True                1 : 0      =     35.8 : 1.0\n",
      "               V_mnuchin = True                0 : 1      =     33.5 : 1.0\n",
      "                  V_epic = True                1 : 0      =     32.8 : 1.0\n",
      "                 V_laugh = True                1 : 0      =     32.6 : 1.0\n",
      "                  V_thug = True                1 : 0      =     30.3 : 1.0\n",
      "               V_furious = True                1 : 0      =     28.7 : 1.0\n",
      "                V_unreal = True                1 : 0      =     27.8 : 1.0\n",
      "                    V_xi = True                0 : 1      =     26.6 : 1.0\n",
      "               V_baghdad = True                0 : 1      =     24.2 : 1.0\n",
      "                 V_envoy = True                0 : 1      =     24.2 : 1.0\n",
      "             V_halloween = True                1 : 0      =     23.9 : 1.0\n",
      "                V_macron = True                0 : 1      =     23.8 : 1.0\n",
      "                   V_mic = True                1 : 0      =     23.8 : 1.0\n",
      "                    V_en = True                1 : 0      =     23.1 : 1.0\n",
      "                  V_seth = True                1 : 0      =     23.1 : 1.0\n",
      "               V_tantrum = True                1 : 0      =     22.4 : 1.0\n",
      "               V_somalia = True                0 : 1      =     22.2 : 1.0\n",
      "              V_cambodia = True                0 : 1      =     21.6 : 1.0\n",
      "                   V_rio = True                0 : 1      =     21.6 : 1.0\n",
      "                 V_viral = True                1 : 0      =     21.4 : 1.0\n",
      "                 V_idiot = True                1 : 0      =     20.3 : 1.0\n",
      "                 V_czech = True                0 : 1      =     19.6 : 1.0\n",
      "                V_soccer = True                0 : 1      =     19.6 : 1.0\n",
      "               V_kremlin = True                0 : 1      =     19.1 : 1.0\n",
      "                V_tucker = True                1 : 0      =     19.1 : 1.0\n",
      "               V_ireland = True                0 : 1      =     18.9 : 1.0\n",
      "                   V_kkk = True                1 : 0      =     18.3 : 1.0\n",
      "             V_tillerson = True                0 : 1      =     18.2 : 1.0\n",
      "                 V_egypt = True                0 : 1      =     17.4 : 1.0\n",
      "                    V_pm = True                0 : 1      =     16.6 : 1.0\n",
      "                   V_abe = True                0 : 1      =     16.4 : 1.0\n",
      "                V_brutal = True                1 : 0      =     16.3 : 1.0\n",
      "                   V_kid = True                1 : 0      =     16.2 : 1.0\n",
      "              V_thailand = True                0 : 1      =     15.6 : 1.0\n",
      "               V_kurdish = True                0 : 1      =     15.5 : 1.0\n",
      "                  V_trey = True                1 : 0      =     15.5 : 1.0\n",
      "               V_perfect = True                1 : 0      =     15.4 : 1.0\n",
      "                V_rapist = True                1 : 0      =     15.3 : 1.0\n",
      "              V_watchdog = True                0 : 1      =     15.2 : 1.0\n",
      "           V_supremacist = True                1 : 0      =     15.1 : 1.0\n",
      "                  V_irma = True                0 : 1      =     14.8 : 1.0\n",
      "                  V_rant = True                1 : 0      =     14.8 : 1.0\n",
      "                   V_doj = True                1 : 0      =     14.7 : 1.0\n",
      "               V_patrick = True                1 : 0      =     14.7 : 1.0\n",
      "                 V_nafta = True                0 : 1      =     14.5 : 1.0\n",
      "             V_flashback = True                1 : 0      =     14.0 : 1.0\n",
      "                    V_ca = True                1 : 0      =     13.6 : 1.0\n",
      "                 V_spain = True                0 : 1      =     13.6 : 1.0\n",
      "               V_taliban = True                0 : 1      =     13.3 : 1.0\n",
      "                   V_hey = True                1 : 0      =     13.1 : 1.0\n",
      "                   V_cop = True                1 : 0      =     12.7 : 1.0\n",
      "              V_thursday = True                0 : 1      =     12.2 : 1.0\n",
      "                 V_watch = True                1 : 0      =     12.2 : 1.0\n",
      "                V_stupid = True                1 : 0      =     12.0 : 1.0\n",
      "                 V_proof = True                1 : 0      =     12.0 : 1.0\n",
      "                 V_guest = True                1 : 0      =     11.8 : 1.0\n",
      "                 V_audio = True                1 : 0      =     11.8 : 1.0\n",
      "                 V_dutch = True                0 : 1      =     11.8 : 1.0\n",
      "                  V_curb = True                0 : 1      =     11.6 : 1.0\n",
      "                    V_oh = True                1 : 0      =     11.4 : 1.0\n",
      "                 V_jesus = True                1 : 0      =     11.3 : 1.0\n",
      "               V_destroy = True                1 : 0      =     11.0 : 1.0\n",
      "                  V_nypd = True                1 : 0      =     11.0 : 1.0\n",
      "                V_racist = True                1 : 0      =     11.0 : 1.0\n",
      "               V_podesta = True                1 : 0      =     10.9 : 1.0\n",
      "                  V_time = True                0 : 1      =     10.9 : 1.0\n",
      "                   V_dad = True                1 : 0      =     10.9 : 1.0\n",
      "                  V_seek = True                0 : 1      =     10.9 : 1.0\n",
      "                V_caught = True                1 : 0      =     10.8 : 1.0\n",
      "                  V_room = True                1 : 0      =     10.7 : 1.0\n",
      "                   V_wsj = True                0 : 1      =     10.6 : 1.0\n",
      "                V_anchor = True                1 : 0      =     10.4 : 1.0\n",
      "                  V_milo = True                0 : 1      =     10.2 : 1.0\n",
      "              V_northern = True                0 : 1      =     10.2 : 1.0\n",
      "                V_taiwan = True                0 : 1      =     10.2 : 1.0\n",
      "                 V_guess = True                1 : 0      =     10.2 : 1.0\n",
      "                 V_break = True                1 : 0      =     10.0 : 1.0\n",
      "             V_spokesman = True                0 : 1      =      9.9 : 1.0\n",
      "                 V_kenya = True                0 : 1      =      9.7 : 1.0\n",
      "                V_oregon = True                1 : 0      =      9.7 : 1.0\n",
      "                  V_peru = True                0 : 1      =      9.6 : 1.0\n",
      "                V_region = True                0 : 1      =      9.6 : 1.0\n",
      "              V_shutdown = True                0 : 1      =      9.6 : 1.0\n",
      "             V_indonesia = True                0 : 1      =      9.5 : 1.0\n",
      "             V_wednesday = True                0 : 1      =      9.5 : 1.0\n",
      "                 V_shock = True                1 : 0      =      9.4 : 1.0\n",
      "                 V_prove = True                1 : 0      =      9.4 : 1.0\n",
      "                  V_rico = True                0 : 1      =      9.4 : 1.0\n",
      "                 V_japan = True                0 : 1      =      9.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"1 = Fake / 0 = Real\")\n",
    "NBclassifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbf989",
   "metadata": {},
   "source": [
    "<h3>Test 2 Cross Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "1fc26b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8441224751980587\n",
      "1 0.8416958104346585\n",
      "2 0.8362715009635286\n",
      "3 0.8409820855042467\n",
      "4 0.8347013061166226\n",
      "mean accuracy 0.8395546356434231\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567850d",
   "metadata": {},
   "source": [
    "<h3>Test 2 Confusion Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "78762716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8790>1768 |\n",
      "0 | 1520<8939>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "goldlist = []\n",
    "predictedlist = []\n",
    "\n",
    "for (features, label) in test_set:\n",
    "    goldlist.append(label)\n",
    "    predictedlist.append(NBclassifier.classify(features))\n",
    "\n",
    "cm = nltk.ConfusionMatrix(goldlist, predictedlist)\n",
    "\n",
    "print(cm.pretty_format(sort_by_count=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8f3de",
   "metadata": {},
   "source": [
    "<h3>Test 2 Evaluation Measures</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "22f757e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.835      0.855      0.845      0.833\n",
      "1 \t      0.853      0.833      0.842      0.855\n"
     ]
    }
   ],
   "source": [
    "eval_measures(goldlist, predictedlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205769d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a8b18c3",
   "metadata": {},
   "source": [
    "<h3>Test 2 Discussion: NB Classifier on Unigram Features of the Cleaned Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae546f",
   "metadata": {},
   "source": [
    "<body>Having taken the text through a customized version of standard pre-processing, \n",
    "    <b>accuracy has dropped from 88 to 83.95%</b>.\n",
    "<br><br>    \n",
    "However, while we may have sacrificed some accuracy, we appear to have a more generalizable model. <br><br>Looking at the <b>Most Informative Features</b> we have fewer items that seem arbitrary and more words with a plausible relationship to the categorzation of real vs. fake news.\n",
    "\n",
    "Drilling down into the list a bit, we can see <b>four broad categories of unigrams</b> that are correlated with  fakenews categorization: \n",
    "\n",
    "* <b>sensationalistic</b> language (e.g. \"brutal\", \"epic\", \"unreal\")\n",
    "* <b>informal</b>, esp. deragatory or dismissive language (e.g. \"cop\", \"stupid\", \"idiot\")\n",
    "* <b>\"hot-button\"</b> topics (e.g. \"antifa\", \"kkk\", \"rapist\") \n",
    "* <b>special punctuation</b> typical of online language use (i.e. \"!\", \"...\")\n",
    "    \n",
    "At the same time, names of <b>non-controversial political figures, places, or roles</b> (e.g. \"Macron\", \"Myanmar\", \"envoy\") are strongly associated with <b>real news</b>.\n",
    "<br><br>Looking at the <b>Evaluation Metrics</b> we see that <b>Precision, Recall, and Specificity are all much closer</b> for both the postive and negative labels and relative to each other. This suggests that the preprocessing we have done has gone a long way to correcting the biases of the minimally processed dataset.\n",
    "<br><br>What difference remains between the scores shows the same pattern, with the model being slightly more sensitive to negative label items and having a slightly higher precision and specificity for the positive label.\n",
    "<br><br>\n",
    "Having found a good recipe for pre-processing, next we will take a look at expanding the corpus from title-only to a concatenated title-and-text...\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d455c",
   "metadata": {},
   "source": [
    "<h1>Test 3:<br>Using the NB Classifier on the Combined Title + Text Unigram Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1699c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE PRE-PROCESSED DATASET IF NEEDED\n",
    "df = pd.read_csv('~/preprocessed_fakenews_df_canonical.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7278713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunday, screen, ‘a, nobl, lie, 2011, 21st, cen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trumpocalyps, 5, ridicul, outdat, assumpt, eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>help, blow, globalist, plot, steal, presid, ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new, report, find, voter, no, idea, outrag, su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>box, offic, tom, hank, circl, bomb, furious, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       combined_text  label\n",
       "0  sunday, screen, ‘a, nobl, lie, 2011, 21st, cen...      1\n",
       "1  trumpocalyps, 5, ridicul, outdat, assumpt, eve...      1\n",
       "2  help, blow, globalist, plot, steal, presid, ma...      1\n",
       "3  new, report, find, voter, no, idea, outrag, su...      1\n",
       "4  box, offic, tom, hank, circl, bomb, furious, c...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMBINE 'TITLE' & 'TEXT' COLUMNS SEPARATED BY A COMMA\n",
    "df['combined_text'] = df.apply(lambda row: \", \".join(row[['title', 'text']].astype(str)), axis=1)\n",
    "df = df[['combined_text', 'label']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0c01525",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_rows = list(df.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d01813fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_str = [(str(text[0]), text[1]) for text in tuple_rows]\n",
    "documents = [(text[0].split(\", \"), text[1]) for text in document_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f719520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list = [word for (title, cat) in documents for word in title]\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "word_items = all_words.most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "120309c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = [word for (word,count) in word_items]\n",
    "text_featuresets = [(unigram_features(text, text_features), cat) for (text, cat) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fdf8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_text_featureset_df = pd.DataFrame(text_featuresets, columns=['features', 'label'])\n",
    "unigram_text_features_df = pd.DataFrame(unigram_text_featureset_df['features'].tolist())\n",
    "df_csv = pd.concat([unigram_text_features_df, unigram_text_featureset_df ['label']], axis=1)\n",
    "df_csv.to_csv('~/combined_title_text_unigram_features_fakenews_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "927bcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE DATASET IF NEEDED\n",
    "df = pd.read_csv('~/combined_title_text_unigram_features_fakenews_df_canonical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f68dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18faad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = text_featuresets[(round(.30 * len(text_featuresets))):], text_featuresets[:(round(.30 * len(text_featuresets)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7df57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fda262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8b7d9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7827472998049199\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311d7f0",
   "metadata": {},
   "source": [
    "<h3>Test 3 Most Informative Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "ca00ab3d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = Fake / 0 = Real\n",
      "Most Informative Features\n",
      "                 V_getti = True                1 : 0      =    101.9 : 1.0\n",
      "               V_catalan = True                0 : 1      =     90.6 : 1.0\n",
      "              V_rohingya = True                0 : 1      =     75.8 : 1.0\n",
      "                     V_и = True                1 : 0      =     71.3 : 1.0\n",
      "             V_catalonia = True                0 : 1      =     66.2 : 1.0\n",
      "                   V_000 = True                0 : 1      =     53.4 : 1.0\n",
      "               V_myanmar = True                0 : 1      =     43.8 : 1.0\n",
      "                     V_в = True                1 : 0      =     43.2 : 1.0\n",
      "                    V_на = True                1 : 0      =     41.6 : 1.0\n",
      "                V_reuter = True                0 : 1      =     37.7 : 1.0\n",
      "            V_screenshot = True                1 : 0      =     32.2 : 1.0\n",
      "                 V_bundi = True                1 : 0      =     23.9 : 1.0\n",
      "                   V_com = True                0 : 1      =     22.7 : 1.0\n",
      "                V_macron = True                0 : 1      =     14.4 : 1.0\n",
      "                V_hilari = True                1 : 0      =     12.0 : 1.0\n",
      "                   V_que = True                1 : 0      =     11.3 : 1.0\n",
      "              V_overhaul = True                0 : 1      =     11.3 : 1.0\n",
      "                   V_via = True                1 : 0      =     10.3 : 1.0\n",
      "                 V_mugab = True                0 : 1      =     10.0 : 1.0\n",
      "                    V_rt = True                1 : 0      =      9.5 : 1.0\n",
      "                  V_beij = True                0 : 1      =      9.5 : 1.0\n",
      "             V_pyongyang = True                0 : 1      =      9.3 : 1.0\n",
      "            V_bangladesh = True                0 : 1      =      8.8 : 1.0\n",
      "                    V_xi = True                0 : 1      =      8.7 : 1.0\n",
      "                   V_doj = True                1 : 0      =      8.5 : 1.0\n",
      "              V_subscrib = True                1 : 0      =      8.0 : 1.0\n",
      "             V_tillerson = True                0 : 1      =      7.6 : 1.0\n",
      "                V_ankara = True                0 : 1      =      7.5 : 1.0\n",
      "                     V_u = True                0 : 1      =      7.4 : 1.0\n",
      "                 V_idiot = True                1 : 0      =      7.2 : 1.0\n",
      "                 V_matti = True                0 : 1      =      7.2 : 1.0\n",
      "                  V_soro = True                1 : 0      =      7.1 : 1.0\n",
      "                 V_insan = True                1 : 0      =      7.0 : 1.0\n",
      "                   V_rex = True                0 : 1      =      6.9 : 1.0\n",
      "                V_weiner = True                1 : 0      =      6.9 : 1.0\n",
      "                  V_wire = True                1 : 0      =      6.6 : 1.0\n",
      "                  V_imag = True                1 : 0      =      6.4 : 1.0\n",
      "               V_mnuchin = True                0 : 1      =      6.2 : 1.0\n",
      "                  V_huma = True                1 : 0      =      6.1 : 1.0\n",
      "                V_abedin = True                1 : 0      =      6.0 : 1.0\n",
      "                  V_21st = True                1 : 0      =      5.9 : 1.0\n",
      "                   V_etc = True                1 : 0      =      5.9 : 1.0\n",
      "         V_parliamentari = True                0 : 1      =      5.9 : 1.0\n",
      "            V_referendum = True                0 : 1      =      5.4 : 1.0\n",
      "             V_crackdown = True                0 : 1      =      5.4 : 1.0\n",
      "                  V_damn = True                1 : 0      =      5.3 : 1.0\n",
      "              V_wikileak = True                1 : 0      =      5.2 : 1.0\n",
      "                   V_cop = True                1 : 0      =      5.1 : 1.0\n",
      "       V_realdonaldtrump = True                1 : 0      =      5.1 : 1.0\n",
      "           V_spokeswoman = True                0 : 1      =      5.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"1 = Fake / 0 = Real\")\n",
    "NBclassifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8a53b",
   "metadata": {},
   "source": [
    "<h3>Test 3 Cross Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ad8dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.7857397758903718\n",
      "1 0.7796017414888302\n",
      "2 0.7794589965027479\n",
      "3 0.78502605095996\n",
      "4 0.7785311540932125\n",
      "mean accuracy 0.7816715437870244\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, text_featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba23b0e",
   "metadata": {},
   "source": [
    "<h3>Test 3 Confusion Matrix & Evaluation Metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf02f443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8992>1566 |\n",
      "0 | 3000<7459>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.826      0.713      0.766      0.852\n",
      "1 \t      0.750      0.852      0.798      0.713\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48fc1b",
   "metadata": {},
   "source": [
    "<h3>Test 3 Discussion: NB Classifier with Ungiram Features on Title + Text Combined</h3>\n",
    "<br>\n",
    "<body>Suprisingly, adding the additional text from the 'text' column to the dataset did not imporve accuracy. In fact, it significantly <b>reduced accuracy from 84 to 78%</b>. \n",
    "<br><br>\n",
    "Interestingly, <b>Most Informative Features</b> for the combined text included several characters that appear to be from a <b>Cryllic characterset</b> (e.g. 'и', 'на','в'), and these are all strongly associated with the <b>fakenews</b> category.\n",
    "<br><br>\n",
    "Looking at the evaulation metrics, we see that with the combined text and title, there is an inversion of the relationship between the postivie and negative labels that we have been seeing in the 'title only' dataset. Here, Precision and Specificity are higher for the positive label than for the negative label, indicating that we are getting more false positives. Correspondingly, we see that Recall for the positive label is also significantly higher, indicating a bias toward predicting the fake news label.\n",
    "<br><br>\n",
    "Because the additional data in the combined text both reduces accuracy and also signficantly slows processing down, we will be focusing on the title text only in the remaining experiments. Next we will look at adjusting vocabulary length.\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f60a7",
   "metadata": {},
   "source": [
    "<h1>TEST 4: Comparing Effects of Vocabulary Size on Unigram Featuresets</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "064530f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE PRE-PROCESSED DATASET IF NEEDED\n",
    "df = pd.read_csv('~/preprocessed_fakenews_df_canonical.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])\n",
    "\n",
    "tuple_rows = list(df.itertuples(index=False, name=None))\n",
    "document_str = [(str(text[0]), text[2]) for text in tuple_rows]\n",
    "documents = [(text[0].split(\", \"), text[1]) for text in document_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66ebbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list = [word for (title, cat) in documents for word in title]\n",
    "all_words = nltk.FreqDist(all_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2ea40",
   "metadata": {},
   "source": [
    "<h4>Use 10% vocab</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7603745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_items = all_words.most_common(round((len(all_words) * 0.10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9620642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with a 10% vocab:0.8603035637817005\n",
      "\n",
      "Execution time: 123.79466509819031 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "title_features = [word for (word,count) in word_items]\n",
    "title_featuresets = [(unigram_features(title, title_features), cat) for (title, cat) in documents]\n",
    "train_set, test_set = title_featuresets[(round(.30 * len(title_featuresets))):], title_featuresets[:(round(.30 * len(title_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "print(f\"Accuracy with a 10% vocab:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b27af4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2577"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2fad4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8622510884305189\n",
      "1 0.8603240311184069\n",
      "2 0.8578259938619656\n",
      "3 0.860752266076654\n",
      "4 0.8543287417029477\n",
      "mean accuracy 0.8590964242380986\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06347111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8891>1667 |\n",
      "0 | 1269<9190>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.846      0.879      0.862      0.842\n",
      "1 \t      0.875      0.842      0.858      0.879\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9546c",
   "metadata": {},
   "source": [
    "<h4>Using 20% vocab</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c256f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual vocab size: 5155\n"
     ]
    }
   ],
   "source": [
    "word_items = all_words.most_common(round((len(all_words) * 0.20)))\n",
    "print(f\"actual vocab size: {len(word_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "124644b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with a 20% vocab:0.8693438644906504\n",
      "\n",
      "Execution time: 356.29472517967224 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time execution\n",
    "start = time.time()\n",
    "\n",
    "title_features = [word for (word,count) in word_items]\n",
    "title_featuresets = [(unigram_features(text, title_features), cat) for (text, cat) in documents]\n",
    "train_set, test_set = title_featuresets[(round(.30 * len(title_featuresets))):], title_featuresets[:(round(.30 * len(title_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "print(f\"Accuracy with a 20% vocab:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49531bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8711726500606666\n",
      "1 0.8701020626650489\n",
      "2 0.8669616729712369\n",
      "3 0.8692455927485547\n",
      "4 0.8652487331382486\n",
      "mean accuracy 0.868546142316751\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c299da29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8987>1571 |\n",
      "0 | 1175<9284>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.855      0.888      0.871      0.851\n",
      "1 \t      0.884      0.851      0.867      0.888\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8177d5",
   "metadata": {},
   "source": [
    "<h4>Using 15% vocab</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7650758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual vocab size: 3866\n"
     ]
    }
   ],
   "source": [
    "word_items = all_words.most_common(round((len(all_words) * 0.15)))\n",
    "\n",
    "print(f\"actual vocab size: {len(word_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1d1e85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with a 15% vocab:0.8660132273873531\n",
      "\n",
      "Execution time: 327.28680086135864 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "title_features = [word for (word,count) in word_items]\n",
    "title_featuresets = [(unigram_features(text, title_features), cat) for (text, cat) in documents]\n",
    "train_set, test_set = title_featuresets[(round(.30 * len(title_featuresets))):], title_featuresets[:(round(.30 * len(title_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "print(f\"Accuracy with a 15% vocab:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ecb64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8677467703946898\n",
      "1 0.8661765755477839\n",
      "2 0.8626079508957248\n",
      "3 0.8663906930269074\n",
      "4 0.8624652059096424\n",
      "mean accuracy 0.8650774391549497\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9f7f88c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8968>1590 |\n",
      "0 | 1226<9233>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.883      0.868      0.849\n",
      "1 \t      0.880      0.849      0.864      0.883\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f935495",
   "metadata": {},
   "source": [
    "<h3>Test 4 Disucssion: Vocabulary Size</h3>\n",
    "<br>\n",
    "<body>\n",
    "    Systematically testing different <b>vocabulary sizes</b> for the featurests \n",
    "as a percentage of the normalized set of words in the pre-processed \n",
    "text gave improvements in accuracy as the size increased, <b>improving accuracy from 84% to 86.9%</b>.\n",
    "<br><br> \n",
    "However, there were diminishing returns even as execution time increased significantly, coming to around 6 minutes for the 20% vocab size.\n",
    "<br><br>\n",
    "Going forward, the <b>15% (word count: 3866) vocabulary with 86.6% accuracy for unigram features</b> is a reasonable compromise.\n",
    "   \n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84daf68f",
   "metadata": {},
   "source": [
    "<h1>Test 4: Baseline Cross Validation and P/R/F1 for Unigram Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093562db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8677467703946898\n",
      "1 0.8661765755477839\n",
      "2 0.8626079508957248\n",
      "3 0.8663906930269074\n",
      "4 0.8624652059096424\n",
      "mean accuracy 0.8650774391549497\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4addae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8968>1590 |\n",
      "0 | 1226<9233>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.883      0.868      0.849\n",
      "1 \t      0.880      0.849      0.864      0.883\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6dc228",
   "metadata": {},
   "source": [
    "<h3>Test 4 Discussion: Cross Validation and Precision / Recall / F1 Baseline for a Unigram Featureset</h3>\n",
    "<br>\n",
    "<body> Using the 15% vocab unigram featureset, we performed cross validation and got a <b>Mean Accuracy of 86.5%</b>\n",
    "<br><br>\n",
    "<b>Precision/Recall/F1</b> scores were in the <b>85-88% range</b> with higher Precision \n",
    "on real news items and better Recall on fakenews items.\n",
    "<br><br>\n",
    "Next, we will export the unigram features for future use and will experiment with <b>additional n-gram features</b>.\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e4369",
   "metadata": {},
   "source": [
    "<h3>Export Unigram Features to CSV for Future Use</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_featureset_df = pd.DataFrame(title_featuresets, columns=['features', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "100a0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_features_df = pd.DataFrame(unigram_featureset_df['features'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8a9d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_trump</th>\n",
       "      <th>V_new</th>\n",
       "      <th>V_video</th>\n",
       "      <th>V_time</th>\n",
       "      <th>V_york</th>\n",
       "      <th>V_us</th>\n",
       "      <th>V_say</th>\n",
       "      <th>V_!</th>\n",
       "      <th>V_hillari</th>\n",
       "      <th>V_obama</th>\n",
       "      <th>...</th>\n",
       "      <th>V_belief</th>\n",
       "      <th>V_disarm</th>\n",
       "      <th>V_pant</th>\n",
       "      <th>V_madonna</th>\n",
       "      <th>V_onto</th>\n",
       "      <th>V_guatemala</th>\n",
       "      <th>V_clerk</th>\n",
       "      <th>V_trader</th>\n",
       "      <th>V_paus</th>\n",
       "      <th>V_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70051</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70052</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70053</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70054</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70055</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70056 rows × 3866 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V_trump  V_new  V_video  V_time  V_york   V_us  V_say    V_!  \\\n",
       "0        False  False    False   False   False  False  False  False   \n",
       "1        False  False    False   False   False  False  False  False   \n",
       "2        False  False    False   False   False  False  False  False   \n",
       "3        False   True    False   False   False  False  False  False   \n",
       "4        False  False    False   False   False  False  False  False   \n",
       "...        ...    ...      ...     ...     ...    ...    ...    ...   \n",
       "70051     True  False    False   False   False  False  False  False   \n",
       "70052    False  False    False   False   False  False  False  False   \n",
       "70053    False  False     True    True   False  False  False   True   \n",
       "70054    False  False    False   False   False  False  False  False   \n",
       "70055     True  False    False   False   False  False  False   True   \n",
       "\n",
       "       V_hillari  V_obama  ...  V_belief  V_disarm  V_pant  V_madonna  V_onto  \\\n",
       "0          False    False  ...     False     False   False      False   False   \n",
       "1          False    False  ...     False     False   False      False   False   \n",
       "2          False    False  ...     False     False   False      False   False   \n",
       "3          False    False  ...     False     False   False      False   False   \n",
       "4          False    False  ...     False     False   False      False   False   \n",
       "...          ...      ...  ...       ...       ...     ...        ...     ...   \n",
       "70051      False    False  ...     False     False   False      False   False   \n",
       "70052      False    False  ...     False     False   False      False   False   \n",
       "70053      False    False  ...     False     False   False      False   False   \n",
       "70054      False    False  ...     False     False   False      False   False   \n",
       "70055      False    False  ...     False     False   False      False   False   \n",
       "\n",
       "       V_guatemala  V_clerk  V_trader  V_paus  V_unknown  \n",
       "0            False    False     False   False      False  \n",
       "1            False    False     False   False      False  \n",
       "2            False    False     False   False      False  \n",
       "3            False    False     False   False      False  \n",
       "4            False    False     False   False      False  \n",
       "...            ...      ...       ...     ...        ...  \n",
       "70051        False    False     False   False      False  \n",
       "70052        False    False     False   False      False  \n",
       "70053        False    False     False   False      False  \n",
       "70054        False    False     False   False      False  \n",
       "70055        False    False     False   False      False  \n",
       "\n",
       "[70056 rows x 3866 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f08ccd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.concat([unigram_features_df, unigram_featureset_df ['label']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9fab61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv('~/title_unigram_features_fakenews_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a00a1d",
   "metadata": {},
   "source": [
    "<h1>TEST 5: Combining Unigram and Bigram Features for the Title-Only Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "342b3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_document_features(document, word_features, bigram_features): \n",
    "    document_words = set(document) \n",
    "    document_bigrams = nltk.bigrams(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f\"W_{word}\"] = (word in document_words)\n",
    "    for bigram in bigram_features:\n",
    "        features[f\"B_{bigram[0]}_{bigram[1]}\"] = (bigram in document_bigrams)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04a6d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4502e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.apply_word_filter(lambda w: len(w) < 2 or w.isalpha() is False)\n",
    "finder.apply_freq_filter(50)\n",
    "bigram_pmi_scored = finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c72fd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_features_pmi = [(bigram[0:2]) for (bigram, frequency) in bigram_pmi_scored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6fa2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "[(('kellyann', 'conway'), 12.024244809567056), (('elizabeth', 'warren'), 11.67746030850408), (('ben', 'carson'), 11.657714679585153), (('puerto', 'rico'), 11.509450550496737), (('megyn', 'kelli'), 11.40868029774349), (('sean', 'spicer'), 11.2838263047642), (('boiler', 'room'), 11.034661425512395), (('saudi', 'arabia'), 10.306262094520516), (('room', 'ep'), 10.303478183940197), (('mike', 'penc'), 10.223732904311289), (('attorney', 'general'), 10.165917382142133), (('ted', 'cruz'), 9.977197628675324), (('prime', 'minist'), 9.882715930432095), (('sexual', 'assault'), 9.752825140046657), (('paul', 'ryan'), 9.515810764823435), (('illeg', 'alien'), 9.51235500544487), (('berni', 'sander'), 9.478932288702826), (('health', 'care'), 9.302446345320355), (('even', 'brief'), 9.291016682970678), (('live', 'matter'), 9.26025692525608), (('wall', 'street'), 9.023600004453623), (('suprem', 'court'), 8.95928182558021), (('america', 'finest'), 8.944092473450603), (('onion', 'america'), 8.879386784062788), (('plan', 'parenthood'), 8.873079313417595), (('climat', 'chang'), 8.814531220725353), (('travel', 'ban'), 8.76036117141862), (('north', 'korea'), 8.753905762140626), (('finest', 'news'), 8.604297957769727), (('north', 'carolina'), 8.535969878279218)]\n"
     ]
    }
   ],
   "source": [
    "print(len(bigram_features_pmi))\n",
    "print(bigram_pmi_scored[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b26410e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_featuresets = [(bigram_document_features(title, title_features, bigram_features_pmi), label) for (title, label) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe4fd5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pmi_bigram_featuresets' (list)\n"
     ]
    }
   ],
   "source": [
    "## Storing bigram featureset var in case kernel crashes\n",
    "# pmi_bigram_featuresets = bigram_featuresets\n",
    "# %store pmi_bigram_featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb18a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the combined unigram-bigram featureset to a CSV for future use\n",
    "bigram_featureset_df = pd.DataFrame(bigram_featuresets, columns=['features', 'label'])\n",
    "bigram_features_df = pd.DataFrame(bigram_featureset_df['features'].tolist())\n",
    "bigram_df_csv = pd.concat([bigram_features_df, bigram_featureset_df ['label']], axis=1)\n",
    "bigram_df_csv.to_csv('~/title_bigram_features_fakenews_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30153946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE DATASET IF NEEDED\n",
    "df = pd.read_csv('~/title_bigram_features_fakenews_df_canonical.csv')\n",
    "\n",
    "bigram_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = bigram_featuresets[(round(.30 * len(bigram_featuresets))):], bigram_featuresets[:(round(.30 * len(bigram_featuresets)))]\n",
    "\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93f8fa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660132273873531\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "25b38552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                W_hilari = True                1 : 0      =    187.1 : 1.0\n",
      "                   W_wow = True                1 : 0      =    162.3 : 1.0\n",
      "               W_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     W_… = True                1 : 0      =     95.7 : 1.0\n",
      "                W_awesom = True                1 : 0      =     64.6 : 1.0\n",
      "                 W_bundi = True                1 : 0      =     57.2 : 1.0\n",
      "                     W_! = True                1 : 0      =     56.9 : 1.0\n",
      "                 W_crook = True                1 : 0      =     53.9 : 1.0\n",
      "                  W_york = True                0 : 1      =     50.5 : 1.0\n",
      "               W_zimbabw = True                0 : 1      =     50.4 : 1.0\n",
      "             W_brilliant = True                1 : 0      =     49.6 : 1.0\n",
      "                 W_onion = True                1 : 0      =     49.2 : 1.0\n",
      "                W_finest = True                1 : 0      =     47.2 : 1.0\n",
      "                   W_oop = True                1 : 0      =     47.2 : 1.0\n",
      "               W_disgust = True                1 : 0      =     46.8 : 1.0\n",
      "             W_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "              W_bombshel = True                1 : 0      =     45.2 : 1.0\n",
      "                 W_mugab = True                0 : 1      =     44.8 : 1.0\n",
      "                 W_video = True                1 : 0      =     38.8 : 1.0\n",
      "                     W_– = True                1 : 0      =     37.6 : 1.0\n",
      "                W_reuter = True                0 : 1      =     36.2 : 1.0\n",
      "                W_antifa = True                1 : 0      =     35.8 : 1.0\n",
      "                   W_beg = True                1 : 0      =     33.8 : 1.0\n",
      "               W_mnuchin = True                0 : 1      =     33.5 : 1.0\n",
      "                  W_epic = True                1 : 0      =     32.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8bd2baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8677467703946898\n",
      "1 0.8661765755477839\n",
      "2 0.862679323388766\n",
      "3 0.8663193205338663\n",
      "4 0.8623938334166013\n",
      "mean accuracy 0.8650631646563415\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate mean accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, bigram_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4391995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8965>1593 |\n",
      "0 | 1223<9236>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.883      0.868      0.849\n",
      "1 \t      0.880      0.849      0.864      0.883\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49455112",
   "metadata": {},
   "source": [
    "<h3>Test 5 Discussion: Unigram + Bigram Features</h3>\n",
    "<br>\n",
    "<body>\n",
    "<b>Bigram features</b> were extracted with a filter applied to limit bigrams \n",
    "to alphabetic tokens with a length longer than two characters and a minimum frequency of 50 in the corpus. \n",
    "Bigrams were scored using PMI, but because the applied filters already yielded only 123 new bigram features, all of the bigrams were used, regardless of score.\n",
    "<br><br>\n",
    "Looking at the bigrams that we were able to extract from the dataset, we see that it is dominated by proper nouns\n",
    "--person and place names (e.g. Kellyann Conway, Puerto Rico).\n",
    "But there are also several that related to issues that relate directly to potentially \n",
    "politically divisive issues that might be predictive of real or fake news (e.g. 'planned parenthood', 'climate change', 'travel ban'). \n",
    "<br><br>\n",
    "Despite this, <b>adding bigram features did not ressult in an increase in accuracy over unigram features alone.</b>\n",
    "The reason for this becomes clear when looking at the <b>Most Informative Features</b>. \n",
    "Nearly all bigram features are at the very bottom of the list and have a probability ratio of 1.0:1.0.\n",
    "<br><br>\n",
    "<b>Because using a combined bigram/unigram featureset score did not improve accuracy, we did not use it in subsequent models.</b>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd809a",
   "metadata": {},
   "source": [
    "<h1>TEST 6: Combining Title Unigram Features with Text Bigram Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338bb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE PRE-PROCESSED DATASET IF NEEDED\n",
    "df_text = pd.read_csv('~/preprocessed_fakenews_df_canonical.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bdf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tuple of 'text' text, label for each row in the df\n",
    "tuple_rows = list(df_text.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4823ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_str = [(str(i[1]), i[2]) for i in tuple_rows]\n",
    "documents = [(i[0].split(\", \"), i[1]) for i in document_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d46052",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_list = [word for (text, cat) in documents for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97dc6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd1587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder.apply_word_filter(lambda w: len(w) < 2 or w.isalpha() is False)\n",
    "finder.apply_freq_filter(500)\n",
    "bigram_pmi_scored = finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46dd0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_features_pmi = [(bigram[0:2]) for (bigram, frequency) in bigram_pmi_scored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "932d3900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252\n",
      "[(('suu', 'kyi'), 15.184964546248196), (('hong', 'kong'), 14.362837007830269), (('shi', 'ite'), 14.144952002661626), (('bashar', 'alassad'), 14.034796390238103), (('silicon', 'valley'), 13.868011069448645), (('reinc', 'priebus'), 13.772902630077997), (('antonin', 'scalia'), 13.736691233340679), (('goldman', 'sach'), 13.72170144621688), (('lindsey', 'graham'), 13.538906023049897), (('kellyann', 'conway'), 13.490162402182875), (('emmanuel', 'macron'), 13.45574856202326), (('asylum', 'seeker'), 13.454465995624247), (('las', 'vega'), 13.437025695365268), (('chancellor', 'angela'), 13.427613012991703), (('nanci', 'pelosi'), 13.376580593519066), (('puerto', 'rico'), 13.33823133934973), (('julian', 'assang'), 13.326875166123205), (('xi', 'jinp'), 13.319535893650087), (('tayyip', 'erdogan'), 13.304951220853933), (('loretta', 'lynch'), 13.141165119993829), (('kim', 'jong'), 13.0006598466225), (('huma', 'abedin'), 12.992188087481754), (('palm', 'beach'), 12.896832257968185), (('jare', 'kushner'), 12.894483031984766), (('ronald', 'reagan'), 12.86962994455262), (('benjamin', 'netanyahu'), 12.850295460501926), (('mitch', 'mcconnel'), 12.825497322977593), (('mitt', 'romney'), 12.772406034539753), (('tim', 'kain'), 12.758743770527566), (('angela', 'merkel'), 12.667713084744314), (('ethnic', 'cleans'), 12.651746359423317), (('super', 'pac'), 12.609695552310807), (('chuck', 'schumer'), 12.564520316702989), (('rex', 'tillerson'), 12.495627652954802), (('pope', 'franci'), 12.448423346599423), (('st', 'loui'), 12.436331008828656), (('le', 'pen'), 12.429335985729995), (('fossil', 'fuel'), 12.42497384132934), (('nofli', 'zone'), 12.399606594692813), (('anthoni', 'weiner'), 12.363482510089735), (('elizabeth', 'warren'), 12.357589854017906), (('megyn', 'kelli'), 12.308680202321153), (('status', 'quo'), 12.28430360528358), (('los', 'angel'), 12.243631748739752), (('san', 'bernardino'), 12.216015031106831), (('sean', 'hanniti'), 12.150324713036856), (('samesex', 'marriag'), 12.128392993885804), (('san', 'diego'), 12.12402004260596), (('san', 'francisco'), 12.095994995654515), (('plead', 'guilti'), 12.088295364871747)]\n"
     ]
    }
   ],
   "source": [
    "print(len(bigram_features_pmi))\n",
    "print(bigram_pmi_scored[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f041fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_only_features(document, bigram_features): \n",
    "    document_bigrams = nltk.bigrams(document) \n",
    "    features = {}\n",
    "    for bigram in bigram_features:\n",
    "        features[f\"B_{bigram[0]}_{bigram[1]}\"] = (bigram in document_bigrams)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018cd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_featuresets = [(bigram_only_features(text, bigram_features_pmi), label) for (text, label) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "364b34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the combined unigram-bigram featureset to a CSV for future use\n",
    "bigram_featureset_df = pd.DataFrame(bigram_featuresets, columns=['features', 'label'])\n",
    "bigram_features_df = pd.DataFrame(bigram_featureset_df['features'].tolist())\n",
    "bigram_df_csv = pd.concat([bigram_features_df, bigram_featureset_df ['label']], axis=1)\n",
    "bigram_df_csv.to_csv('~/text_bigram_only_features_fakenews_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa4bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_bigrams = pd.read_csv('~/text_bigram_only_features_fakenews_df_canonical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "206c5324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_suu_kyi</th>\n",
       "      <th>B_hong_kong</th>\n",
       "      <th>B_shi_ite</th>\n",
       "      <th>B_bashar_alassad</th>\n",
       "      <th>B_silicon_valley</th>\n",
       "      <th>B_reinc_priebus</th>\n",
       "      <th>B_antonin_scalia</th>\n",
       "      <th>B_goldman_sach</th>\n",
       "      <th>B_lindsey_graham</th>\n",
       "      <th>B_kellyann_conway</th>\n",
       "      <th>...</th>\n",
       "      <th>B_us_not</th>\n",
       "      <th>B_state_said</th>\n",
       "      <th>B_trump_clinton</th>\n",
       "      <th>B_said_like</th>\n",
       "      <th>B_one_trump</th>\n",
       "      <th>B_state_trump</th>\n",
       "      <th>B_not_trump</th>\n",
       "      <th>B_trump_trump</th>\n",
       "      <th>B_said_said</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B_suu_kyi  B_hong_kong  B_shi_ite  B_bashar_alassad  B_silicon_valley  \\\n",
       "0      False        False      False             False             False   \n",
       "1      False        False      False             False             False   \n",
       "2      False        False      False             False             False   \n",
       "3      False        False      False             False             False   \n",
       "4      False        False      False             False             False   \n",
       "\n",
       "   B_reinc_priebus  B_antonin_scalia  B_goldman_sach  B_lindsey_graham  \\\n",
       "0            False             False           False             False   \n",
       "1            False             False           False             False   \n",
       "2            False             False           False             False   \n",
       "3            False             False           False             False   \n",
       "4            False             False           False             False   \n",
       "\n",
       "   B_kellyann_conway  ...  B_us_not  B_state_said  B_trump_clinton  \\\n",
       "0              False  ...     False         False            False   \n",
       "1              False  ...     False         False            False   \n",
       "2              False  ...     False         False            False   \n",
       "3              False  ...     False         False            False   \n",
       "4              False  ...     False         False            False   \n",
       "\n",
       "   B_said_like  B_one_trump  B_state_trump  B_not_trump  B_trump_trump  \\\n",
       "0        False        False          False        False          False   \n",
       "1        False        False          False        False          False   \n",
       "2        False        False          False        False          False   \n",
       "3        False        False          False        False          False   \n",
       "4        False        False          False        False          False   \n",
       "\n",
       "   B_said_said  label  \n",
       "0        False      1  \n",
       "1        False      1  \n",
       "2        False      1  \n",
       "3        False      1  \n",
       "4        False      0  \n",
       "\n",
       "[5 rows x 1253 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2584c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_unigrams = pd.read_csv('~/title_unigram_features_fakenews_df_canonical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c8d6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_label = df_title_unigrams.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65a6df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_uni_text_bi_df = pd.concat([df_title_unigrams, df_text_bigrams], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9455fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_uni_text_bi_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in title_uni_text_bi_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f30498de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = title_uni_text_bi_featuresets[(round(.30 * len(title_uni_text_bi_featuresets))):], title_uni_text_bi_featuresets[:(round(.30 * len(title_uni_text_bi_featuresets)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ed642c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0950d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6648bacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865965646857306\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "656c589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                V_hilari = True                1 : 0      =    187.1 : 1.0\n",
      "                   V_wow = True                1 : 0      =    162.3 : 1.0\n",
      "               V_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     V_… = True                1 : 0      =     95.7 : 1.0\n",
      "               B_suu_kyi = True                0 : 1      =     94.6 : 1.0\n",
      "                V_awesom = True                1 : 0      =     64.6 : 1.0\n",
      "                 V_bundi = True                1 : 0      =     57.2 : 1.0\n",
      "                     V_! = True                1 : 0      =     56.9 : 1.0\n",
      "                 V_crook = True                1 : 0      =     53.9 : 1.0\n",
      "                  V_york = True                0 : 1      =     50.5 : 1.0\n",
      "               V_zimbabw = True                0 : 1      =     50.4 : 1.0\n",
      "             V_brilliant = True                1 : 0      =     49.6 : 1.0\n",
      "                 V_onion = True                1 : 0      =     49.2 : 1.0\n",
      "                V_finest = True                1 : 0      =     47.2 : 1.0\n",
      "                   V_oop = True                1 : 0      =     47.2 : 1.0\n",
      "               V_disgust = True                1 : 0      =     46.8 : 1.0\n",
      "             V_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "              V_bombshel = True                1 : 0      =     45.2 : 1.0\n",
      "                 V_mugab = True                0 : 1      =     44.8 : 1.0\n",
      "                 V_video = True                1 : 0      =     38.8 : 1.0\n",
      "                     V_– = True                1 : 0      =     37.6 : 1.0\n",
      "                V_reuter = True                0 : 1      =     36.2 : 1.0\n",
      "                V_antifa = True                1 : 0      =     35.8 : 1.0\n",
      "                   V_beg = True                1 : 0      =     33.8 : 1.0\n",
      "               V_mnuchin = True                0 : 1      =     33.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NBclassifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08a76672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8676040254086075\n",
      "1 0.8661765755477839\n",
      "2 0.862679323388766\n",
      "3 0.866247948040825\n",
      "4 0.8628934408678895\n",
      "mean accuracy 0.8651202626507744\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate mean accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_uni_text_bi_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62620a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8968>1590 |\n",
      "0 | 1227<9232>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.883      0.868      0.849\n",
      "1 \t      0.880      0.849      0.864      0.883\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e72f8",
   "metadata": {},
   "source": [
    "<h1>TEST 7: Combining Unigram and Trigram Features (Title Only)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29cb4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_document_features(document, word_features, trigram_features): \n",
    "    document_words = set(document) \n",
    "    document_trigrams = nltk.trigrams(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f\"W_{word}\"] = (word in document_words)\n",
    "    for trigram in trigram_features:\n",
    "        features[f\"T_{trigram[0]}_{trigram[1]}_{trigram[2]}\"] = (trigram in document_trigrams)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bea63ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scored using PMI with freq filter 25, filtering out words shorter than 2 char and punctuation:\n",
      "\n",
      "(('tresa', 'balda', 'tbalda'), 39.412388286891385)\n",
      "(('httpstwittercomlukewearechang', 'nstagram', 'httpinstagramcomlukewearechang'), 38.395415208287666)\n",
      "(('lukewearechang', 'fbook', 'httpsfacebookcomlukewearechang'), 38.32697415218579)\n",
      "(('пак', 'кын', 'хе'), 37.79374214689376)\n",
      "(('boldital', 'textememphas', 'textem'), 37.357426814047166)\n",
      "(('leasta', 'hrefhttplinkaddresscomnam', 'linka'), 37.357426814047166)\n",
      "(('bradd', 'jaffi', 'braddjaffi'), 36.68128429357141)\n",
      "(('bess', 'kalb', 'bessbel'), 36.44070590952366)\n",
      "(('читайте', 'последние', 'новости'), 36.28807699945452)\n",
      "(('alexandra', 'meador', 'wwwgalacticconnectioncom'), 36.176190066029896)\n",
      "(('degrass', 'tyson', 'neiltyson'), 35.11857500292884)\n",
      "(('snapchat', 'lukewearechang', 'fbook'), 34.997053266544896)\n",
      "(('juanita', 'broaddrick', 'atensnut'), 34.94560287479281)\n",
      "(('lauren', 'duca', 'laurenduca'), 34.696365394304266)\n",
      "(('kyaw', 'soe', 'oo'), 34.68278019317627)\n",
      "(('patton', 'oswalt', 'pattonoswalt'), 34.62364904300112)\n",
      "(('simon', 'hedlin', 'simonhedlin'), 34.40972304497154)\n",
      "(('daphn', 'caruana', 'galizia'), 34.322316593138275)\n",
      "(('troubadour', 'sail', 'hibiscus'), 34.201106796361984)\n",
      "(('kristina', 'wong', 'mskristinawong'), 34.03570417274045)\n",
      "(('erick', 'fernandez', 'erickfernandez'), 34.00510795030519)\n",
      "(('catherin', 'cortez', 'masto'), 33.933659718545826)\n",
      "(('ho', 'chi', 'minh'), 33.81948900357701)\n",
      "(('comet', 'ping', 'pong'), 33.8125056563011)\n",
      "(('luigi', 'di', 'maio'), 33.57742176578371)\n",
      "(('последние', 'новости', 'pravdaru'), 33.47312607242053)\n",
      "(('matt', 'haig', 'matthaig'), 33.42017897607139)\n",
      "(('aed', 'aegypti', 'mosquito'), 33.32460055756273)\n",
      "(('doc', 'burkhart', 'vicepresid'), 33.322956791652295)\n",
      "(('abdrabbu', 'mansour', 'hadi'), 33.31632933768411)\n"
     ]
    }
   ],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = TrigramCollocationFinder.from_words(all_words_list)\n",
    "finder.apply_word_filter(lambda w: len(w) < 2 or w.isalpha() is False)\n",
    "finder.apply_freq_filter(25)\n",
    "scored = finder.score_ngrams(trigram_measures.pmi)\n",
    "print(\"\\nScored using PMI with freq filter 25, filtering out words shorter than 2 char and punctuation:\\n\")\n",
    "for tscore in scored[:30]:\n",
    "    print(tscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68e5c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_features_pmi = [(trigram[0:3]) for (trigram, frequency) in scored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "26f227ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_featuresets = [(trigram_document_features(title, title_features, trigram_features_pmi), label) for (title, label) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f1adb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the combined unigram-trigram featureset to a CSV for future use\n",
    "trigram_featureset_df = pd.DataFrame(trigram_featuresets, columns=['features', 'label'])\n",
    "trigram_features_df = pd.DataFrame(trigram_featureset_df['features'].tolist())\n",
    "trigram_df_csv = pd.concat([trigram_features_df, trigram_featureset_df ['label']], axis=1)\n",
    "trigram_df_csv.to_csv('~/title_trigram_features_fakenews_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61bf4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_trigram_df = pd.read_csv('~/title_trigram_features_fakenews_df_canonical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93ddc22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_trump</th>\n",
       "      <th>W_new</th>\n",
       "      <th>W_video</th>\n",
       "      <th>W_time</th>\n",
       "      <th>W_york</th>\n",
       "      <th>W_us</th>\n",
       "      <th>W_say</th>\n",
       "      <th>W_!</th>\n",
       "      <th>W_hillari</th>\n",
       "      <th>W_obama</th>\n",
       "      <th>...</th>\n",
       "      <th>B_trump_hillari_clinton</th>\n",
       "      <th>B_say_donald_trump</th>\n",
       "      <th>B_york_time_new</th>\n",
       "      <th>B_york_time_video</th>\n",
       "      <th>B_donald_trump_video</th>\n",
       "      <th>B_trump_new_york</th>\n",
       "      <th>B_time_new_york</th>\n",
       "      <th>B_video_trump_say</th>\n",
       "      <th>B_time_trump_say</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70051</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70052</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70053</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70054</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70055</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70056 rows × 3989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       W_trump  W_new  W_video  W_time  W_york   W_us  W_say    W_!  \\\n",
       "0        False  False    False   False   False  False  False  False   \n",
       "1        False  False    False   False   False  False  False  False   \n",
       "2        False  False    False   False   False  False  False  False   \n",
       "3        False   True    False   False   False  False  False  False   \n",
       "4        False  False    False   False   False  False  False  False   \n",
       "...        ...    ...      ...     ...     ...    ...    ...    ...   \n",
       "70051     True  False    False   False   False  False  False  False   \n",
       "70052    False  False    False   False   False  False  False  False   \n",
       "70053    False  False     True    True   False  False  False   True   \n",
       "70054    False  False    False   False   False  False  False  False   \n",
       "70055     True  False    False   False   False  False  False   True   \n",
       "\n",
       "       W_hillari  W_obama  ...  B_trump_hillari_clinton  B_say_donald_trump  \\\n",
       "0          False    False  ...                    False               False   \n",
       "1          False    False  ...                    False               False   \n",
       "2          False    False  ...                    False               False   \n",
       "3          False    False  ...                    False               False   \n",
       "4          False    False  ...                    False               False   \n",
       "...          ...      ...  ...                      ...                 ...   \n",
       "70051      False    False  ...                    False               False   \n",
       "70052      False    False  ...                    False               False   \n",
       "70053      False    False  ...                    False               False   \n",
       "70054      False    False  ...                    False               False   \n",
       "70055      False    False  ...                    False               False   \n",
       "\n",
       "       B_york_time_new  B_york_time_video  B_donald_trump_video  \\\n",
       "0                False              False                 False   \n",
       "1                False              False                 False   \n",
       "2                False              False                 False   \n",
       "3                False              False                 False   \n",
       "4                False              False                 False   \n",
       "...                ...                ...                   ...   \n",
       "70051            False              False                 False   \n",
       "70052            False              False                 False   \n",
       "70053            False              False                 False   \n",
       "70054            False              False                 False   \n",
       "70055            False              False                 False   \n",
       "\n",
       "       B_trump_new_york  B_time_new_york  B_video_trump_say  B_time_trump_say  \\\n",
       "0                 False            False              False             False   \n",
       "1                 False            False              False             False   \n",
       "2                 False            False              False             False   \n",
       "3                 False            False              False             False   \n",
       "4                 False            False              False             False   \n",
       "...                 ...              ...                ...               ...   \n",
       "70051             False            False              False             False   \n",
       "70052             False            False              False             False   \n",
       "70053             False            False              False             False   \n",
       "70054             False            False              False             False   \n",
       "70055             False            False              False             False   \n",
       "\n",
       "       label  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          0  \n",
       "...      ...  \n",
       "70051      1  \n",
       "70052      0  \n",
       "70053      1  \n",
       "70054      0  \n",
       "70055      1  \n",
       "\n",
       "[70056 rows x 3989 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_trigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a6d56aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in uni_trigram_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "47caa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = trigram_featuresets[(round(.30 * len(trigram_featuresets))):], trigram_featuresets[:(round(.30 * len(trigram_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1ff14e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660132273873531\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5a31b7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                W_hilari = True                1 : 0      =    187.1 : 1.0\n",
      "                   W_wow = True                1 : 0      =    162.3 : 1.0\n",
      "               W_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     W_… = True                1 : 0      =     95.7 : 1.0\n",
      "                W_awesom = True                1 : 0      =     64.6 : 1.0\n",
      "                 W_bundi = True                1 : 0      =     57.2 : 1.0\n",
      "                     W_! = True                1 : 0      =     56.9 : 1.0\n",
      "                 W_crook = True                1 : 0      =     53.9 : 1.0\n",
      "                  W_york = True                0 : 1      =     50.5 : 1.0\n",
      "               W_zimbabw = True                0 : 1      =     50.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ef89e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B_новое_восточное_обозрение', False)]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'classifier' is your trained Naive Bayes classifier\n",
    "most_informative_features = classifier.most_informative_features(5000)\n",
    "\n",
    "# Convert the list of tuples to a list of features\n",
    "features = [(feature, score) for (feature, score) in most_informative_features if re.match(r'^B_', feature)]\n",
    "\n",
    "#b_features = [feature for feature in features if re.findall(r'^[B_]*', feature)]\n",
    "\n",
    "# Print the list of features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c3197088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8676040254086075\n",
      "1 0.8661765755477839\n",
      "2 0.862679323388766\n",
      "3 0.866247948040825\n",
      "4 0.8628934408678895\n",
      "mean accuracy 0.8651202626507744\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate mean accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, title_uni_text_bi_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7f90d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8967>1591 |\n",
      "0 | 1225<9234>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.883      0.868      0.849\n",
      "1 \t      0.880      0.849      0.864      0.883\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8fb4e",
   "metadata": {},
   "source": [
    "<h3>Test 7 Discussion: Unigram + Trigram Features</h3>\n",
    "<br>\n",
    "<body>\n",
    "<b>Trigram features</b> were extracted with a filter applied to limit bigrams \n",
    "to alphabetic tokens with a length longer than two characters and a minimum frequency of 50 in the corpus. \n",
    "Trigrams were scored using PMI, but because the applied filters already yielded only 122 new, trigram features, all of the trigrams were used, regardless of score.\n",
    "<br><br>\n",
    "Looking at the trigrams that we were able to extract from the dataset, we are getting a bit more context than we were with bigrams.\n",
    "    For instance, \"Puerto Rico\" becomes <b>\"Puerto Rican Debt\"</b> and \"Lives Matter\" becomes <b>\"Black Lives Matter\"</b>. \n",
    "    Other newsworthy items also appear in the list, such as <b>\"Dakota Access Pipeline\"</b> and <b>\"Voter ID Law\"</b>.\n",
    "<br><br>\n",
    "    It's intesting to note that the most common trigram is <b>'новое восточное обозрение'</b>, which translates to <b>\"New Eastern Outlook\"</b> (also in the  top-scoring list of trigrams). This is the name of a Russia-based online journal that has come to be associated with fakenews and was identified by the U.S. Dept. of State as part of \"Russia's disinformation and propaganda system\" in 2020.\n",
    "<br><br>\n",
    "Despite the additional context, <b>combining trigram features and unigram also did not ressult in an increase in accuracy over unigram features alone.</b>\n",
    "The reason for this again becomes clear when looking at the <b>Most Informative Features</b>. \n",
    "As with the bigram features, all trigram features are at the very bottom of the list and have a probability ratio of 1.0:1.0.\n",
    "<br><br>\n",
    "<b>Because using a combined trigram/unigram featureset did not improve accuracy of the unigram baseline, we did not use it in subsequent models.</b>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e4dda",
   "metadata": {},
   "source": [
    "<h1>Test 8: Combining Sentiment and Unigram Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483f1f84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokens_df = pd.read_csv('~/preprocessed_fakenews_df_canonical.csv', \n",
    "                 #index_col='index', \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582df699",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_rows = list(tokens_df.itertuples(index=False, name=None))\n",
    "document_str = [(str(i[0]), i[2]) for i in tuple_rows]\n",
    "documents = [(i[0].split(\", \"), i[1]) for i in document_str]\n",
    "\n",
    "\n",
    "#title_featuresets = [(unigram_features(title, title_features), cat) for (title, cat) in documents]\n",
    "\n",
    "all_words_list = [word for (title, cat) in documents for word in title]\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "word_items = all_words.most_common(round((len(all_words) * 0.15)))\n",
    "\n",
    "title_features = [word for (word,count) in word_items]\n",
    "\n",
    "stemmer = nltk.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34be664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-face', 'abnorm', 'abolish', 'abomin', 'abort']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD THE NEGATIVE SENTIMENT LEXICON AND STEM IT USING THE SAME STEMMER AS APPLIED TO THE CORPUS\n",
    "\n",
    "df_neg = pd.read_csv('~/*/IST664/FINAL_PROJECT/SENTIMENT/negative-words.txt',\n",
    "                 names=['neg_words'])\n",
    "\n",
    "neg_lex = sorted(set([stemmer.stem(word) for word in list(df_neg.neg_words)]))\n",
    "\n",
    "neg_lex[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681c2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE POSITIVE SENTIMENT LEXICON AND STEM IT USING THE SAME STEMMER AS APPLIED TO THE CORPUS\n",
    "\n",
    "df_pos = pd.read_csv('~/*/IST664/FINAL_PROJECT/SENTIMENT/positive-words.txt',\n",
    "                 skiprows=1,\n",
    "                 names=['pos_words'])\n",
    "\n",
    "pos_lex = sorted(set([stemmer.stem(word) for word in list(df_pos.pos_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f2ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abound', 'abund', 'access', 'acclaim', 'acclam']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lex[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d80162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PosNeg_features(document, pos_lex, neg_lex):\n",
    "    \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for word in document_words:\n",
    "        if word in pos_lex:\n",
    "            pos_count += 1\n",
    "                \n",
    "        if word in neg_lex:\n",
    "            neg_count += 1\n",
    "        \n",
    "        features['positivecount'] = pos_count\n",
    "        features['negativecount'] = neg_count\n",
    "    \n",
    "    for word in title_features:\n",
    "        features[f'W_{word}'] = (word in document_words)\n",
    "                \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0d1e4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosNeg_featuresets = [(PosNeg_features(doc, pos_lex, neg_lex), label) for (doc, label) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1873bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and sentiment score:0.8643954893657515\n",
      "\n",
      "Execution time: 159.67037630081177 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = PosNeg_featuresets[(round(.30 * len(PosNeg_featuresets))):], PosNeg_featuresets[:(round(.30 * len(PosNeg_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "print(f\"Accuracy with combined unigram and sentiment score:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b41d950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                W_hilari = True                1 : 0      =    187.1 : 1.0\n",
      "                   W_wow = True                1 : 0      =    162.3 : 1.0\n",
      "               W_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     W_… = True                1 : 0      =     95.7 : 1.0\n",
      "                W_awesom = True                1 : 0      =     64.6 : 1.0\n",
      "                 W_bundi = True                1 : 0      =     57.2 : 1.0\n",
      "                     W_! = True                1 : 0      =     56.9 : 1.0\n",
      "                 W_crook = True                1 : 0      =     53.9 : 1.0\n",
      "                  W_york = True                0 : 1      =     50.5 : 1.0\n",
      "               W_zimbabw = True                0 : 1      =     50.4 : 1.0\n",
      "             W_brilliant = True                1 : 0      =     49.6 : 1.0\n",
      "                 W_onion = True                1 : 0      =     49.2 : 1.0\n",
      "                W_finest = True                1 : 0      =     47.2 : 1.0\n",
      "                   W_oop = True                1 : 0      =     47.2 : 1.0\n",
      "               W_disgust = True                1 : 0      =     46.8 : 1.0\n",
      "             W_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "              W_bombshel = True                1 : 0      =     45.2 : 1.0\n",
      "                 W_mugab = True                0 : 1      =     44.8 : 1.0\n",
      "                 W_video = True                1 : 0      =     38.8 : 1.0\n",
      "                     W_– = True                1 : 0      =     37.6 : 1.0\n",
      "                W_reuter = True                0 : 1      =     36.2 : 1.0\n",
      "                W_antifa = True                1 : 0      =     35.8 : 1.0\n",
      "                   W_beg = True                1 : 0      =     33.8 : 1.0\n",
      "               W_mnuchin = True                0 : 1      =     33.5 : 1.0\n",
      "                  W_epic = True                1 : 0      =     32.8 : 1.0\n",
      "                 W_laugh = True                1 : 0      =     32.6 : 1.0\n",
      "                  W_damn = True                1 : 0      =     32.5 : 1.0\n",
      "             W_hypocrisi = True                1 : 0      =     32.5 : 1.0\n",
      "                   W_a** = True                1 : 0      =     31.8 : 1.0\n",
      "       W_#blacklivesmatt = True                1 : 0      =     31.1 : 1.0\n",
      "                  W_thug = True                1 : 0      =     30.3 : 1.0\n",
      "                 W_gonna = True                1 : 0      =     29.8 : 1.0\n",
      "                 W_insan = True                1 : 0      =     29.1 : 1.0\n",
      "               W_furious = True                1 : 0      =     28.7 : 1.0\n",
      "                  W_sh*t = True                1 : 0      =     27.9 : 1.0\n",
      "                W_unreal = True                1 : 0      =     27.8 : 1.0\n",
      "                    W_xi = True                0 : 1      =     26.6 : 1.0\n",
      "              W_undercov = True                1 : 0      =     26.4 : 1.0\n",
      "                 W_youll = True                1 : 0      =     26.4 : 1.0\n",
      "                 W_smack = True                1 : 0      =     25.1 : 1.0\n",
      "               W_baghdad = True                0 : 1      =     24.2 : 1.0\n",
      "                 W_envoy = True                0 : 1      =     24.2 : 1.0\n",
      "             W_halloween = True                1 : 0      =     23.9 : 1.0\n",
      "                W_macron = True                0 : 1      =     23.8 : 1.0\n",
      "                   W_mic = True                1 : 0      =     23.8 : 1.0\n",
      "                    W_en = True                1 : 0      =     23.1 : 1.0\n",
      "                  W_seth = True                1 : 0      =     23.1 : 1.0\n",
      "               W_tantrum = True                1 : 0      =     22.4 : 1.0\n",
      "               W_somalia = True                0 : 1      =     22.2 : 1.0\n",
      "              W_cambodia = True                0 : 1      =     21.6 : 1.0\n",
      "                   W_rio = True                0 : 1      =     21.6 : 1.0\n",
      "                  W_brag = True                1 : 0      =     21.5 : 1.0\n",
      "                 W_viral = True                1 : 0      =     21.4 : 1.0\n",
      "                W_hyster = True                1 : 0      =     21.1 : 1.0\n",
      "                W_pathet = True                1 : 0      =     21.1 : 1.0\n",
      "                 W_shred = True                1 : 0      =     21.1 : 1.0\n",
      "                 W_expos = True                1 : 0      =     20.7 : 1.0\n",
      "              W_sanction = True                0 : 1      =     20.3 : 1.0\n",
      "                 W_idiot = True                1 : 0      =     20.3 : 1.0\n",
      "                 W_liter = True                1 : 0      =     20.2 : 1.0\n",
      "                W_bizarr = True                1 : 0      =     19.9 : 1.0\n",
      "                 W_czech = True                0 : 1      =     19.6 : 1.0\n",
      "                W_soccer = True                0 : 1      =     19.6 : 1.0\n",
      "               W_kremlin = True                0 : 1      =     19.1 : 1.0\n",
      "                W_tucker = True                1 : 0      =     19.1 : 1.0\n",
      "               W_ireland = True                0 : 1      =     18.9 : 1.0\n",
      "               W_septemb = True                0 : 1      =     18.9 : 1.0\n",
      "              W_farright = True                0 : 1      =     18.9 : 1.0\n",
      "                W_scream = True                1 : 0      =     18.7 : 1.0\n",
      "              W_hypocrit = True                1 : 0      =     18.5 : 1.0\n",
      "          W_antiamerican = True                1 : 0      =     18.4 : 1.0\n",
      "                 W_scath = True                1 : 0      =     18.4 : 1.0\n",
      "            W_disrespect = True                1 : 0      =     18.3 : 1.0\n",
      "                   W_kkk = True                1 : 0      =     18.3 : 1.0\n",
      "             W_tillerson = True                0 : 1      =     18.2 : 1.0\n",
      "               W_dumbest = True                1 : 0      =     17.7 : 1.0\n",
      "                 W_satan = True                1 : 0      =     17.7 : 1.0\n",
      "                W_incred = True                1 : 0      =     17.5 : 1.0\n",
      "                 W_egypt = True                0 : 1      =     17.4 : 1.0\n",
      "            W_girlfriend = True                1 : 0      =     17.1 : 1.0\n",
      "                   W_hed = True                1 : 0      =     17.1 : 1.0\n",
      "                  W_ouch = True                1 : 0      =     17.1 : 1.0\n",
      "              W_pedophil = True                1 : 0      =     17.1 : 1.0\n",
      "                W_predat = True                1 : 0      =     17.1 : 1.0\n",
      "                  W_quot = True                1 : 0      =     17.1 : 1.0\n",
      "                    W_pm = True                0 : 1      =     16.6 : 1.0\n",
      "                 W_freak = True                1 : 0      =     16.5 : 1.0\n",
      "               W_birther = True                1 : 0      =     16.4 : 1.0\n",
      "            W_napolitano = True                1 : 0      =     16.4 : 1.0\n",
      "                 W_roast = True                1 : 0      =     16.4 : 1.0\n",
      "                  W_rudi = True                1 : 0      =     16.4 : 1.0\n",
      "                W_thread = True                1 : 0      =     16.4 : 1.0\n",
      "                   W_abe = True                0 : 1      =     16.4 : 1.0\n",
      "                W_brutal = True                1 : 0      =     16.3 : 1.0\n",
      "                   W_feb = True                0 : 1      =     16.3 : 1.0\n",
      "                 W_polar = True                0 : 1      =     16.3 : 1.0\n",
      "                 W_screw = True                1 : 0      =     16.3 : 1.0\n",
      "                   W_kid = True                1 : 0      =     16.2 : 1.0\n",
      "               W_vicious = True                1 : 0      =     15.7 : 1.0\n",
      "              W_thailand = True                0 : 1      =     15.6 : 1.0\n",
      "               W_kurdish = True                0 : 1      =     15.5 : 1.0\n",
      "                  W_trey = True                1 : 0      =     15.5 : 1.0\n",
      "               W_perfect = True                1 : 0      =     15.4 : 1.0\n",
      "                W_rapist = True                1 : 0      =     15.3 : 1.0\n",
      "                   W_eus = True                0 : 1      =     15.3 : 1.0\n",
      "              W_watchdog = True                0 : 1      =     15.2 : 1.0\n",
      "                    W_fl = True                1 : 0      =     15.1 : 1.0\n",
      "                  W_okay = True                1 : 0      =     15.1 : 1.0\n",
      "           W_supremacist = True                1 : 0      =     15.1 : 1.0\n",
      "                    W_tx = True                1 : 0      =     15.1 : 1.0\n",
      "                W_humili = True                1 : 0      =     15.1 : 1.0\n",
      "                  W_boko = True                0 : 1      =     14.9 : 1.0\n",
      "                 W_haram = True                0 : 1      =     14.9 : 1.0\n",
      "                  W_irma = True                0 : 1      =     14.8 : 1.0\n",
      "                  W_rant = True                1 : 0      =     14.8 : 1.0\n",
      "                   W_doj = True                1 : 0      =     14.7 : 1.0\n",
      "               W_patrick = True                1 : 0      =     14.7 : 1.0\n",
      "                  W_loom = True                0 : 1      =     14.7 : 1.0\n",
      "             W_embarrass = True                1 : 0      =     14.5 : 1.0\n",
      "                 W_nafta = True                0 : 1      =     14.5 : 1.0\n",
      "                   W_blm = True                1 : 0      =     14.4 : 1.0\n",
      "                W_implod = True                1 : 0      =     14.4 : 1.0\n",
      "                W_skewer = True                1 : 0      =     14.4 : 1.0\n",
      "                  W_suck = True                1 : 0      =     14.4 : 1.0\n",
      "                 W_weird = True                1 : 0      =     14.4 : 1.0\n",
      "                 W_decri = True                0 : 1      =     14.3 : 1.0\n",
      "                  W_fate = True                0 : 1      =     14.3 : 1.0\n",
      "            W_postbrexit = True                0 : 1      =     14.3 : 1.0\n",
      "                  W_stun = True                1 : 0      =     14.2 : 1.0\n",
      "             W_flashback = True                1 : 0      =     14.0 : 1.0\n",
      "                 W_bigot = True                1 : 0      =     13.9 : 1.0\n",
      "               W_pension = True                0 : 1      =     13.7 : 1.0\n",
      "                 W_arrog = True                1 : 0      =     13.7 : 1.0\n",
      "                 W_commi = True                1 : 0      =     13.7 : 1.0\n",
      "                W_costum = True                1 : 0      =     13.7 : 1.0\n",
      "                 W_cough = True                1 : 0      =     13.7 : 1.0\n",
      "                W_surfac = True                1 : 0      =     13.7 : 1.0\n",
      "                    W_ca = True                1 : 0      =     13.6 : 1.0\n",
      "                   W_edt = True                0 : 1      =     13.6 : 1.0\n",
      "                 W_pursu = True                0 : 1      =     13.6 : 1.0\n",
      "                 W_spain = True                0 : 1      =     13.6 : 1.0\n",
      "           negativecount = 6                   1 : 0      =     13.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NBclassifier.show_most_informative_features(142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a6bd23d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8655342231104133\n",
      "1 0.865462850617372\n",
      "2 0.8604667761044893\n",
      "3 0.8670330454642781\n",
      "4 0.8614659910070659\n",
      "mean accuracy 0.8639925772607236\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, PosNeg_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "53fe493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PosNeg_Boolean_features(document, pos_lex, neg_lex):\n",
    "    \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for word in document_words:\n",
    "        if word in pos_lex:\n",
    "            pos_count += 1         \n",
    "            \n",
    "        if pos_count >= 2:\n",
    "            positive = True            \n",
    "        else:\n",
    "            positive = False\n",
    "            \n",
    "                \n",
    "        if word in neg_lex:\n",
    "            neg_count += 1\n",
    "            \n",
    "        if neg_count >=2:\n",
    "            negative = True           \n",
    "        else:\n",
    "            negative = False\n",
    "        \n",
    "        features['strong_positive'] = positive\n",
    "        features['strong_negative'] = negative\n",
    "    \n",
    "    for word in title_features:\n",
    "        features[f'W_{word}'] = (word in document_words)\n",
    "                \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0c49164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosNeg_Boolean_featuresets = [(PosNeg_Boolean_features(doc, pos_lex, neg_lex), label) for (doc, label) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f225d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpinionBool_df = pd.read_csv('~/boolean_opinion_features_fakenews_df_canonical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "51385b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_unigrams = pd.read_csv('~/title_unigram_features_fakenews_df_canonical.csv')\n",
    "remove_label = df_title_unigrams.pop('label')\n",
    "unigram_OpinionBool_df = pd.concat([df_title_unigrams, OpinionBool_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9836f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_OpinionBool_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in unigram_OpinionBool_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dba3ba2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and sentiment score:0.8652043583765523\n",
      "\n",
      "Execution time: 120.026606798172 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = unigram_OpinionBool_featuresets[(round(.30 * len(unigram_OpinionBool_featuresets))):], unigram_OpinionBool_featuresets[:(round(.30 * len(unigram_OpinionBool_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "print(f\"Accuracy with combined unigram and sentiment score:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9d3f9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.866604810506031\n",
      "1 0.8665334380129898\n",
      "2 0.8621797159374777\n",
      "3 0.8659624580686603\n",
      "4 0.8629648133609307\n",
      "mean accuracy 0.8648490471772179\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, unigram_OpinionBool_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f25bff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8925>1633 |\n",
      "0 | 1200<9259>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.850      0.885      0.867      0.845\n",
      "1 \t      0.881      0.845      0.863      0.885\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985e1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51982b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StrongOpinion_features(document, pos_lex, neg_lex):  \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    pos_count = 0\n",
    "    neg_count = 0   \n",
    "    for word in document_words:\n",
    "        if word in pos_lex:\n",
    "            pos_count += 1                       \n",
    "        if word in neg_lex:\n",
    "            neg_count += 1       \n",
    "        if pos_count + neg_count >= 2:\n",
    "            opinion_strength = True             \n",
    "        else:\n",
    "            opinion_strength = False       \n",
    "        features['strong_opinion'] = opinion_strength    \n",
    "    for word in title_features:\n",
    "        features[f'W_{word}'] = (word in document_words)\n",
    "                \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb62b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "StrongOpinion_featuresets = [(StrongOpinion_features(doc, pos_lex, neg_lex), label) for (doc, label) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7861a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and opinion strength score:0.865061616786411\n",
      "\n",
      "Execution time: 161.1317481994629 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = StrongOpinion_featuresets[(round(.30 * len(StrongOpinion_featuresets))):], StrongOpinion_featuresets[:(round(.30 * len(StrongOpinion_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "print(f\"Accuracy with combined unigram and opinion strength score:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, PosNeg_Boolean_featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85033d5",
   "metadata": {},
   "source": [
    "<h3>Test 8 Discussion: Opinion Sentiment Lexicon and Unigram Featureset</h3>\n",
    "    <br>\n",
    "    <body>\n",
    "    <b>Hypothesis:</b> Fakenews will be more strongly associated with a higher use of emotinally charged language whether negative or positive.\n",
    "    <br><br>\n",
    "    To perform sentiment analysis, we used <b>Bing Liu's Opinion Lexicon*</b>. We selected this lexicon because it was an unscored binary lexicon, so we were able to stem the lexicon entries without having to handle different scores belonging to multiple words that share a common stem. \n",
    "    <br><br>Adding sentiment-based features to unigrams in our featureset did not improve accuracy using the NLTK NB Classifier. In fact, <b>it fell slightly, from 86.6 to 86.5</b>. \n",
    "Although there was some assoication between <b>higher scores in both the positive and (more strongly) the negative category for fakenews</b>, in the <b>Most Important Featuers</b> index, the highest rank -- a negative count of 6 -- rates only 143rd, so they did not affect the model significantly.\n",
    "    <br><br>Modifying the evaluation method in our feature extraction function from a count to a <b>boolean \"strong\" positive or negative</b> based on a <b>>=2 count threshold</b> gave better results. This finding makes sense in the context of fakenews evaluation, because this allows the evaluation to focus simply on strongly emotionally charged language, rather than particular discrete counts.  \n",
    "<br><br>Further simplifying the opinion feature to simplpy reflect whether the sum of the count of positive and negative for a given document was >= 2 slightly reduced accuracy.\n",
    "<br><br>\n",
    "* Citation:\n",
    "    This lexicon was first published by Bing Liu in conjunction with: Minqing Hu and Bing Liu, ``Mining and summarizing customer reviews.'', Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD-2004), Seattle, Washington, USA, Aug 22-25, 2004.\n",
    "    </body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64b37c",
   "metadata": {},
   "source": [
    "<h3>Export Boolean Opinion Features Only (Pos/Neg) Features to CSV for Future Use</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac24dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_opinion_only_features(document, pos_lex, neg_lex):   \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    pos_count = 0\n",
    "    neg_count = 0  \n",
    "    for word in document_words:\n",
    "        if word in pos_lex:\n",
    "            pos_count += 1                     \n",
    "        if pos_count >= 2:\n",
    "            positive = True            \n",
    "        else:\n",
    "            positive = False \n",
    "            \n",
    "        if word in neg_lex:\n",
    "            neg_count += 1      \n",
    "        if neg_count >=2:\n",
    "            negative = True         \n",
    "        else:\n",
    "            negative = False\n",
    "        \n",
    "        features['strong_positive'] = positive\n",
    "        features['strong_negative'] = negative\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "959b9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_opinion_only_features = [(boolean_opinion_only_features(d, pos_lex, neg_lex), l) for (d, l) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03226391",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_opinion_featureset_df = pd.DataFrame(boolean_opinion_only_features, columns=['features', 'label'])\n",
    "bool_opinion_features_df = pd.DataFrame(bool_opinion_featureset_df['features'].tolist())\n",
    "df_csv = pd.concat([bool_opinion_features_df, bool_opinion_featureset_df ['label']], axis=1)\n",
    "df_csv.to_csv('~/boolean_opinion_features_fakenews_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e956c",
   "metadata": {},
   "source": [
    "<h1>Extracting Quantitative Linguistic Features from the Minimally Processed Dataset</h1>\n",
    "<br>\n",
    "<body>\n",
    "    Although the pre-processing steps that we undertook early in the process have been helpful in improving the Bag of Words (BoW) features, there is information loss that might be useful to building a robust classification model. \n",
    "    <br><br>\n",
    "    These quantitate linguistic features include:\n",
    "    <br>\n",
    "        * calculating the average word length (best done on unstemmed data without stopword filtering)\n",
    "        <br>\n",
    "        * calculating the percent of words in each document that are in ALL CAPS (cannot be done with lowercased tokens)\n",
    "        <br>\n",
    "        * calculating the percent of each document that is punctuation (cannot be done with data in which most or all punctuation has been removed)\n",
    "        <br>\n",
    "        * calculating the average length in words for each sentence in the main \"text\" body (cannot be done without sentence tokenization)\n",
    "    \n",
    "We extract those features in the section below and write the resulting featuresets to CSV for future use.\n",
    "    \n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e66107eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE MINIMALLY PRE-PROCESSED DATASET\n",
    "\n",
    "df = pd.read_csv('~/min_process_fakenews_df_canonical.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])\n",
    "\n",
    "# make a tuple of title, label for each row in the df\n",
    "tuple_rows = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# tokenize sentences in the title\n",
    "text_sents_tuple = [(sent_tokenize(text[1]), text[2]) for text in tuple_rows]\n",
    "text_documents = text_sents_tuple\n",
    "\n",
    "# tokenize words in the title\n",
    "title_words_tuple = [(word_tokenize(title[0]), title[2]) for title in tuple_rows]\n",
    "documents = title_words_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3785b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A FUNCTION TO CALCULATE THE AVERAGE WORD LENGTH IN EACH DOCUMENT\n",
    "\n",
    "def avg_word_length(document):\n",
    "    total_length = 0\n",
    "    word_count = 0\n",
    "    \n",
    "    for word in document:\n",
    "        total_length += len(word)\n",
    "        word_count += 1\n",
    "        \n",
    "    avg_word_len = total_length / word_count if word_count > 0 else 0\n",
    "    \n",
    "    return round(avg_word_len, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab108096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A FUNCTION TO CALCULATE THE PERCENT OF WORDS IN EACH DOCUMENT THAT ARE ALL CAPS\n",
    "\n",
    "def percent_ALL_CAP(document):\n",
    "    all_cap_count = 0\n",
    "    \n",
    "    for word in document:\n",
    "        if re.findall(r'([A-Z]+)\\b', word):\n",
    "            all_cap_count +=1\n",
    "\n",
    "    total_words = sum([1 for word in document if word.isalpha()])\n",
    "    \n",
    "    return round(all_cap_count/total_words, 2) if all_cap_count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b0aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A FUNCTION TO CALCULATE THE PERCENT OF CHARACTERS IN EACH DOCUMENT THAT ARE PUNCTUATION\n",
    "\n",
    "def percent_punct(document):\n",
    "    \n",
    "    count = sum([1 for token in document if token in string.punctuation])\n",
    "    \n",
    "    return round(count/(len(document)), 2) if len(document) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9f02f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a featureset that combines the minimallly processed text linguistic features:\n",
    "## Average Word Length, % Capitals, % Punctuation \n",
    "\n",
    "combined_raw_featuresets = [(avg_word_length(title), percent_ALL_CAP(title), percent_punct(title),  cat) for (title, cat) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9a7e431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_raw_featuresets_df = pd.DataFrame(combined_raw_featuresets, columns=['word_length', 'all_caps', 'punct', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0c76f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_raw_featuresets_df.to_csv('~/quant_linguistic_featuresets_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "1b0149f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A FUNCTION TO CALCULATE SENTENCE LENGTH IN THE TEXT BODY FOR EACH DOCUMENT\n",
    "\n",
    "def avg_sentence_length(document):\n",
    "    total_words = 0\n",
    "    total_sentences = 0\n",
    "    \n",
    "    for sent in document:\n",
    "        # Tokenize the sentence into words\n",
    "        words = nltk.word_tokenize(sent)\n",
    "        \n",
    "        # Count the words in the current sentence\n",
    "        total_words += len(words)\n",
    "        \n",
    "        # Increment the total sentence count\n",
    "        total_sentences += 1\n",
    "    \n",
    "    # Calculate the average sentence length\n",
    "    returns = round(total_words / total_sentences, 2) if total_sentences > 0 else 0\n",
    "    \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0aaf6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a featureset that combines the minimallly processed text linguistic features:\n",
    "## Average Word Length, % Capitals, % Punctuation \n",
    "\n",
    "avg_sent_len_featuresets = [(avg_sentence_length(text), cat) for (text, cat) in text_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7cd39b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sent_len_featuresets_df = pd.DataFrame(avg_sent_len_featuresets, columns=['avg_sen_length', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "14fe5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sent_len_featuresets_df.to_csv('~/avg_sent_len_featuresets_df_canonical.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c410ff",
   "metadata": {},
   "source": [
    "<h1>Test 9: Unigrams + Quantitative Linguistic Features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7c2cceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF QUANTITATIVE LINGUISTIC FEATURES + UNIGRAM FEATURES\n",
    "df_title_unigrams = pd.read_csv('~/title_unigram_features_fakenews_df_canonical.csv')\n",
    "\n",
    "quant_ling_featuresets_df = pd.read_csv('~/title_quant_ling_featuresets_df_canonical.csv')\n",
    "\n",
    "remove_label1 = quant_ling_featuresets_df.pop('label')\n",
    "\n",
    "avg_sent_len_featuresets_df = pd.read_csv('~/avg_sent_len_featuresets_df_canonical.csv')\n",
    "\n",
    "remove_label2 = avg_sent_len_featuresets_df.pop('label')\n",
    "\n",
    "unigram_quant_ling_df = pd.concat([avg_sent_len_featuresets_df, quant_ling_featuresets_df, df_title_unigrams], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5c009b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF ONLY QUANTITATIVE LINGUISTIC FEATURES\n",
    "quant_ling_featuresets_df = pd.read_csv('~/title_quant_ling_featuresets_df_canonical.csv')\n",
    "remove_label1 = quant_ling_featuresets_df.pop('label')\n",
    "avg_sent_len_featuresets_df = pd.read_csv('~/avg_sent_len_featuresets_df_canonical.csv')\n",
    "quant_ling_only_df = pd.concat([quant_ling_featuresets_df, avg_sent_len_featuresets_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bc8a489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_ling_only_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in quant_ling_only_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "51b5985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and quantitative linguistic features:0.7506780225531713\n",
      "\n",
      "Execution time: 0.2662849426269531 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = quant_ling_only_featuresets[(round(.30 * len(quant_ling_only_featuresets))):], quant_ling_only_featuresets[:(round(.30 * len(quant_ling_only_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "\n",
    "print(f\"Accuracy with combined unigram and quantitative linguistic features:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ce44e311",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                all_caps = 1.0               1.0 : 0.0    =    347.1 : 1.0\n",
      "          avg_sen_length = 0.0               1.0 : 0.0    =    338.9 : 1.0\n",
      "                all_caps = 0.36              1.0 : 0.0    =    183.1 : 1.0\n",
      "                all_caps = 0.24              1.0 : 0.0    =    144.9 : 1.0\n",
      "                all_caps = 0.43              1.0 : 0.0    =     93.4 : 1.0\n",
      "                all_caps = 0.4               1.0 : 0.0    =     67.3 : 1.0\n",
      "                all_caps = 0.19              1.0 : 0.0    =     59.7 : 1.0\n",
      "                all_caps = 0.45              1.0 : 0.0    =     59.2 : 1.0\n",
      "                all_caps = 0.21              1.0 : 0.0    =     47.3 : 1.0\n",
      "                all_caps = 0.38              1.0 : 0.0    =     42.8 : 1.0\n",
      "                all_caps = 0.5               1.0 : 0.0    =     42.1 : 1.0\n",
      "                all_caps = 0.27              1.0 : 0.0    =     36.4 : 1.0\n",
      "          avg_sen_length = 8.0               1.0 : 0.0    =     31.8 : 1.0\n",
      "                all_caps = 0.23              1.0 : 0.0    =     28.8 : 1.0\n",
      "          avg_sen_length = 13.0              1.0 : 0.0    =     28.4 : 1.0\n",
      "                   punct = 0.04              1.0 : 0.0    =     23.3 : 1.0\n",
      "             word_length = 4.52              1.0 : 0.0    =     20.3 : 1.0\n",
      "             word_length = 5.04              1.0 : 0.0    =     17.7 : 1.0\n",
      "             word_length = 4.48              1.0 : 0.0    =     15.3 : 1.0\n",
      "             word_length = 5.65              1.0 : 0.0    =     15.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NBclassifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "180b97fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "     |    1    0 |\n",
      "    |    .    . |\n",
      "    |    0    0 |\n",
      "----+-----------+\n",
      "1.0 |<7231>3327 |\n",
      "0.0 | 1913<8546>|\n",
      "----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0.0 \t      0.720      0.817      0.765      0.685\n",
      "1.0 \t      0.791      0.685      0.734      0.817\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "04b77249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_sen_length</th>\n",
       "      <th>word_length</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>punct</th>\n",
       "      <th>V_trump</th>\n",
       "      <th>V_new</th>\n",
       "      <th>V_video</th>\n",
       "      <th>V_time</th>\n",
       "      <th>V_york</th>\n",
       "      <th>V_us</th>\n",
       "      <th>...</th>\n",
       "      <th>V_disarm</th>\n",
       "      <th>V_pant</th>\n",
       "      <th>V_madonna</th>\n",
       "      <th>V_onto</th>\n",
       "      <th>V_guatemala</th>\n",
       "      <th>V_clerk</th>\n",
       "      <th>V_trader</th>\n",
       "      <th>V_paus</th>\n",
       "      <th>V_unknown</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.86</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.41</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.24</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.62</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.65</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3871 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_sen_length  word_length  all_caps  punct  V_trump  V_new  V_video  \\\n",
       "0           24.86         3.00      0.60   0.27    False  False    False   \n",
       "1           22.41         7.00      0.00   0.11    False  False    False   \n",
       "2           20.24         4.50      0.00   0.00    False  False    False   \n",
       "3           39.62         4.48      0.00   0.08    False   True    False   \n",
       "4           25.65         3.39      0.11   0.17    False  False    False   \n",
       "\n",
       "   V_time  V_york   V_us  ...  V_disarm  V_pant  V_madonna  V_onto  \\\n",
       "0   False   False  False  ...     False   False      False   False   \n",
       "1   False   False  False  ...     False   False      False   False   \n",
       "2   False   False  False  ...     False   False      False   False   \n",
       "3   False   False  False  ...     False   False      False   False   \n",
       "4   False   False  False  ...     False   False      False   False   \n",
       "\n",
       "   V_guatemala  V_clerk  V_trader  V_paus  V_unknown  label  \n",
       "0        False    False     False   False      False      1  \n",
       "1        False    False     False   False      False      1  \n",
       "2        False    False     False   False      False      1  \n",
       "3        False    False     False   False      False      1  \n",
       "4        False    False     False   False      False      0  \n",
       "\n",
       "[5 rows x 3871 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_quant_ling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a653c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_quant_ling_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in unigram_quant_ling_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "72dd38a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and quantitative linguistic features:0.8801446448113432\n",
      "\n",
      "Execution time: 120.22409510612488 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = unigram_quant_ling_featuresets[(round(.30 * len(unigram_quant_ling_featuresets))):], unigram_quant_ling_featuresets[:(round(.30 * len(unigram_quant_ling_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "\n",
    "print(f\"Accuracy with combined unigram and quantitative linguistic features:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c8af5390",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                all_caps = 1.0                 1 : 0      =    347.1 : 1.0\n",
      "          avg_sen_length = 0.0                 1 : 0      =    338.9 : 1.0\n",
      "                V_hilari = True                1 : 0      =    187.1 : 1.0\n",
      "                all_caps = 0.36                1 : 0      =    183.1 : 1.0\n",
      "                   V_wow = True                1 : 0      =    162.3 : 1.0\n",
      "                all_caps = 0.24                1 : 0      =    144.9 : 1.0\n",
      "               V_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     V_… = True                1 : 0      =     95.7 : 1.0\n",
      "                all_caps = 0.43                1 : 0      =     93.4 : 1.0\n",
      "                all_caps = 0.4                 1 : 0      =     67.3 : 1.0\n",
      "                V_awesom = True                1 : 0      =     64.6 : 1.0\n",
      "                all_caps = 0.19                1 : 0      =     59.7 : 1.0\n",
      "                all_caps = 0.45                1 : 0      =     59.2 : 1.0\n",
      "                 V_bundi = True                1 : 0      =     57.2 : 1.0\n",
      "                     V_! = True                1 : 0      =     56.9 : 1.0\n",
      "                 V_crook = True                1 : 0      =     53.9 : 1.0\n",
      "                  V_york = True                0 : 1      =     50.5 : 1.0\n",
      "               V_zimbabw = True                0 : 1      =     50.4 : 1.0\n",
      "             V_brilliant = True                1 : 0      =     49.6 : 1.0\n",
      "                 V_onion = True                1 : 0      =     49.2 : 1.0\n",
      "                all_caps = 0.21                1 : 0      =     47.3 : 1.0\n",
      "                V_finest = True                1 : 0      =     47.2 : 1.0\n",
      "                   V_oop = True                1 : 0      =     47.2 : 1.0\n",
      "               V_disgust = True                1 : 0      =     46.8 : 1.0\n",
      "             V_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "              V_bombshel = True                1 : 0      =     45.2 : 1.0\n",
      "                 V_mugab = True                0 : 1      =     44.8 : 1.0\n",
      "                all_caps = 0.38                1 : 0      =     42.8 : 1.0\n",
      "                all_caps = 0.5                 1 : 0      =     42.1 : 1.0\n",
      "                 V_video = True                1 : 0      =     38.8 : 1.0\n",
      "                     V_– = True                1 : 0      =     37.6 : 1.0\n",
      "                all_caps = 0.27                1 : 0      =     36.4 : 1.0\n",
      "                V_reuter = True                0 : 1      =     36.2 : 1.0\n",
      "                V_antifa = True                1 : 0      =     35.8 : 1.0\n",
      "                   V_beg = True                1 : 0      =     33.8 : 1.0\n",
      "               V_mnuchin = True                0 : 1      =     33.5 : 1.0\n",
      "                  V_epic = True                1 : 0      =     32.8 : 1.0\n",
      "                 V_laugh = True                1 : 0      =     32.6 : 1.0\n",
      "                  V_damn = True                1 : 0      =     32.5 : 1.0\n",
      "             V_hypocrisi = True                1 : 0      =     32.5 : 1.0\n",
      "                   V_a** = True                1 : 0      =     31.8 : 1.0\n",
      "          avg_sen_length = 8.0                 1 : 0      =     31.8 : 1.0\n",
      "       V_#blacklivesmatt = True                1 : 0      =     31.1 : 1.0\n",
      "                  V_thug = True                1 : 0      =     30.3 : 1.0\n",
      "                 V_gonna = True                1 : 0      =     29.8 : 1.0\n",
      "                 V_insan = True                1 : 0      =     29.1 : 1.0\n",
      "                all_caps = 0.23                1 : 0      =     28.8 : 1.0\n",
      "               V_furious = True                1 : 0      =     28.7 : 1.0\n",
      "          avg_sen_length = 13.0                1 : 0      =     28.4 : 1.0\n",
      "                  V_sh*t = True                1 : 0      =     27.9 : 1.0\n",
      "                V_unreal = True                1 : 0      =     27.8 : 1.0\n",
      "                    V_xi = True                0 : 1      =     26.6 : 1.0\n",
      "              V_undercov = True                1 : 0      =     26.4 : 1.0\n",
      "                 V_youll = True                1 : 0      =     26.4 : 1.0\n",
      "                 V_smack = True                1 : 0      =     25.1 : 1.0\n",
      "               V_baghdad = True                0 : 1      =     24.2 : 1.0\n",
      "                 V_envoy = True                0 : 1      =     24.2 : 1.0\n",
      "             V_halloween = True                1 : 0      =     23.9 : 1.0\n",
      "                V_macron = True                0 : 1      =     23.8 : 1.0\n",
      "                   V_mic = True                1 : 0      =     23.8 : 1.0\n",
      "                   punct = 0.04                1 : 0      =     23.3 : 1.0\n",
      "                    V_en = True                1 : 0      =     23.1 : 1.0\n",
      "                  V_seth = True                1 : 0      =     23.1 : 1.0\n",
      "               V_tantrum = True                1 : 0      =     22.4 : 1.0\n",
      "               V_somalia = True                0 : 1      =     22.2 : 1.0\n",
      "              V_cambodia = True                0 : 1      =     21.6 : 1.0\n",
      "                   V_rio = True                0 : 1      =     21.6 : 1.0\n",
      "                  V_brag = True                1 : 0      =     21.5 : 1.0\n",
      "                 V_viral = True                1 : 0      =     21.4 : 1.0\n",
      "                V_hyster = True                1 : 0      =     21.1 : 1.0\n",
      "                V_pathet = True                1 : 0      =     21.1 : 1.0\n",
      "                 V_shred = True                1 : 0      =     21.1 : 1.0\n",
      "                 V_expos = True                1 : 0      =     20.7 : 1.0\n",
      "              V_sanction = True                0 : 1      =     20.3 : 1.0\n",
      "                 V_idiot = True                1 : 0      =     20.3 : 1.0\n",
      "             word_length = 4.52                1 : 0      =     20.3 : 1.0\n",
      "                 V_liter = True                1 : 0      =     20.2 : 1.0\n",
      "                V_bizarr = True                1 : 0      =     19.9 : 1.0\n",
      "                 V_czech = True                0 : 1      =     19.6 : 1.0\n",
      "                V_soccer = True                0 : 1      =     19.6 : 1.0\n",
      "               V_kremlin = True                0 : 1      =     19.1 : 1.0\n",
      "                V_tucker = True                1 : 0      =     19.1 : 1.0\n",
      "               V_ireland = True                0 : 1      =     18.9 : 1.0\n",
      "               V_septemb = True                0 : 1      =     18.9 : 1.0\n",
      "              V_farright = True                0 : 1      =     18.9 : 1.0\n",
      "                V_scream = True                1 : 0      =     18.7 : 1.0\n",
      "              V_hypocrit = True                1 : 0      =     18.5 : 1.0\n",
      "          V_antiamerican = True                1 : 0      =     18.4 : 1.0\n",
      "                 V_scath = True                1 : 0      =     18.4 : 1.0\n",
      "            V_disrespect = True                1 : 0      =     18.3 : 1.0\n",
      "                   V_kkk = True                1 : 0      =     18.3 : 1.0\n",
      "             V_tillerson = True                0 : 1      =     18.2 : 1.0\n",
      "               V_dumbest = True                1 : 0      =     17.7 : 1.0\n",
      "                 V_satan = True                1 : 0      =     17.7 : 1.0\n",
      "             word_length = 5.04                1 : 0      =     17.7 : 1.0\n",
      "                V_incred = True                1 : 0      =     17.5 : 1.0\n",
      "                 V_egypt = True                0 : 1      =     17.4 : 1.0\n",
      "            V_girlfriend = True                1 : 0      =     17.1 : 1.0\n",
      "                   V_hed = True                1 : 0      =     17.1 : 1.0\n",
      "                  V_ouch = True                1 : 0      =     17.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NBclassifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431eee63",
   "metadata": {},
   "source": [
    "<h3>Inspecting the Dataset for Empty Text Fields</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "38a68847",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_lens = avg_sent_len_featuresets_df['avg_sen_length'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "21937e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_sent = [sen for sen in sen_lens if sen==0.0]\n",
    "len(zero_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8373a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114, 123, 169, 214, 289]\n"
     ]
    }
   ],
   "source": [
    "def find_zero_sens(sen_lens):\n",
    "    zero_sens = []\n",
    "    for i, sen in enumerate(sen_lens):\n",
    "        if sen == 0.0:\n",
    "            zero_sens.append(i) # Append the index directly\n",
    "    return zero_sens\n",
    "\n",
    "print(find_zero_sens(sen_lens)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c3b15878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>FAKE NEWS! MAXINE WATERS and JOY REID Make Out...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TRUMP’S GREAT ANSWER On Terror Attack: “It’s a...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>TOMI LAHREN: “AFTER 8 YEARS…We were part of a ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>MICHAEL FLYNN’S LAWYER Releases Statement Scor...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>FAKE NEWS ALERT! FORMER GOV OF MARYLAND Calls ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title text  label\n",
       "114  FAKE NEWS! MAXINE WATERS and JOY REID Make Out...           1\n",
       "123  TRUMP’S GREAT ANSWER On Terror Attack: “It’s a...           1\n",
       "169  TOMI LAHREN: “AFTER 8 YEARS…We were part of a ...           1\n",
       "214  MICHAEL FLYNN’S LAWYER Releases Statement Scor...           1\n",
       "289  FAKE NEWS ALERT! FORMER GOV OF MARYLAND Calls ...           1"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[114, 123, 169, 214, 289]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "14c54341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8811647990864321\n",
      "1 0.8821640139890087\n",
      "2 0.872885589893655\n",
      "3 0.883876953821997\n",
      "4 0.8763114695596317\n",
      "mean accuracy 0.8792805652701448\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, unigram_quant_ling_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7a6e547e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8898>1660 |\n",
      "0 |  859<9600>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.918      0.884      0.843\n",
      "1 \t      0.912      0.843      0.876      0.918\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ecc38",
   "metadata": {},
   "source": [
    "<h1>Test 10: Large Composite Featureset:</h1><h3>Title Unigrams/Text Bigrams/Opinion Lexicon/Quantitative Linguistic Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "92cc0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF QUANTITATIVE LINGUISTIC FEATURES + UNIGRAM FEATURES\n",
    "title_unigrams_df = pd.read_csv('~/title_unigram_features_fakenews_df_canonical.csv')\n",
    "\n",
    "text_bigrams_df = pd.read_csv('~/text_bigram_only_features_fakenews_df_canonical.csv')\n",
    "remove_label1 = text_bigrams_df.pop('label')\n",
    "\n",
    "quant_ling_featuresets_df = pd.read_csv('~/title_quant_ling_featuresets_df_canonical.csv')\n",
    "remove_label2 = quant_ling_featuresets_df.pop('label')\n",
    "\n",
    "avg_sent_len_featuresets_df = pd.read_csv('~/avg_sent_len_featuresets_df_canonical.csv')\n",
    "remove_label3 = avg_sent_len_featuresets_df.pop('label')\n",
    "\n",
    "opinion_only_df = pd.read_csv('~/sentiment_unigram_features_fakenews_df_canonical.csv')\n",
    "remove_label4 = opinion_only_df.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e3862fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_composite_df = pd.concat([avg_sent_len_featuresets_df, quant_ling_featuresets_df,opinion_only_df, text_bigrams_df, title_unigrams_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5f9e01d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_sen_length</th>\n",
       "      <th>word_length</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>punct</th>\n",
       "      <th>positivecount</th>\n",
       "      <th>negativecount</th>\n",
       "      <th>B_suu_kyi</th>\n",
       "      <th>B_hong_kong</th>\n",
       "      <th>B_shi_ite</th>\n",
       "      <th>B_bashar_alassad</th>\n",
       "      <th>...</th>\n",
       "      <th>V_disarm</th>\n",
       "      <th>V_pant</th>\n",
       "      <th>V_madonna</th>\n",
       "      <th>V_onto</th>\n",
       "      <th>V_guatemala</th>\n",
       "      <th>V_clerk</th>\n",
       "      <th>V_trader</th>\n",
       "      <th>V_paus</th>\n",
       "      <th>V_unknown</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.86</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.41</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.24</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.62</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.65</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_sen_length  word_length  all_caps  punct  positivecount  negativecount  \\\n",
       "0           24.86         3.00      0.60   0.27              1              1   \n",
       "1           22.41         7.00      0.00   0.11              0              1   \n",
       "2           20.24         4.50      0.00   0.00              1              3   \n",
       "3           39.62         4.48      0.00   0.08              1              1   \n",
       "4           25.65         3.39      0.11   0.17              0              2   \n",
       "\n",
       "   B_suu_kyi  B_hong_kong  B_shi_ite  B_bashar_alassad  ...  V_disarm  V_pant  \\\n",
       "0      False        False      False             False  ...     False   False   \n",
       "1      False        False      False             False  ...     False   False   \n",
       "2      False        False      False             False  ...     False   False   \n",
       "3      False        False      False             False  ...     False   False   \n",
       "4      False        False      False             False  ...     False   False   \n",
       "\n",
       "   V_madonna  V_onto  V_guatemala  V_clerk  V_trader  V_paus  V_unknown  label  \n",
       "0      False   False        False    False     False   False      False      1  \n",
       "1      False   False        False    False     False   False      False      1  \n",
       "2      False   False        False    False     False   False      False      1  \n",
       "3      False   False        False    False     False   False      False      1  \n",
       "4      False   False        False    False     False   False      False      0  \n",
       "\n",
       "[5 rows x 5125 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_composite_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c251bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_composite_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in large_composite_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "79650157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and quantitative linguistic features:0.8780035209592235\n",
      "\n",
      "Execution time: 166.2221622467041 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = large_composite_featuresets[(round(.30 * len(large_composite_featuresets))):], large_composite_featuresets[:(round(.30 * len(large_composite_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "\n",
    "print(f\"Accuracy with combined unigram and quantitative linguistic features:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "02003edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8866>1692 |\n",
      "0 |  872<9587>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.850      0.917      0.882      0.840\n",
      "1 \t      0.910      0.840      0.874      0.917\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1fd76a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each fold size: 14011\n",
      "0 0.8792377417743201\n",
      "1 0.8805224466490614\n",
      "2 0.8716722575119549\n",
      "3 0.8827349939333381\n",
      "4 0.8753836271500963\n",
      "mean accuracy 0.8779102134037542\n"
     ]
    }
   ],
   "source": [
    "# perform the cross-validation on the featuresets with word features and generate accuracy\n",
    "num_folds = 5\n",
    "cross_validation_accuracy(num_folds, large_composite_featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "51285b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                all_caps = 1.0                 1 : 0      =    347.1 : 1.0\n",
      "          avg_sen_length = 0.0                 1 : 0      =    338.9 : 1.0\n",
      "                V_hilari = True                1 : 0      =    187.1 : 1.0\n",
      "                all_caps = 0.36                1 : 0      =    183.1 : 1.0\n",
      "                   V_wow = True                1 : 0      =    162.3 : 1.0\n",
      "                all_caps = 0.24                1 : 0      =    144.9 : 1.0\n",
      "               V_myanmar = True                0 : 1      =    141.1 : 1.0\n",
      "                     V_… = True                1 : 0      =     95.7 : 1.0\n",
      "               B_suu_kyi = True                0 : 1      =     94.6 : 1.0\n",
      "                all_caps = 0.43                1 : 0      =     93.4 : 1.0\n",
      "                all_caps = 0.4                 1 : 0      =     67.3 : 1.0\n",
      "                V_awesom = True                1 : 0      =     64.6 : 1.0\n",
      "                all_caps = 0.19                1 : 0      =     59.7 : 1.0\n",
      "                all_caps = 0.45                1 : 0      =     59.2 : 1.0\n",
      "                 V_bundi = True                1 : 0      =     57.2 : 1.0\n",
      "                     V_! = True                1 : 0      =     56.9 : 1.0\n",
      "                 V_crook = True                1 : 0      =     53.9 : 1.0\n",
      "                  V_york = True                0 : 1      =     50.5 : 1.0\n",
      "               V_zimbabw = True                0 : 1      =     50.4 : 1.0\n",
      "             V_brilliant = True                1 : 0      =     49.6 : 1.0\n",
      "                 V_onion = True                1 : 0      =     49.2 : 1.0\n",
      "                all_caps = 0.21                1 : 0      =     47.3 : 1.0\n",
      "                V_finest = True                1 : 0      =     47.2 : 1.0\n",
      "                   V_oop = True                1 : 0      =     47.2 : 1.0\n",
      "               V_disgust = True                1 : 0      =     46.8 : 1.0\n",
      "             V_breitbart = True                0 : 1      =     45.3 : 1.0\n",
      "              V_bombshel = True                1 : 0      =     45.2 : 1.0\n",
      "                 V_mugab = True                0 : 1      =     44.8 : 1.0\n",
      "                all_caps = 0.38                1 : 0      =     42.8 : 1.0\n",
      "                all_caps = 0.5                 1 : 0      =     42.1 : 1.0\n",
      "                 V_video = True                1 : 0      =     38.8 : 1.0\n",
      "                     V_– = True                1 : 0      =     37.6 : 1.0\n",
      "                all_caps = 0.27                1 : 0      =     36.4 : 1.0\n",
      "                V_reuter = True                0 : 1      =     36.2 : 1.0\n",
      "                V_antifa = True                1 : 0      =     35.8 : 1.0\n",
      "                   V_beg = True                1 : 0      =     33.8 : 1.0\n",
      "               V_mnuchin = True                0 : 1      =     33.5 : 1.0\n",
      "                  V_epic = True                1 : 0      =     32.8 : 1.0\n",
      "                 V_laugh = True                1 : 0      =     32.6 : 1.0\n",
      "                  V_damn = True                1 : 0      =     32.5 : 1.0\n",
      "             V_hypocrisi = True                1 : 0      =     32.5 : 1.0\n",
      "                   V_a** = True                1 : 0      =     31.8 : 1.0\n",
      "          avg_sen_length = 8.0                 1 : 0      =     31.8 : 1.0\n",
      "       V_#blacklivesmatt = True                1 : 0      =     31.1 : 1.0\n",
      "                  V_thug = True                1 : 0      =     30.3 : 1.0\n",
      "                 V_gonna = True                1 : 0      =     29.8 : 1.0\n",
      "                 V_insan = True                1 : 0      =     29.1 : 1.0\n",
      "                all_caps = 0.23                1 : 0      =     28.8 : 1.0\n",
      "               V_furious = True                1 : 0      =     28.7 : 1.0\n",
      "          avg_sen_length = 13.0                1 : 0      =     28.4 : 1.0\n",
      "                  V_sh*t = True                1 : 0      =     27.9 : 1.0\n",
      "                V_unreal = True                1 : 0      =     27.8 : 1.0\n",
      "                    V_xi = True                0 : 1      =     26.6 : 1.0\n",
      "              V_undercov = True                1 : 0      =     26.4 : 1.0\n",
      "                 V_youll = True                1 : 0      =     26.4 : 1.0\n",
      "                 V_smack = True                1 : 0      =     25.1 : 1.0\n",
      "               V_baghdad = True                0 : 1      =     24.2 : 1.0\n",
      "                 V_envoy = True                0 : 1      =     24.2 : 1.0\n",
      "             V_halloween = True                1 : 0      =     23.9 : 1.0\n",
      "                V_macron = True                0 : 1      =     23.8 : 1.0\n",
      "                   V_mic = True                1 : 0      =     23.8 : 1.0\n",
      "                   punct = 0.04                1 : 0      =     23.3 : 1.0\n",
      "                    V_en = True                1 : 0      =     23.1 : 1.0\n",
      "                  V_seth = True                1 : 0      =     23.1 : 1.0\n",
      "               V_tantrum = True                1 : 0      =     22.4 : 1.0\n",
      "               V_somalia = True                0 : 1      =     22.2 : 1.0\n",
      "              V_cambodia = True                0 : 1      =     21.6 : 1.0\n",
      "                   V_rio = True                0 : 1      =     21.6 : 1.0\n",
      "                  V_brag = True                1 : 0      =     21.5 : 1.0\n",
      "                 V_viral = True                1 : 0      =     21.4 : 1.0\n",
      "                V_hyster = True                1 : 0      =     21.1 : 1.0\n",
      "                V_pathet = True                1 : 0      =     21.1 : 1.0\n",
      "                 V_shred = True                1 : 0      =     21.1 : 1.0\n",
      "                 V_expos = True                1 : 0      =     20.7 : 1.0\n",
      "              V_sanction = True                0 : 1      =     20.3 : 1.0\n",
      "                 V_idiot = True                1 : 0      =     20.3 : 1.0\n",
      "             word_length = 4.52                1 : 0      =     20.3 : 1.0\n",
      "                 V_liter = True                1 : 0      =     20.2 : 1.0\n",
      "                V_bizarr = True                1 : 0      =     19.9 : 1.0\n",
      "                 V_czech = True                0 : 1      =     19.6 : 1.0\n",
      "                V_soccer = True                0 : 1      =     19.6 : 1.0\n",
      "               V_kremlin = True                0 : 1      =     19.1 : 1.0\n",
      "                V_tucker = True                1 : 0      =     19.1 : 1.0\n",
      "               V_ireland = True                0 : 1      =     18.9 : 1.0\n",
      "               V_septemb = True                0 : 1      =     18.9 : 1.0\n",
      "              V_farright = True                0 : 1      =     18.9 : 1.0\n",
      "                V_scream = True                1 : 0      =     18.7 : 1.0\n",
      "              V_hypocrit = True                1 : 0      =     18.5 : 1.0\n",
      "          V_antiamerican = True                1 : 0      =     18.4 : 1.0\n",
      "                 V_scath = True                1 : 0      =     18.4 : 1.0\n",
      "            V_disrespect = True                1 : 0      =     18.3 : 1.0\n",
      "                   V_kkk = True                1 : 0      =     18.3 : 1.0\n",
      "             V_tillerson = True                0 : 1      =     18.2 : 1.0\n",
      "               V_dumbest = True                1 : 0      =     17.7 : 1.0\n",
      "                 V_satan = True                1 : 0      =     17.7 : 1.0\n",
      "             word_length = 5.04                1 : 0      =     17.7 : 1.0\n",
      "                V_incred = True                1 : 0      =     17.5 : 1.0\n",
      "                 V_egypt = True                0 : 1      =     17.4 : 1.0\n",
      "            V_girlfriend = True                1 : 0      =     17.1 : 1.0\n",
      "                   V_hed = True                1 : 0      =     17.1 : 1.0\n",
      "                  V_ouch = True                1 : 0      =     17.1 : 1.0\n",
      "              V_pedophil = True                1 : 0      =     17.1 : 1.0\n",
      "                V_predat = True                1 : 0      =     17.1 : 1.0\n",
      "                  V_quot = True                1 : 0      =     17.1 : 1.0\n",
      "                    V_pm = True                0 : 1      =     16.6 : 1.0\n",
      "                 V_freak = True                1 : 0      =     16.5 : 1.0\n",
      "               V_birther = True                1 : 0      =     16.4 : 1.0\n",
      "            V_napolitano = True                1 : 0      =     16.4 : 1.0\n",
      "                 V_roast = True                1 : 0      =     16.4 : 1.0\n",
      "                  V_rudi = True                1 : 0      =     16.4 : 1.0\n",
      "                V_thread = True                1 : 0      =     16.4 : 1.0\n",
      "                   V_abe = True                0 : 1      =     16.4 : 1.0\n",
      "                V_brutal = True                1 : 0      =     16.3 : 1.0\n",
      "                   V_feb = True                0 : 1      =     16.3 : 1.0\n",
      "                 V_polar = True                0 : 1      =     16.3 : 1.0\n",
      "                 V_screw = True                1 : 0      =     16.3 : 1.0\n",
      "                   V_kid = True                1 : 0      =     16.2 : 1.0\n",
      "               V_vicious = True                1 : 0      =     15.7 : 1.0\n",
      "              V_thailand = True                0 : 1      =     15.6 : 1.0\n",
      "               V_kurdish = True                0 : 1      =     15.5 : 1.0\n",
      "                  V_trey = True                1 : 0      =     15.5 : 1.0\n",
      "               V_perfect = True                1 : 0      =     15.4 : 1.0\n",
      "                V_rapist = True                1 : 0      =     15.3 : 1.0\n",
      "             word_length = 4.48                1 : 0      =     15.3 : 1.0\n",
      "                   V_eus = True                0 : 1      =     15.3 : 1.0\n",
      "              V_watchdog = True                0 : 1      =     15.2 : 1.0\n",
      "                    V_fl = True                1 : 0      =     15.1 : 1.0\n",
      "                  V_okay = True                1 : 0      =     15.1 : 1.0\n",
      "           V_supremacist = True                1 : 0      =     15.1 : 1.0\n",
      "                    V_tx = True                1 : 0      =     15.1 : 1.0\n",
      "                V_humili = True                1 : 0      =     15.1 : 1.0\n",
      "             word_length = 5.65                1 : 0      =     15.1 : 1.0\n",
      "          avg_sen_length = 36.6                1 : 0      =     15.1 : 1.0\n",
      "                  V_boko = True                0 : 1      =     14.9 : 1.0\n",
      "                 V_haram = True                0 : 1      =     14.9 : 1.0\n",
      "                  V_irma = True                0 : 1      =     14.8 : 1.0\n",
      "                  V_rant = True                1 : 0      =     14.8 : 1.0\n",
      "                   V_doj = True                1 : 0      =     14.7 : 1.0\n",
      "               V_patrick = True                1 : 0      =     14.7 : 1.0\n",
      "                  V_loom = True                0 : 1      =     14.7 : 1.0\n",
      "             V_embarrass = True                1 : 0      =     14.5 : 1.0\n",
      "                 V_nafta = True                0 : 1      =     14.5 : 1.0\n",
      "                   V_blm = True                1 : 0      =     14.4 : 1.0\n",
      "                V_implod = True                1 : 0      =     14.4 : 1.0\n",
      "                V_skewer = True                1 : 0      =     14.4 : 1.0\n",
      "                  V_suck = True                1 : 0      =     14.4 : 1.0\n",
      "                 V_weird = True                1 : 0      =     14.4 : 1.0\n",
      "          avg_sen_length = 6.0                 1 : 0      =     14.4 : 1.0\n",
      "                 V_decri = True                0 : 1      =     14.3 : 1.0\n",
      "                  V_fate = True                0 : 1      =     14.3 : 1.0\n",
      "            V_postbrexit = True                0 : 1      =     14.3 : 1.0\n",
      "                  V_stun = True                1 : 0      =     14.2 : 1.0\n",
      "             V_flashback = True                1 : 0      =     14.0 : 1.0\n",
      "                 V_bigot = True                1 : 0      =     13.9 : 1.0\n",
      "          avg_sen_length = 15.67               1 : 0      =     13.9 : 1.0\n",
      "               V_pension = True                0 : 1      =     13.7 : 1.0\n",
      "                 V_arrog = True                1 : 0      =     13.7 : 1.0\n",
      "                 V_commi = True                1 : 0      =     13.7 : 1.0\n",
      "                V_costum = True                1 : 0      =     13.7 : 1.0\n",
      "                 V_cough = True                1 : 0      =     13.7 : 1.0\n",
      "                V_surfac = True                1 : 0      =     13.7 : 1.0\n",
      "                    V_ca = True                1 : 0      =     13.6 : 1.0\n",
      "                   V_edt = True                0 : 1      =     13.6 : 1.0\n",
      "                 V_pursu = True                0 : 1      =     13.6 : 1.0\n",
      "                 V_spain = True                0 : 1      =     13.6 : 1.0\n",
      "           negativecount = 6                   1 : 0      =     13.5 : 1.0\n",
      "               V_taliban = True                0 : 1      =     13.3 : 1.0\n",
      "                  V_amaz = True                1 : 0      =     13.3 : 1.0\n",
      "                 V_craig = True                1 : 0      =     13.1 : 1.0\n",
      "                  V_flip = True                1 : 0      =     13.1 : 1.0\n",
      "                   V_hey = True                1 : 0      =     13.1 : 1.0\n",
      "                  V_prof = True                1 : 0      =     13.1 : 1.0\n",
      "                     V_u = True                1 : 0      =     13.1 : 1.0\n",
      "             word_length = 5.94                1 : 0      =     13.1 : 1.0\n",
      "               V_opposit = True                0 : 1      =     13.0 : 1.0\n",
      "                all_caps = 0.33                1 : 0      =     13.0 : 1.0\n",
      "                 V_avert = True                0 : 1      =     12.9 : 1.0\n",
      "               V_setback = True                0 : 1      =     12.9 : 1.0\n",
      "              V_wikileak = True                1 : 0      =     12.7 : 1.0\n",
      "                   V_cop = True                1 : 0      =     12.7 : 1.0\n",
      "             V_communism = True                1 : 0      =     12.4 : 1.0\n",
      "              V_demolish = True                1 : 0      =     12.4 : 1.0\n",
      "                  V_eras = True                1 : 0      =     12.4 : 1.0\n",
      "                 V_pirro = True                1 : 0      =     12.4 : 1.0\n",
      "                  V_rude = True                1 : 0      =     12.4 : 1.0\n",
      "             V_smackdown = True                1 : 0      =     12.4 : 1.0\n",
      "               V_deficit = True                0 : 1      =     12.3 : 1.0\n",
      "                  V_exil = True                0 : 1      =     12.3 : 1.0\n",
      "              V_thursday = True                0 : 1      =     12.2 : 1.0\n",
      "                 V_watch = True                1 : 0      =     12.2 : 1.0\n",
      "                  V_nail = True                1 : 0      =     12.2 : 1.0\n",
      "                all_caps = 0.3                 1 : 0      =     12.0 : 1.0\n",
      "                V_stupid = True                1 : 0      =     12.0 : 1.0\n",
      "                 V_proof = True                1 : 0      =     12.0 : 1.0\n",
      "                 V_chill = True                1 : 0      =     11.9 : 1.0\n",
      "                 V_guest = True                1 : 0      =     11.8 : 1.0\n",
      "               V_dialogu = True                0 : 1      =     11.8 : 1.0\n",
      "                 V_audio = True                1 : 0      =     11.8 : 1.0\n",
      "                 V_dutch = True                0 : 1      =     11.8 : 1.0\n",
      "                    V_ha = True                1 : 0      =     11.7 : 1.0\n",
      "                V_molest = True                1 : 0      =     11.7 : 1.0\n",
      "                   V_sum = True                1 : 0      =     11.7 : 1.0\n",
      "          avg_sen_length = 40.6                1 : 0      =     11.7 : 1.0\n",
      "          avg_sen_length = 30.19               0 : 1      =     11.6 : 1.0\n",
      "                  V_curb = True                0 : 1      =     11.6 : 1.0\n",
      "                  V_abba = True                0 : 1      =     11.6 : 1.0\n",
      "               V_displac = True                0 : 1      =     11.6 : 1.0\n",
      "                  V_emir = True                0 : 1      =     11.6 : 1.0\n",
      "                 V_hurdl = True                0 : 1      =     11.6 : 1.0\n",
      "                V_labour = True                0 : 1      =     11.6 : 1.0\n",
      "               V_persist = True                0 : 1      =     11.6 : 1.0\n",
      "                V_provoc = True                0 : 1      =     11.6 : 1.0\n",
      "                V_runoff = True                0 : 1      =     11.6 : 1.0\n",
      "               V_tougher = True                0 : 1      =     11.6 : 1.0\n",
      "           V_uncertainti = True                0 : 1      =     11.6 : 1.0\n",
      "                 V_troll = True                1 : 0      =     11.6 : 1.0\n",
      "               V_disturb = True                1 : 0      =     11.5 : 1.0\n",
      "                    V_oh = True                1 : 0      =     11.4 : 1.0\n",
      "               V_deadlin = True                0 : 1      =     11.4 : 1.0\n",
      "                V_madrid = True                0 : 1      =     11.4 : 1.0\n",
      "                V_resolv = True                0 : 1      =     11.4 : 1.0\n",
      "                  V_f*ck = True                1 : 0      =     11.4 : 1.0\n",
      "                 V_jesus = True                1 : 0      =     11.3 : 1.0\n",
      "             word_length = 4.84                1 : 0      =     11.3 : 1.0\n",
      "                  V_bibl = True                1 : 0      =     11.0 : 1.0\n",
      "               V_destroy = True                1 : 0      =     11.0 : 1.0\n",
      "             V_discoveri = True                1 : 0      =     11.0 : 1.0\n",
      "                 V_exact = True                1 : 0      =     11.0 : 1.0\n",
      "                  V_nypd = True                1 : 0      =     11.0 : 1.0\n",
      "                    V_qb = True                1 : 0      =     11.0 : 1.0\n",
      "                  V_vinc = True                1 : 0      =     11.0 : 1.0\n",
      "              V_vineyard = True                1 : 0      =     11.0 : 1.0\n",
      "             word_length = 6.07                1 : 0      =     11.0 : 1.0\n",
      "          avg_sen_length = 14.0                1 : 0      =     11.0 : 1.0\n",
      "          avg_sen_length = 64.0                1 : 0      =     11.0 : 1.0\n",
      "                V_racist = True                1 : 0      =     11.0 : 1.0\n",
      "               V_contend = True                0 : 1      =     11.0 : 1.0\n",
      "                 V_malta = True                0 : 1      =     11.0 : 1.0\n",
      "               V_reassur = True                0 : 1      =     11.0 : 1.0\n",
      "               V_podesta = True                1 : 0      =     10.9 : 1.0\n",
      "                  V_time = True                0 : 1      =     10.9 : 1.0\n",
      "                   V_dad = True                1 : 0      =     10.9 : 1.0\n",
      "                  V_imag = True                1 : 0      =     10.9 : 1.0\n",
      "                  V_seek = True                0 : 1      =     10.9 : 1.0\n",
      "              V_confeder = True                1 : 0      =     10.9 : 1.0\n",
      "                V_caught = True                1 : 0      =     10.8 : 1.0\n",
      "                all_caps = 0.13                1 : 0      =     10.8 : 1.0\n",
      "               V_couldnt = True                1 : 0      =     10.8 : 1.0\n",
      "                  V_room = True                1 : 0      =     10.7 : 1.0\n",
      "                  V_shes = True                1 : 0      =     10.6 : 1.0\n",
      "                   V_wsj = True                0 : 1      =     10.6 : 1.0\n",
      "                V_anchor = True                1 : 0      =     10.4 : 1.0\n",
      "                V_detent = True                0 : 1      =     10.4 : 1.0\n",
      "               V_blatant = True                1 : 0      =     10.4 : 1.0\n",
      "                 V_truli = True                1 : 0      =     10.4 : 1.0\n",
      "                V_valeri = True                1 : 0      =     10.4 : 1.0\n",
      "          avg_sen_length = 39.4                1 : 0      =     10.4 : 1.0\n",
      "          avg_sen_length = 23.09               0 : 1      =     10.3 : 1.0\n",
      "                   V_kyi = True                0 : 1      =     10.3 : 1.0\n",
      "                  V_mali = True                0 : 1      =     10.3 : 1.0\n",
      "                  V_rein = True                0 : 1      =     10.3 : 1.0\n",
      "                   V_suu = True                0 : 1      =     10.3 : 1.0\n",
      "                  V_milo = True                0 : 1      =     10.2 : 1.0\n",
      "              V_northern = True                0 : 1      =     10.2 : 1.0\n",
      "                V_taiwan = True                0 : 1      =     10.2 : 1.0\n",
      "                  V_euro = True                0 : 1      =     10.2 : 1.0\n",
      "                V_coward = True                1 : 0      =     10.2 : 1.0\n",
      "                 V_guess = True                1 : 0      =     10.2 : 1.0\n",
      "                   V_eas = True                0 : 1      =     10.1 : 1.0\n",
      "                 V_break = True                1 : 0      =     10.0 : 1.0\n",
      "                V_anonym = True                1 : 0      =      9.9 : 1.0\n",
      "             V_spokesman = True                0 : 1      =      9.9 : 1.0\n",
      "               V_inquiri = True                0 : 1      =      9.8 : 1.0\n",
      "                V_explod = True                1 : 0      =      9.8 : 1.0\n",
      "                 V_invad = True                1 : 0      =      9.8 : 1.0\n",
      "                    V_pa = True                1 : 0      =      9.8 : 1.0\n",
      "          avg_sen_length = 13.5                1 : 0      =      9.8 : 1.0\n",
      "                all_caps = 0.15                1 : 0      =      9.8 : 1.0\n",
      "             word_length = 7.14                0 : 1      =      9.8 : 1.0\n",
      "              V_brooklyn = True                0 : 1      =      9.8 : 1.0\n",
      "                  V_soro = True                1 : 0      =      9.7 : 1.0\n",
      "                 V_kenya = True                0 : 1      =      9.7 : 1.0\n",
      "                  V_kurd = True                0 : 1      =      9.7 : 1.0\n",
      "                V_christ = True                1 : 0      =      9.7 : 1.0\n",
      "                  V_hook = True                1 : 0      =      9.7 : 1.0\n",
      "               V_horizon = True                1 : 0      =      9.7 : 1.0\n",
      "                  V_pure = True                1 : 0      =      9.7 : 1.0\n",
      "                V_watter = True                1 : 0      =      9.7 : 1.0\n",
      "                all_caps = 0.8                 1 : 0      =      9.7 : 1.0\n",
      "             word_length = 5.95                1 : 0      =      9.7 : 1.0\n",
      "          avg_sen_length = 11.5                1 : 0      =      9.7 : 1.0\n",
      "          avg_sen_length = 38.78               1 : 0      =      9.7 : 1.0\n",
      "                V_coalit = True                0 : 1      =      9.7 : 1.0\n",
      "                V_oregon = True                1 : 0      =      9.7 : 1.0\n",
      "                V_atlant = True                0 : 1      =      9.6 : 1.0\n",
      "               V_extrump = True                0 : 1      =      9.6 : 1.0\n",
      "                V_lockhe = True                0 : 1      =      9.6 : 1.0\n",
      "                  V_peru = True                0 : 1      =      9.6 : 1.0\n",
      "                 V_rajoy = True                0 : 1      =      9.6 : 1.0\n",
      "                V_trader = True                0 : 1      =      9.6 : 1.0\n",
      "                V_region = True                0 : 1      =      9.6 : 1.0\n",
      "              V_shutdown = True                0 : 1      =      9.6 : 1.0\n",
      "             V_indonesia = True                0 : 1      =      9.5 : 1.0\n",
      "                V_hammer = True                1 : 0      =      9.5 : 1.0\n",
      "                V_extend = True                0 : 1      =      9.5 : 1.0\n",
      "             V_wednesday = True                0 : 1      =      9.5 : 1.0\n",
      "                V_someth = True                1 : 0      =      9.5 : 1.0\n",
      "                V_feloni = True                1 : 0      =      9.4 : 1.0\n",
      "                 V_sleep = True                1 : 0      =      9.4 : 1.0\n",
      "                 V_whine = True                1 : 0      =      9.4 : 1.0\n",
      "                 V_shock = True                1 : 0      =      9.4 : 1.0\n",
      "                 V_prove = True                1 : 0      =      9.4 : 1.0\n",
      "                  V_rico = True                0 : 1      =      9.4 : 1.0\n",
      "             word_length = 3.96                1 : 0      =      9.4 : 1.0\n",
      "                  V_lash = True                1 : 0      =      9.3 : 1.0\n",
      "                 V_japan = True                0 : 1      =      9.3 : 1.0\n",
      "              V_accident = True                1 : 0      =      9.2 : 1.0\n",
      "                  V_huma = True                1 : 0      =      9.2 : 1.0\n",
      "            V_parliament = True                0 : 1      =      9.2 : 1.0\n",
      "                V_assang = True                1 : 0      =      9.2 : 1.0\n",
      "                 V_trash = True                1 : 0      =      9.2 : 1.0\n",
      "                V_exampl = True                1 : 0      =      9.0 : 1.0\n",
      "                 V_gitmo = True                1 : 0      =      9.0 : 1.0\n",
      "                  V_vile = True                1 : 0      =      9.0 : 1.0\n",
      "                 V_brave = True                1 : 0      =      9.0 : 1.0\n",
      "          avg_sen_length = 2.0                 1 : 0      =      9.0 : 1.0\n",
      "          avg_sen_length = 40.11               1 : 0      =      9.0 : 1.0\n",
      "                 V_boost = True                0 : 1      =      9.0 : 1.0\n",
      "               V_lebanon = True                0 : 1      =      9.0 : 1.0\n",
      "                  V_pact = True                0 : 1      =      9.0 : 1.0\n",
      "                    V_1b = True                0 : 1      =      9.0 : 1.0\n",
      "                V_convoy = True                0 : 1      =      9.0 : 1.0\n",
      "                  V_gulf = True                0 : 1      =      9.0 : 1.0\n",
      "         V_parliamentari = True                0 : 1      =      9.0 : 1.0\n",
      "             V_peacekeep = True                0 : 1      =      9.0 : 1.0\n",
      "               V_proceed = True                0 : 1      =      9.0 : 1.0\n",
      "                  V_rift = True                0 : 1      =      9.0 : 1.0\n",
      "               V_tourism = True                0 : 1      =      9.0 : 1.0\n",
      "                  V_gave = True                1 : 0      =      8.9 : 1.0\n",
      "             word_length = 6.22                0 : 1      =      8.9 : 1.0\n",
      "               V_terrifi = True                1 : 0      =      8.9 : 1.0\n",
      "                   V_urg = True                0 : 1      =      8.9 : 1.0\n",
      "                   V_nut = True                1 : 0      =      8.9 : 1.0\n",
      "            V_referendum = True                0 : 1      =      8.8 : 1.0\n",
      "           V_whistleblow = True                1 : 0      =      8.8 : 1.0\n",
      "                  V_veto = True                0 : 1      =      8.8 : 1.0\n",
      "          avg_sen_length = 11.0                1 : 0      =      8.8 : 1.0\n",
      "                V_finger = True                1 : 0      =      8.7 : 1.0\n",
      "                   V_pig = True                1 : 0      =      8.7 : 1.0\n",
      "                   V_bid = True                0 : 1      =      8.7 : 1.0\n",
      "                 V_nanci = True                1 : 0      =      8.7 : 1.0\n",
      "                V_abedin = True                1 : 0      =      8.7 : 1.0\n",
      "                V_remind = True                1 : 0      =      8.7 : 1.0\n",
      "                V_disput = True                0 : 1      =      8.6 : 1.0\n",
      "               V_cartoon = True                1 : 0      =      8.6 : 1.0\n",
      "                V_realiz = True                1 : 0      =      8.6 : 1.0\n",
      "                V_taxpay = True                1 : 0      =      8.6 : 1.0\n",
      "                V_whoopi = True                1 : 0      =      8.6 : 1.0\n",
      "               V_hanniti = True                1 : 0      =      8.6 : 1.0\n",
      "                   V_rip = True                1 : 0      =      8.6 : 1.0\n",
      "                V_extens = True                0 : 1      =      8.6 : 1.0\n",
      "               V_subsidi = True                0 : 1      =      8.6 : 1.0\n",
      "                  V_huge = True                1 : 0      =      8.5 : 1.0\n",
      "                   V_lie = True                1 : 0      =      8.5 : 1.0\n",
      "                  V_oliv = True                1 : 0      =      8.5 : 1.0\n",
      "             V_hezbollah = True                0 : 1      =      8.4 : 1.0\n",
      "                  V_crop = True                1 : 0      =      8.4 : 1.0\n",
      "         V_extraordinari = True                1 : 0      =      8.4 : 1.0\n",
      "                 V_meyer = True                1 : 0      =      8.4 : 1.0\n",
      "                   V_out = True                1 : 0      =      8.4 : 1.0\n",
      "             word_length = 5.05                1 : 0      =      8.4 : 1.0\n",
      "             word_length = 2.75                1 : 0      =      8.4 : 1.0\n",
      "          avg_sen_length = 57.5                1 : 0      =      8.4 : 1.0\n",
      "          avg_sen_length = 66.0                1 : 0      =      8.4 : 1.0\n",
      "                 V_maxin = True                1 : 0      =      8.3 : 1.0\n",
      "                  V_mull = True                0 : 1      =      8.3 : 1.0\n",
      "                    V_nz = True                0 : 1      =      8.3 : 1.0\n",
      "              V_reshuffl = True                0 : 1      =      8.3 : 1.0\n",
      "                  V_mock = True                1 : 0      =      8.3 : 1.0\n",
      "                 V_alert = True                1 : 0      =      8.2 : 1.0\n",
      "                V_puppet = True                1 : 0      =      8.2 : 1.0\n",
      "                 V_unarm = True                1 : 0      =      8.2 : 1.0\n",
      "                 V_steal = True                1 : 0      =      8.2 : 1.0\n",
      "                 V_south = True                0 : 1      =      8.2 : 1.0\n",
      "              V_anderson = True                1 : 0      =      8.2 : 1.0\n",
      "                 V_radic = True                1 : 0      =      8.2 : 1.0\n",
      "              V_unbeliev = True                1 : 0      =      8.2 : 1.0\n",
      "                  V_yell = True                1 : 0      =      8.2 : 1.0\n",
      "             word_length = 4.32                1 : 0      =      8.2 : 1.0\n",
      "                 V_korea = True                0 : 1      =      8.2 : 1.0\n",
      "                 V_emiss = True                0 : 1      =      8.2 : 1.0\n",
      "                  V_bust = True                1 : 0      =      8.2 : 1.0\n",
      "                    V_rt = True                1 : 0      =      8.1 : 1.0\n",
      "                 V_teach = True                1 : 0      =      8.1 : 1.0\n",
      "                V_reveal = True                1 : 0      =      8.1 : 1.0\n",
      "                  V_boom = True                1 : 0      =      8.1 : 1.0\n",
      "            V_indonesian = True                0 : 1      =      8.1 : 1.0\n",
      "             V_peninsula = True                0 : 1      =      8.1 : 1.0\n",
      "                 V_impos = True                0 : 1      =      8.1 : 1.0\n",
      "               V_turkish = True                0 : 1      =      8.0 : 1.0\n",
      "                V_exclus = True                0 : 1      =      8.0 : 1.0\n",
      "                   V_god = True                1 : 0      =      8.0 : 1.0\n",
      "                V_financ = True                0 : 1      =      7.9 : 1.0\n",
      "                V_barack = True                1 : 0      =      7.9 : 1.0\n",
      "                 V_crazi = True                1 : 0      =      7.9 : 1.0\n",
      "                V_scorch = True                1 : 0      =      7.9 : 1.0\n",
      "              V_sharpton = True                1 : 0      =      7.9 : 1.0\n",
      "                   V_iii = True                1 : 0      =      7.8 : 1.0\n",
      "                  V_lame = True                1 : 0      =      7.8 : 1.0\n",
      "               V_oppress = True                1 : 0      =      7.8 : 1.0\n",
      "                  V_ever = True                1 : 0      =      7.8 : 1.0\n",
      "             V_highlight = True                0 : 1      =      7.8 : 1.0\n",
      "            V_guantanamo = True                0 : 1      =      7.8 : 1.0\n",
      "                 V_gowdi = True                1 : 0      =      7.8 : 1.0\n",
      "                  V_newt = True                1 : 0      =      7.8 : 1.0\n",
      "                V_libyan = True                0 : 1      =      7.7 : 1.0\n",
      "                 V_shame = True                1 : 0      =      7.7 : 1.0\n",
      "                  V_wire = True                1 : 0      =      7.7 : 1.0\n",
      "                V_puerto = True                0 : 1      =      7.7 : 1.0\n",
      "               V_carlson = True                1 : 0      =      7.7 : 1.0\n",
      "               V_f*cking = True                1 : 0      =      7.7 : 1.0\n",
      "              V_meltdown = True                1 : 0      =      7.7 : 1.0\n",
      "             word_length = 5.28                1 : 0      =      7.7 : 1.0\n",
      "          avg_sen_length = 36.1                1 : 0      =      7.7 : 1.0\n",
      "          avg_sen_length = 40.38               1 : 0      =      7.7 : 1.0\n",
      "               V_everyon = True                1 : 0      =      7.6 : 1.0\n",
      "                V_academ = True                0 : 1      =      7.6 : 1.0\n",
      "                V_kosovo = True                0 : 1      =      7.6 : 1.0\n",
      "                 V_minut = True                1 : 0      =      7.6 : 1.0\n",
      "                  V_sick = True                1 : 0      =      7.6 : 1.0\n",
      "                   V_ass = True                1 : 0      =      7.6 : 1.0\n",
      "                V_kimmel = True                1 : 0      =      7.6 : 1.0\n",
      "                  V_liar = True                1 : 0      =      7.6 : 1.0\n",
      "             word_length = 4.68                1 : 0      =      7.6 : 1.0\n",
      "                V_brexit = True                0 : 1      =      7.6 : 1.0\n",
      "              V_approach = True                0 : 1      =      7.5 : 1.0\n",
      "                V_backer = True                0 : 1      =      7.5 : 1.0\n",
      "                  V_gaza = True                0 : 1      =      7.5 : 1.0\n",
      "               V_erdogan = True                0 : 1      =      7.5 : 1.0\n",
      "               V_austria = True                0 : 1      =      7.5 : 1.0\n",
      "                  V_dumb = True                1 : 0      =      7.5 : 1.0\n",
      "                     V_n = True                1 : 0      =      7.5 : 1.0\n",
      "          avg_sen_length = 10.0                1 : 0      =      7.5 : 1.0\n",
      "                  V_amid = True                0 : 1      =      7.5 : 1.0\n",
      "                V_summit = True                0 : 1      =      7.4 : 1.0\n",
      "                 V_tweet = True                1 : 0      =      7.4 : 1.0\n",
      "               V_clapper = True                1 : 0      =      7.4 : 1.0\n",
      "                V_jeanin = True                1 : 0      =      7.4 : 1.0\n",
      "                  V_juan = True                1 : 0      =      7.4 : 1.0\n",
      "                   V_msm = True                1 : 0      =      7.4 : 1.0\n",
      "             V_protestor = True                1 : 0      =      7.4 : 1.0\n",
      "                V_throat = True                1 : 0      =      7.4 : 1.0\n",
      "                V_verita = True                1 : 0      =      7.4 : 1.0\n",
      "             word_length = 5.41                1 : 0      =      7.4 : 1.0\n",
      "                V_turkey = True                0 : 1      =      7.4 : 1.0\n",
      "                  V_nine = True                0 : 1      =      7.4 : 1.0\n",
      "                  V_toll = True                0 : 1      =      7.4 : 1.0\n",
      "                V_actual = True                1 : 0      =      7.4 : 1.0\n",
      "                    V_eu = True                0 : 1      =      7.4 : 1.0\n",
      "               V_colbert = True                1 : 0      =      7.4 : 1.0\n",
      "                 V_liber = True                1 : 0      =      7.4 : 1.0\n",
      "                V_berlin = True                0 : 1      =      7.4 : 1.0\n",
      "               V_bridgeg = True                0 : 1      =      7.4 : 1.0\n",
      "                V_fiscal = True                0 : 1      =      7.4 : 1.0\n",
      "                  V_info = True                1 : 0      =      7.3 : 1.0\n",
      "                V_rememb = True                1 : 0      =      7.3 : 1.0\n",
      "                V_diseas = True                1 : 0      =      7.3 : 1.0\n",
      "                   V_ron = True                1 : 0      =      7.3 : 1.0\n",
      "               V_hillari = True                1 : 0      =      7.3 : 1.0\n",
      "                 V_doubt = True                0 : 1      =      7.3 : 1.0\n",
      "                 V_stanc = True                0 : 1      =      7.3 : 1.0\n",
      "            V_bipartisan = True                0 : 1      =      7.3 : 1.0\n",
      "                   punct = 0.26                1 : 0      =      7.2 : 1.0\n",
      "                V_bomber = True                0 : 1      =      7.1 : 1.0\n",
      "                 V_trade = True                0 : 1      =      7.1 : 1.0\n",
      "                V_reform = True                0 : 1      =      7.1 : 1.0\n",
      "                 V_china = True                0 : 1      =      7.1 : 1.0\n",
      "                  V_cave = True                1 : 0      =      7.0 : 1.0\n",
      "                 V_dirti = True                1 : 0      =      7.0 : 1.0\n",
      "           V_documentari = True                1 : 0      =      7.0 : 1.0\n",
      "              V_frighten = True                1 : 0      =      7.0 : 1.0\n",
      "                V_infuri = True                1 : 0      =      7.0 : 1.0\n",
      "                  V_jess = True                1 : 0      =      7.0 : 1.0\n",
      "                  V_knee = True                1 : 0      =      7.0 : 1.0\n",
      "               V_leftist = True                1 : 0      =      7.0 : 1.0\n",
      "                  V_mask = True                1 : 0      =      7.0 : 1.0\n",
      "                V_physic = True                1 : 0      =      7.0 : 1.0\n",
      "                  V_ugli = True                1 : 0      =      7.0 : 1.0\n",
      "                V_vandal = True                1 : 0      =      7.0 : 1.0\n",
      "                V_wallac = True                1 : 0      =      7.0 : 1.0\n",
      "                   V_guy = True                1 : 0      =      7.0 : 1.0\n",
      "             word_length = 5.35                1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 17.17               1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 40.44               1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 41.62               1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 42.25               1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 43.4                1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 43.83               1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 46.71               1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 57.0                1 : 0      =      7.0 : 1.0\n",
      "                all_caps = 0.29                1 : 0      =      7.0 : 1.0\n",
      "          avg_sen_length = 21.89               0 : 1      =      7.0 : 1.0\n",
      "          avg_sen_length = 23.48               0 : 1      =      7.0 : 1.0\n",
      "          avg_sen_length = 27.97               0 : 1      =      7.0 : 1.0\n",
      "          avg_sen_length = 29.85               0 : 1      =      7.0 : 1.0\n",
      "                  V_clue = True                0 : 1      =      7.0 : 1.0\n",
      "              V_expresid = True                0 : 1      =      7.0 : 1.0\n",
      "                 V_pitch = True                0 : 1      =      7.0 : 1.0\n",
      "                 V_revis = True                0 : 1      =      7.0 : 1.0\n",
      "               V_shakeup = True                0 : 1      =      7.0 : 1.0\n",
      "             V_southeast = True                0 : 1      =      7.0 : 1.0\n",
      "              V_submarin = True                0 : 1      =      7.0 : 1.0\n",
      "                 V_matti = True                0 : 1      =      7.0 : 1.0\n",
      "                 V_milit = True                0 : 1      =      7.0 : 1.0\n",
      "             V_philippin = True                0 : 1      =      6.9 : 1.0\n",
      "                    V_dr = True                1 : 0      =      6.9 : 1.0\n",
      "               V_violent = True                1 : 0      =      6.9 : 1.0\n",
      "             word_length = 6.44                0 : 1      =      6.9 : 1.0\n",
      "               V_ridicul = True                1 : 0      =      6.9 : 1.0\n",
      "             word_length = 6.11                0 : 1      =      6.9 : 1.0\n",
      "                V_devast = True                1 : 0      =      6.9 : 1.0\n",
      "                V_minist = True                0 : 1      =      6.8 : 1.0\n",
      "                   V_nyc = True                1 : 0      =      6.8 : 1.0\n",
      "                 V_trend = True                1 : 0      =      6.8 : 1.0\n",
      "               V_michell = True                1 : 0      =      6.8 : 1.0\n",
      "              V_chaffetz = True                1 : 0      =      6.7 : 1.0\n",
      "                 V_grope = True                1 : 0      =      6.7 : 1.0\n",
      "                 V_ultim = True                1 : 0      =      6.7 : 1.0\n",
      "                V_julian = True                1 : 0      =      6.7 : 1.0\n",
      "          avg_sen_length = 28.65               0 : 1      =      6.7 : 1.0\n",
      "                   V_all = True                1 : 0      =      6.6 : 1.0\n",
      "               V_horrifi = True                1 : 0      =      6.6 : 1.0\n",
      "               V_lesbian = True                1 : 0      =      6.6 : 1.0\n",
      "                 V_malia = True                1 : 0      =      6.6 : 1.0\n",
      "               V_obliter = True                1 : 0      =      6.6 : 1.0\n",
      "              V_starbuck = True                1 : 0      =      6.6 : 1.0\n",
      "                 V_sarah = True                1 : 0      =      6.6 : 1.0\n",
      "                V_pastor = True                1 : 0      =      6.6 : 1.0\n",
      "                 V_delay = True                0 : 1      =      6.6 : 1.0\n",
      "                 V_limit = True                0 : 1      =      6.6 : 1.0\n",
      "                  V_fool = True                1 : 0      =      6.6 : 1.0\n",
      "             word_length = 5.16                1 : 0      =      6.6 : 1.0\n",
      "          avg_sen_length = 25.97               0 : 1      =      6.6 : 1.0\n",
      "                 V_assur = True                0 : 1      =      6.6 : 1.0\n",
      "                   V_cbo = True                0 : 1      =      6.6 : 1.0\n",
      "              V_honduran = True                0 : 1      =      6.6 : 1.0\n",
      "              V_mulvaney = True                0 : 1      =      6.6 : 1.0\n",
      "                V_sought = True                0 : 1      =      6.6 : 1.0\n",
      "                V_camera = True                1 : 0      =      6.6 : 1.0\n",
      "                   V_old = True                1 : 0      =      6.5 : 1.0\n",
      "                  V_hama = True                0 : 1      =      6.5 : 1.0\n",
      "                V_usback = True                0 : 1      =      6.5 : 1.0\n",
      "                  V_went = True                1 : 0      =      6.5 : 1.0\n",
      "                 V_excus = True                1 : 0      =      6.5 : 1.0\n",
      "                  V_dare = True                1 : 0      =      6.5 : 1.0\n",
      "                V_honest = True                1 : 0      =      6.5 : 1.0\n",
      "               V_pretend = True                1 : 0      =      6.5 : 1.0\n",
      "                  V_scam = True                1 : 0      =      6.4 : 1.0\n",
      "                   V_aim = True                0 : 1      =      6.4 : 1.0\n",
      "                   V_got = True                1 : 0      =      6.4 : 1.0\n",
      "                  V_modi = True                0 : 1      =      6.4 : 1.0\n",
      "                 V_north = True                0 : 1      =      6.4 : 1.0\n",
      "                 V_msnbc = True                1 : 0      =      6.4 : 1.0\n",
      "                  V_weve = True                1 : 0      =      6.4 : 1.0\n",
      "             word_length = 6.19                1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 12.67               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 12.8                1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 14.5                1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 16.4                1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 33.78               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 38.38               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 39.44               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 39.6                1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 40.42               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 41.14               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 41.29               1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 44.2                1 : 0      =      6.4 : 1.0\n",
      "          avg_sen_length = 21.91               0 : 1      =      6.3 : 1.0\n",
      "          avg_sen_length = 23.34               0 : 1      =      6.3 : 1.0\n",
      "          avg_sen_length = 26.51               0 : 1      =      6.3 : 1.0\n",
      "          avg_sen_length = 26.59               0 : 1      =      6.3 : 1.0\n",
      "          avg_sen_length = 30.28               0 : 1      =      6.3 : 1.0\n",
      "          avg_sen_length = 34.58               0 : 1      =      6.3 : 1.0\n",
      "              V_interior = True                0 : 1      =      6.3 : 1.0\n",
      "               V_actress = True                1 : 0      =      6.3 : 1.0\n",
      "               V_tension = True                0 : 1      =      6.3 : 1.0\n",
      "                V_racism = True                1 : 0      =      6.3 : 1.0\n",
      "                V_korean = True                0 : 1      =      6.3 : 1.0\n",
      "                V_disabl = True                1 : 0      =      6.3 : 1.0\n",
      "              V_colombia = True                0 : 1      =      6.2 : 1.0\n",
      "               V_tuesday = True                0 : 1      =      6.2 : 1.0\n",
      "                  V_agit = True                1 : 0      =      6.2 : 1.0\n",
      "             V_columnist = True                1 : 0      =      6.2 : 1.0\n",
      "                V_decept = True                1 : 0      =      6.2 : 1.0\n",
      "                V_serial = True                1 : 0      =      6.2 : 1.0\n",
      "          avg_sen_length = 14.6                1 : 0      =      6.2 : 1.0\n",
      "            V_conspiraci = True                1 : 0      =      6.2 : 1.0\n",
      "                 V_black = True                1 : 0      =      6.2 : 1.0\n",
      "               V_complic = True                0 : 1      =      6.2 : 1.0\n",
      "                V_consul = True                0 : 1      =      6.2 : 1.0\n",
      "              V_obamaera = True                0 : 1      =      6.2 : 1.0\n",
      "                V_polish = True                0 : 1      =      6.2 : 1.0\n",
      "                V_imagin = True                1 : 0      =      6.2 : 1.0\n",
      "                 V_actor = True                1 : 0      =      6.1 : 1.0\n",
      "               V_coverup = True                1 : 0      =      6.1 : 1.0\n",
      "              V_snowflak = True                1 : 0      =      6.1 : 1.0\n",
      "               V_societi = True                1 : 0      =      6.1 : 1.0\n",
      "                 V_theyr = True                1 : 0      =      6.1 : 1.0\n",
      "               V_illinoi = True                0 : 1      =      6.1 : 1.0\n",
      "                  V_sack = True                0 : 1      =      6.1 : 1.0\n",
      "                 V_color = True                1 : 0      =      6.1 : 1.0\n",
      "                  V_duke = True                1 : 0      =      6.1 : 1.0\n",
      "           negativecount = 5                   1 : 0      =      6.1 : 1.0\n",
      "                   V_ago = True                1 : 0      =      6.1 : 1.0\n",
      "             word_length = 4.37                1 : 0      =      6.1 : 1.0\n",
      "                   V_rnc = True                1 : 0      =      6.1 : 1.0\n",
      "             V_argentina = True                0 : 1      =      6.1 : 1.0\n",
      "             V_venezuela = True                0 : 1      =      6.0 : 1.0\n",
      "                   V_goe = True                1 : 0      =      6.0 : 1.0\n",
      "                   V_mom = True                1 : 0      =      6.0 : 1.0\n",
      "               V_advisor = True                1 : 0      =      6.0 : 1.0\n",
      "                V_someon = True                1 : 0      =      6.0 : 1.0\n",
      "                 V_truth = True                1 : 0      =      5.9 : 1.0\n",
      "          avg_sen_length = 19.5                1 : 0      =      5.9 : 1.0\n",
      "                 V_clash = True                0 : 1      =      5.9 : 1.0\n",
      "                  V_asia = True                0 : 1      =      5.9 : 1.0\n",
      "                 V_rival = True                0 : 1      =      5.9 : 1.0\n",
      "              V_islamist = True                0 : 1      =      5.9 : 1.0\n",
      "              V_suppress = True                1 : 0      =      5.9 : 1.0\n",
      "                  V_rock = True                1 : 0      =      5.9 : 1.0\n",
      "                 V_entir = True                1 : 0      =      5.9 : 1.0\n",
      "                 V_admit = True                1 : 0      =      5.9 : 1.0\n",
      "                  V_punk = True                1 : 0      =      5.9 : 1.0\n",
      "                 V_everi = True                1 : 0      =      5.9 : 1.0\n",
      "                 V_fresh = True                0 : 1      =      5.9 : 1.0\n",
      "                 V_phase = True                0 : 1      =      5.9 : 1.0\n",
      "                V_despit = True                0 : 1      =      5.9 : 1.0\n",
      "                V_beauti = True                1 : 0      =      5.8 : 1.0\n",
      "               V_shooter = True                1 : 0      =      5.8 : 1.0\n",
      "             word_length = 4.95                1 : 0      =      5.8 : 1.0\n",
      "             V_australia = True                0 : 1      =      5.8 : 1.0\n",
      "                 V_femal = True                1 : 0      =      5.8 : 1.0\n",
      "                  V_echo = True                0 : 1      =      5.8 : 1.0\n",
      "             V_intensifi = True                0 : 1      =      5.8 : 1.0\n",
      "                  V_cher = True                1 : 0      =      5.8 : 1.0\n",
      "                 V_choke = True                1 : 0      =      5.8 : 1.0\n",
      "                    V_do = True                1 : 0      =      5.8 : 1.0\n",
      "                V_evolut = True                1 : 0      =      5.8 : 1.0\n",
      "              V_goldberg = True                1 : 0      =      5.8 : 1.0\n",
      "               V_tyranni = True                1 : 0      =      5.8 : 1.0\n",
      "                  V_2018 = True                0 : 1      =      5.8 : 1.0\n",
      "                  V_piec = True                1 : 0      =      5.8 : 1.0\n",
      "          avg_sen_length = 27.28               0 : 1      =      5.8 : 1.0\n",
      "               V_fashion = True                0 : 1      =      5.8 : 1.0\n",
      "               V_hondura = True                0 : 1      =      5.8 : 1.0\n",
      "              V_istanbul = True                0 : 1      =      5.8 : 1.0\n",
      "                   V_joe = True                1 : 0      =      5.8 : 1.0\n",
      "                  V_hide = True                1 : 0      =      5.8 : 1.0\n",
      "                 V_punch = True                1 : 0      =      5.8 : 1.0\n",
      "                  V_here = True                1 : 0      =      5.8 : 1.0\n",
      "                 V_uncov = True                1 : 0      =      5.8 : 1.0\n",
      "                 V_reviv = True                0 : 1      =      5.7 : 1.0\n",
      "                 V_split = True                0 : 1      =      5.7 : 1.0\n",
      "          avg_sen_length = 18.0                1 : 0      =      5.7 : 1.0\n",
      "                 V_angri = True                1 : 0      =      5.7 : 1.0\n",
      "                 V_clown = True                1 : 0      =      5.7 : 1.0\n",
      "                   V_mob = True                1 : 0      =      5.7 : 1.0\n",
      "             word_length = 2.8                 1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 13.33               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 18.14               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 20.12               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 20.37               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 22.84               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 37.22               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 37.89               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 39.56               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 45.88               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 46.75               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 48.29               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 49.67               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 51.33               1 : 0      =      5.7 : 1.0\n",
      "          avg_sen_length = 27.66               0 : 1      =      5.6 : 1.0\n",
      "          avg_sen_length = 28.51               0 : 1      =      5.6 : 1.0\n",
      "          avg_sen_length = 33.37               0 : 1      =      5.6 : 1.0\n",
      "          avg_sen_length = 26.82               0 : 1      =      5.6 : 1.0\n",
      "               V_zealand = True                0 : 1      =      5.6 : 1.0\n",
      "              V_malaysia = True                0 : 1      =      5.6 : 1.0\n",
      "            V_strengthen = True                0 : 1      =      5.6 : 1.0\n",
      "                 V_updat = True                1 : 0      =      5.6 : 1.0\n",
      "                   V_boo = True                1 : 0      =      5.6 : 1.0\n",
      "                 V_funni = True                1 : 0      =      5.6 : 1.0\n",
      "                  V_flag = True                1 : 0      =      5.6 : 1.0\n",
      "                 V_anyon = True                1 : 0      =      5.6 : 1.0\n",
      "                  V_dump = True                1 : 0      =      5.6 : 1.0\n",
      "                    V_su = True                1 : 0      =      5.6 : 1.0\n",
      "                   V_bee = True                1 : 0      =      5.6 : 1.0\n",
      "              V_clueless = True                1 : 0      =      5.6 : 1.0\n",
      "                V_discov = True                1 : 0      =      5.6 : 1.0\n",
      "                   V_rig = True                1 : 0      =      5.6 : 1.0\n",
      "                V_happen = True                1 : 0      =      5.6 : 1.0\n",
      "              V_kellyann = True                1 : 0      =      5.6 : 1.0\n",
      "             V_jerusalem = True                0 : 1      =      5.6 : 1.0\n",
      "                  V_read = True                1 : 0      =      5.6 : 1.0\n",
      "                   V_jim = True                1 : 0      =      5.6 : 1.0\n",
      "                   V_own = True                1 : 0      =      5.6 : 1.0\n",
      "             V_weinstein = True                1 : 0      =      5.6 : 1.0\n",
      "                V_obsess = True                1 : 0      =      5.6 : 1.0\n",
      "             word_length = 4.63                1 : 0      =      5.6 : 1.0\n",
      "          avg_sen_length = 31.56               0 : 1      =      5.6 : 1.0\n",
      "                V_collin = True                0 : 1      =      5.5 : 1.0\n",
      "              V_selfdriv = True                0 : 1      =      5.5 : 1.0\n",
      "                 V_bulli = True                1 : 0      =      5.5 : 1.0\n",
      "                V_dutert = True                0 : 1      =      5.5 : 1.0\n",
      "                  V_lift = True                0 : 1      =      5.5 : 1.0\n",
      "              V_nightmar = True                1 : 0      =      5.5 : 1.0\n",
      "                 V_phoni = True                1 : 0      =      5.5 : 1.0\n",
      "                V_divers = True                1 : 0      =      5.5 : 1.0\n",
      "                 V_behar = True                1 : 0      =      5.5 : 1.0\n",
      "                V_betray = True                1 : 0      =      5.5 : 1.0\n",
      "                 V_clark = True                1 : 0      =      5.5 : 1.0\n",
      "                V_tshirt = True                1 : 0      =      5.5 : 1.0\n",
      "             word_length = 5.53                1 : 0      =      5.4 : 1.0\n",
      "                  V_tone = True                0 : 1      =      5.4 : 1.0\n",
      "                 V_calai = True                1 : 0      =      5.4 : 1.0\n",
      "              V_everyday = True                1 : 0      =      5.4 : 1.0\n",
      "              V_portland = True                1 : 0      =      5.4 : 1.0\n",
      "                  V_wive = True                1 : 0      =      5.4 : 1.0\n",
      "             word_length = 6.06                1 : 0      =      5.4 : 1.0\n",
      "                V_outrag = True                1 : 0      =      5.4 : 1.0\n",
      "                    V_la = True                1 : 0      =      5.4 : 1.0\n",
      "                  V_wolf = True                1 : 0      =      5.4 : 1.0\n",
      "          avg_sen_length = 25.28               0 : 1      =      5.4 : 1.0\n",
      "          avg_sen_length = 29.19               0 : 1      =      5.4 : 1.0\n",
      "          avg_sen_length = 30.39               0 : 1      =      5.4 : 1.0\n",
      "                V_cleric = True                0 : 1      =      5.4 : 1.0\n",
      "               V_hardlin = True                0 : 1      =      5.4 : 1.0\n",
      "               V_reflect = True                0 : 1      =      5.4 : 1.0\n",
      "                V_smuggl = True                0 : 1      =      5.4 : 1.0\n",
      "             word_length = 4.74                1 : 0      =      5.4 : 1.0\n",
      "                 V_swiss = True                0 : 1      =      5.3 : 1.0\n",
      "               V_liberti = True                1 : 0      =      5.3 : 1.0\n",
      "            V_australian = True                0 : 1      =      5.3 : 1.0\n",
      "                V_sexist = True                1 : 0      =      5.3 : 1.0\n",
      "                 V_brief = True                0 : 1      =      5.3 : 1.0\n",
      "                   V_new = True                0 : 1      =      5.3 : 1.0\n",
      "                   V_4th = True                1 : 0      =      5.3 : 1.0\n",
      "                 V_hater = True                1 : 0      =      5.3 : 1.0\n",
      "               V_intoler = True                1 : 0      =      5.3 : 1.0\n",
      "               V_militar = True                1 : 0      =      5.3 : 1.0\n",
      "                 V_mouth = True                1 : 0      =      5.3 : 1.0\n",
      "               V_segment = True                1 : 0      =      5.3 : 1.0\n",
      "              V_surround = True                1 : 0      =      5.3 : 1.0\n",
      "                 V_whose = True                1 : 0      =      5.3 : 1.0\n",
      "                 V_regim = True                1 : 0      =      5.3 : 1.0\n",
      "                V_muslim = True                1 : 0      =      5.3 : 1.0\n",
      "               V_britain = True                0 : 1      =      5.3 : 1.0\n",
      "                V_dollar = True                1 : 0      =      5.3 : 1.0\n",
      "                 V_nasti = True                1 : 0      =      5.3 : 1.0\n",
      "             word_length = 6.62                0 : 1      =      5.3 : 1.0\n",
      "                V_budget = True                0 : 1      =      5.3 : 1.0\n",
      "               V_suspect = True                0 : 1      =      5.2 : 1.0\n",
      "                 V_donna = True                1 : 0      =      5.2 : 1.0\n",
      "                V_volunt = True                1 : 0      =      5.2 : 1.0\n",
      "                V_merkel = True                0 : 1      =      5.2 : 1.0\n",
      "               V_connect = True                1 : 0      =      5.2 : 1.0\n",
      "                V_famous = True                1 : 0      =      5.2 : 1.0\n",
      "               V_mention = True                1 : 0      =      5.2 : 1.0\n",
      "                   V_rob = True                1 : 0      =      5.2 : 1.0\n",
      "                  V_tire = True                1 : 0      =      5.2 : 1.0\n",
      "               V_belgian = True                0 : 1      =      5.2 : 1.0\n",
      "               V_januari = True                0 : 1      =      5.2 : 1.0\n",
      "             word_length = 6.88                0 : 1      =      5.2 : 1.0\n",
      "               V_outlook = True                1 : 0      =      5.2 : 1.0\n",
      "                 V_shout = True                1 : 0      =      5.2 : 1.0\n",
      "                V_maduro = True                0 : 1      =      5.2 : 1.0\n",
      "             V_terrorist = True                1 : 0      =      5.1 : 1.0\n",
      "                  V_hell = True                1 : 0      =      5.1 : 1.0\n",
      "                  V_wear = True                1 : 0      =      5.1 : 1.0\n",
      "                 V_earth = True                1 : 0      =      5.1 : 1.0\n",
      "                 V_dozen = True                0 : 1      =      5.1 : 1.0\n",
      "               V_staffer = True                1 : 0      =      5.1 : 1.0\n",
      "            V_propaganda = True                1 : 0      =      5.1 : 1.0\n",
      "                   V_dnc = True                1 : 0      =      5.1 : 1.0\n",
      "               V_explain = True                1 : 0      =      5.1 : 1.0\n",
      "                    V_65 = True                1 : 0      =      5.0 : 1.0\n",
      "            V_accomplish = True                1 : 0      =      5.0 : 1.0\n",
      "                 V_akbar = True                1 : 0      =      5.0 : 1.0\n",
      "                    V_my = True                1 : 0      =      5.0 : 1.0\n",
      "                  V_pill = True                1 : 0      =      5.0 : 1.0\n",
      "                    V_sc = True                1 : 0      =      5.0 : 1.0\n",
      "                  V_sore = True                1 : 0      =      5.0 : 1.0\n",
      "                 V_stunt = True                1 : 0      =      5.0 : 1.0\n",
      "                  V_tree = True                1 : 0      =      5.0 : 1.0\n",
      "                V_unload = True                1 : 0      =      5.0 : 1.0\n",
      "                  V_alec = True                1 : 0      =      5.0 : 1.0\n",
      "                V_daniel = True                1 : 0      =      5.0 : 1.0\n",
      "                 V_dress = True                1 : 0      =      5.0 : 1.0\n",
      "                  V_kept = True                1 : 0      =      5.0 : 1.0\n",
      "                   V_nra = True                1 : 0      =      5.0 : 1.0\n",
      "               V_wildlif = True                1 : 0      =      5.0 : 1.0\n",
      "                   V_hat = True                1 : 0      =      5.0 : 1.0\n",
      "                 V_invas = True                1 : 0      =      5.0 : 1.0\n",
      "             word_length = 6.21                1 : 0      =      5.0 : 1.0\n",
      "             word_length = 4.76                1 : 0      =      5.0 : 1.0\n",
      "             word_length = 5.39                1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 21.98               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 33.26               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 35.26               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 37.45               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 38.82               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 39.86               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 40.57               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 40.69               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 47.25               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 50.17               1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 59.0                1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 73.0                1 : 0      =      5.0 : 1.0\n",
      "          avg_sen_length = 24.24               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 24.51               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 27.43               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 28.28               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 28.96               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 29.18               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 29.87               0 : 1      =      5.0 : 1.0\n",
      "          avg_sen_length = 30.35               0 : 1      =      5.0 : 1.0\n",
      "                V_massiv = True                1 : 0      =      5.0 : 1.0\n",
      "             word_length = 7.62                0 : 1      =      5.0 : 1.0\n",
      "             V_diplomaci = True                0 : 1      =      5.0 : 1.0\n",
      "                 V_entri = True                0 : 1      =      5.0 : 1.0\n",
      "               V_japanes = True                0 : 1      =      5.0 : 1.0\n",
      "             V_pakistani = True                0 : 1      =      5.0 : 1.0\n",
      "                  V_port = True                0 : 1      =      5.0 : 1.0\n",
      "               V_theresa = True                0 : 1      =      5.0 : 1.0\n",
      "              V_treasuri = True                0 : 1      =      5.0 : 1.0\n",
      "               V_turmoil = True                0 : 1      =      5.0 : 1.0\n",
      "                V_uphold = True                0 : 1      =      5.0 : 1.0\n",
      "               V_charter = True                0 : 1      =      5.0 : 1.0\n",
      "               V_conceal = True                0 : 1      =      5.0 : 1.0\n",
      "                V_corker = True                0 : 1      =      5.0 : 1.0\n",
      "                V_decemb = True                0 : 1      =      5.0 : 1.0\n",
      "                   V_fcc = True                0 : 1      =      5.0 : 1.0\n",
      "                V_houthi = True                0 : 1      =      5.0 : 1.0\n",
      "                 V_olymp = True                0 : 1      =      5.0 : 1.0\n",
      "              V_principl = True                0 : 1      =      5.0 : 1.0\n",
      "                 V_swift = True                0 : 1      =      5.0 : 1.0\n",
      "                   V_hes = True                1 : 0      =      5.0 : 1.0\n",
      "                 V_franc = True                0 : 1      =      5.0 : 1.0\n",
      "                 V_palin = True                1 : 0      =      5.0 : 1.0\n",
      "                  V_nazi = True                1 : 0      =      4.9 : 1.0\n",
      "                   V_cri = True                1 : 0      =      4.9 : 1.0\n",
      "                  V_live = True                1 : 0      =      4.9 : 1.0\n",
      "                 V_cyber = True                0 : 1      =      4.9 : 1.0\n",
      "                 V_panel = True                0 : 1      =      4.9 : 1.0\n",
      "                 V_ahead = True                0 : 1      =      4.9 : 1.0\n",
      "                V_beyonc = True                1 : 0      =      4.9 : 1.0\n",
      "              V_giuliani = True                1 : 0      =      4.9 : 1.0\n",
      "                 V_panic = True                1 : 0      =      4.9 : 1.0\n",
      "                  V_wast = True                1 : 0      =      4.9 : 1.0\n",
      "                  V_sing = True                1 : 0      =      4.9 : 1.0\n",
      "                V_reason = True                1 : 0      =      4.9 : 1.0\n",
      "                 V_resum = True                0 : 1      =      4.8 : 1.0\n",
      "                   V_mad = True                1 : 0      =      4.8 : 1.0\n",
      "                 V_wreck = True                1 : 0      =      4.8 : 1.0\n",
      "                   V_vow = True                0 : 1      =      4.8 : 1.0\n",
      "             word_length = 7.12                0 : 1      =      4.8 : 1.0\n",
      "             word_length = 4.04                1 : 0      =      4.8 : 1.0\n",
      "          avg_sen_length = 26.07               0 : 1      =      4.8 : 1.0\n",
      "                 V_glenn = True                1 : 0      =      4.8 : 1.0\n",
      "                 V_smash = True                1 : 0      =      4.8 : 1.0\n",
      "                V_suppos = True                1 : 0      =      4.8 : 1.0\n",
      "                  V_sean = True                1 : 0      =      4.8 : 1.0\n",
      "          avg_sen_length = 27.27               0 : 1      =      4.8 : 1.0\n",
      "                V_monday = True                0 : 1      =      4.8 : 1.0\n",
      "                 V_idlib = True                0 : 1      =      4.8 : 1.0\n",
      "                  V_mate = True                0 : 1      =      4.8 : 1.0\n",
      "                V_packag = True                0 : 1      =      4.8 : 1.0\n",
      "               V_audienc = True                1 : 0      =      4.8 : 1.0\n",
      "              V_privileg = True                1 : 0      =      4.8 : 1.0\n",
      "               V_america = True                1 : 0      =      4.7 : 1.0\n",
      "              V_manafort = True                0 : 1      =      4.7 : 1.0\n",
      "                V_afraid = True                1 : 0      =      4.7 : 1.0\n",
      "                 V_allah = True                1 : 0      =      4.7 : 1.0\n",
      "                 V_allen = True                1 : 0      =      4.7 : 1.0\n",
      "                V_belong = True                1 : 0      =      4.7 : 1.0\n",
      "                  V_cake = True                1 : 0      =      4.7 : 1.0\n",
      "               V_panther = True                1 : 0      =      4.7 : 1.0\n",
      "                   V_pic = True                1 : 0      =      4.7 : 1.0\n",
      "               V_qualifi = True                1 : 0      =      4.7 : 1.0\n",
      "             word_length = 2.88                1 : 0      =      4.7 : 1.0\n",
      "        V_charlottesvill = True                1 : 0      =      4.7 : 1.0\n",
      "                V_deserv = True                1 : 0      =      4.7 : 1.0\n",
      "              V_homeless = True                1 : 0      =      4.7 : 1.0\n",
      "                   V_roy = True                1 : 0      =      4.7 : 1.0\n",
      "          avg_sen_length = 32.13               0 : 1      =      4.7 : 1.0\n",
      "          avg_sen_length = 32.79               0 : 1      =      4.7 : 1.0\n",
      "             word_length = 7.71                0 : 1      =      4.7 : 1.0\n",
      "           V_connecticut = True                0 : 1      =      4.7 : 1.0\n",
      "         V_counterterror = True                0 : 1      =      4.7 : 1.0\n",
      "               V_exercis = True                0 : 1      =      4.7 : 1.0\n",
      "                 V_niger = True                0 : 1      =      4.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NBclassifier.show_most_informative_features(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4e23906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_textbigram_quant_composite_df = pd.concat([avg_sent_len_featuresets_df, quant_ling_featuresets_df,text_bigrams_df, title_unigrams_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "455a67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_textbigram_quant_composite_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in uni_textbigram_quant_composite_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4e837bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and quantitative linguistic features:0.8800019032212019\n",
      "\n",
      "Execution time: 162.03447699546814 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = uni_textbigram_quant_composite_featuresets[(round(.30 * len(uni_textbigram_quant_composite_featuresets))):], uni_textbigram_quant_composite_featuresets[:(round(.30 * len(uni_textbigram_quant_composite_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "\n",
    "print(f\"Accuracy with combined unigram and quantitative linguistic features:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9ca68e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion_Matrix----\n",
      "\n",
      "   |    1    0 |\n",
      "--+-----------+\n",
      "1 |<8900>1658 |\n",
      "0 |  864<9595>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "\n",
      "Evaluation_Metrics----\n",
      "\n",
      "\tPrecision\tRecall\t    F1\t Specificity\n",
      "0 \t      0.853      0.917      0.884      0.843\n",
      "1 \t      0.912      0.843      0.876      0.917\n"
     ]
    }
   ],
   "source": [
    "cm_eval_print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "caa8bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_opinion_quant_composite_df = pd.concat([avg_sent_len_featuresets_df, quant_ling_featuresets_df, opinion_only_df, title_unigrams_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "23c6bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_opinion_quant_composite_featuresets = [(dict(row.drop('label').items()), row['label']) for index, row in uni_opinion_quant_composite_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a565d169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with combined unigram and quantitative linguistic features:0.8780035209592235\n",
      "\n",
      "Execution time: 148.7792510986328 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_set, test_set = uni_opinion_quant_composite_featuresets[(round(.30 * len(uni_opinion_quant_composite_featuresets))):], uni_opinion_quant_composite_featuresets[:(round(.30 * len(uni_opinion_quant_composite_featuresets)))]\n",
    "NBclassifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(NBclassifier, test_set)\n",
    "\n",
    "print(f\"Accuracy with combined unigram and quantitative linguistic features:{accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nExecution time: {end - start} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a54a43",
   "metadata": {},
   "source": [
    "<h1>Test 11: Using a Composite Featureset  with SciKit Learn Classifiers</h1>\n",
    "<h3>Features: Unigram + Bigram + Three Quantitative Lingusitic Features</h3>\n",
    "<h3>Classifiers: Linear SVC, NB Gaussian, Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f6173392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF QUANTITATIVE LINGUISTIC FEATURES + UNIGRAM FEATURES\n",
    "df_title_unigrams = pd.read_csv('~/title_unigram_features_fakenews_df_canonical.csv')\n",
    "\n",
    "quant_ling_featuresets_df = pd.read_csv('~/title_quant_ling_featuresets_df_canonical.csv')\n",
    "\n",
    "remove_label1 = quant_ling_featuresets_df.pop('label')\n",
    "\n",
    "avg_sent_len_featuresets_df = pd.read_csv('~/avg_sent_len_featuresets_df_canonical.csv')\n",
    "\n",
    "remove_label2 = avg_sent_len_featuresets_df.pop('label')\n",
    "\n",
    "unigram_quant_ling_df = pd.concat([avg_sent_len_featuresets_df, quant_ling_featuresets_df, df_title_unigrams], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "884c47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unigram_quant_ling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4d5e9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70056, 3871)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "98c71c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2cb283f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kFolds = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb98aa6",
   "metadata": {},
   "source": [
    "<h2>a) Linear SVC Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5df7f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_classifier = LinearSVC(C=1, penalty='l1', dual=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bc0844db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(SVC_classifier, X, y, cv=kFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "06e2afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation Metrics for Linear SVC\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91     35028\n",
      "           1       0.91      0.90      0.90     35028\n",
      "\n",
      "    accuracy                           0.90     70056\n",
      "   macro avg       0.90      0.90      0.90     70056\n",
      "weighted avg       0.90      0.90      0.90     70056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross Validation Metrics for Linear SVC\\n\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9cd91723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Linear SVC\n",
      "\n",
      " Predicted      0      1    All\n",
      "Actual                        \n",
      "0          31757   3271  35028\n",
      "1           3391  31637  35028\n",
      "All        35148  34908  70056\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix for Linear SVC\\n\\n\", pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "23d05e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=1, dual=False, penalty=&#x27;l1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=1, dual=False, penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=1, dual=False, penalty='l1')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "cdd28137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict decision scores\n",
    "y_pred_scores = SVC_classifier.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f41bd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FPR, TPR, and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_scores)\n",
    "auc = roc_auc_score(y_test, y_pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "3b425cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC ROC Curve for SVC Linear Classifier:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nAUC ROC Curve for SVC Linear Classifier:\\n\")\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0cbaa",
   "metadata": {},
   "source": [
    "<h2>b) Naive Bayes Gaussian Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "31209ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classifier = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1fe4df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(NB_classifier, X, y, cv=kFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "4b84c88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation Metrics for NB Gaussian\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80     35028\n",
      "           1       0.83      0.73      0.78     35028\n",
      "\n",
      "    accuracy                           0.79     70056\n",
      "   macro avg       0.80      0.79      0.79     70056\n",
      "weighted avg       0.80      0.79      0.79     70056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross Validation Metrics for NB Gaussian\\n\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b51782be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0a8af5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Gaussian Naive Bayes:\n",
      "\n",
      " Predicted      0      1    All\n",
      "Actual                        \n",
      "0          29834   5194  35028\n",
      "1           9312  25716  35028\n",
      "All        39146  30910  70056\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\\nConfusion Matrix for Gaussian Naive Bayes:\\n\\n\", pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1d316128",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = NB_classifier.predict_proba(X_test)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8dc63c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FPR, TPR, and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "33747dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC ROC for Gaussian Naive Bayes Classifier:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nAUC ROC for Gaussian Naive Bayes Classifier:\")\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbff97c",
   "metadata": {},
   "source": [
    "<h2>c) Logistic Regression Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e4e9f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier = LogisticRegression(class_weight='balanced',solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d8657cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = cross_val_predict(logreg_classifier, X, y, cv=kFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "aaf13897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation Metrics for Logistic Regression:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91     35028\n",
      "           1       0.91      0.90      0.91     35028\n",
      "\n",
      "    accuracy                           0.91     70056\n",
      "   macro avg       0.91      0.91      0.91     70056\n",
      "weighted avg       0.91      0.91      0.91     70056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross Validation Metrics for Logistic Regression:\\n\\n\", classification_report(y, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "350435fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='liblinear')"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "81dd4b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "\n",
      " Predicted      0      1    All\n",
      "Actual                        \n",
      "0          31902   3126  35028\n",
      "1           3369  31659  35028\n",
      "All        35271  34785  70056\n"
     ]
    }
   ],
   "source": [
    "cm_logreg = confusion_matrix(y, y_pred_logreg)\n",
    "print(\"\\nConfusion Matrix for Logistic Regression:\\n\\n\", pd.crosstab(y, y_pred_logreg, rownames=['Actual'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7a7c1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_proba = logreg_classifier.predict_proba(X_test)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e1e1e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FPR, TPR, and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "601d4446",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC ROC for Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nAUC ROC for Logistic Regression:\")\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a859258",
   "metadata": {},
   "source": [
    "<h3>Test 9.a-c Discussion: Combining Featuresets and Using SciKit Learn Classifiers</h3>\n",
    "<br>  \n",
    "<body>\n",
    "The combining of several featuresets, mixing BoW features with several quantitative linguistic features gave us a reasonably high score, with\n",
    "    <b>Accuracy / Precision / Recall / F1 in the 90-91% range </b> on \n",
    "    both the <b>Linear SVC</b> and the <b>Logistic Regression</b> classifiers. \n",
    "<br><br>\n",
    "Suprisingly, the Gaussian Naive Bayes classifier produced significantly poorer results--among the lowest we achieved--with a mean accuracy of only 79%. \n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6432ea",
   "metadata": {},
   "source": [
    "<h1>Test 15b: TF-IDF vectorization with quantitative linguistic features</h1>\n",
    "<br>\n",
    "<body>This was a quick experiment with adding several of the quantitative linguistic features used with the unigram Bag of Words featureset to a TF-IDF vectorization. We found that it enhanced performance, yielding some of our highest scores.</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9d5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702ad6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/WELFake_Dataset.csv', \n",
    "                 index_col=None, \n",
    "                 header=0,\n",
    "                 names=['title', 'text', 'label'])\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ef0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['punct%'] = data['title'].apply(lambda x: percent_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf91093",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['body_len'] = data['title'].apply(lambda x: len(x) - x.count(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f84877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['all_caps'] = data['title'].apply(lambda x: percent_ALL_CAP(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767ddf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase the text and remove unwanted characters\n",
    "    text = \"\".join([word.lower() for word in text if (word not in string.punctuation and \n",
    "    word not in extra_punct) or word in style_punct])\n",
    "    \n",
    "    # Define a RegexpTokenizer that tokenizes asteriks within words (e.g. for obscuring expletives)\n",
    "    # and keeps hashes with hashtags\n",
    "    tokenizer = RegexpTokenizer(r'[A-Za-z*]+|\\S+')\n",
    "\n",
    "    # Tokenize the cleaned text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # stem words using Snowball Stemmer\n",
    "    text = [stemmer.stem(word) for word in tokens if word not in filter_words]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ed5b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['title', 'punct%', 'all_caps', 'body_len']], data['label'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace02297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>punct%</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>body_len</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>22450</th>\n",
       "      <th>22451</th>\n",
       "      <th>22452</th>\n",
       "      <th>22453</th>\n",
       "      <th>22454</th>\n",
       "      <th>22455</th>\n",
       "      <th>22456</th>\n",
       "      <th>22457</th>\n",
       "      <th>22458</th>\n",
       "      <th>22459</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>85</td>\n",
       "      <td>0.146367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.36</td>\n",
       "      <td>123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   punct%  all_caps  body_len         0    1    2    3    4    5    6  ...  \\\n",
       "0    0.01      0.07        64  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1    0.04      0.25        65  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2    0.08      0.09        64  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3    0.03      0.46        85  0.146367  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4    0.01      0.36       123  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   22450  22451  22452  22453  22454  22455  22456  22457  22458  22459  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 22463 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['title'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['title'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['title'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['punct%','all_caps', 'body_len']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['punct%', 'all_caps', 'body_len']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c028e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "X_train_vect.columns = X_train_vect.columns.astype(str)\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "\n",
    "X_test_vect.columns = X_test_vect.columns.astype(str)\n",
    "y_pred = rf_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3bee4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.939 / Recall: 0.951 / Accuracy: 0.944\n",
      "F1: 0.945\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label=1, average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "f1 = round(calculate_f1_score(precision, recall), 3)\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02384dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg_Precision: 0.949 / Neg_Recall: 0.936 / Neg_Accuracy: 0.944\n",
      "Neg_F1: 0.942\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label=0, average='binary')\n",
    "print('Neg_Precision: {} / Neg_Recall: {} / Neg_Accuracy: {}'.format(round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "f1 = round(calculate_f1_score(precision, recall), 3)\n",
    "print(f\"Neg_F1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
